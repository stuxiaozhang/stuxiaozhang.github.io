<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="[toc]
卷积神经网络
卷积神经网络 CNN
计算机视觉
计算机视觉（Computer Vision）的高速发展标志着新型应用产生的可能，例如自动驾驶、人脸识别、创造新的艺术风格。人们对于计算机视觉的研究也催生了很多机算机视觉与其他领域的交叉成果。一般的计算机视觉问题包括以下几类：

图片分类（Image Classification）；
目标检测（Object detection"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>《深度学习》课程笔记4_卷积神经网络 - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/vs.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:85,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,0)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="《深度学习》课程笔记4_卷积神经网络"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2020-12-06 17:18" pubdate>2020-12-06</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 5.1k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 70 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">《深度学习》课程笔记4_卷积神经网络</h1><div class="markdown-body"><p>[toc]</p><h1 id="卷积神经网络">卷积神经网络</h1><h2 id="卷积神经网络-cnn">卷积神经网络 CNN</h2><h3 id="计算机视觉">计算机视觉</h3><p><strong>计算机视觉（Computer Vision）</strong>的高速发展标志着新型应用产生的可能，例如自动驾驶、人脸识别、创造新的艺术风格。人们对于计算机视觉的研究也催生了很多机算机视觉与其他领域的交叉成果。一般的计算机视觉问题包括以下几类：</p><ul><li>图片分类（Image Classification）；</li><li>目标检测（Object detection）；</li><li>神经风格转换（Neural Style Transfer）。</li></ul><p>应用计算机视觉时要面临的一个挑战是数据的输入可能会非常大。例如一张 1000x1000x3 的图片，神经网络输入层的维度将高达三百万，使得网络权重 W 非常庞大。这样会造成两个后果：</p><ol type="1"><li>神经网络结构复杂，数据量相对较少，容易出现过拟合；</li><li>所需内存和计算量巨大。</li></ol><p>因此，一般的神经网络很难处理蕴含着大量数据的图像。解决这一问题的方法就是使用<strong>卷积神经网络（Convolutional Neural Network, CNN）</strong>。</p><h3 id="卷积运算">卷积运算</h3><p>我们之前提到过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等），到最后面的一层就可以根据前面检测的特征来识别整体面部轮廓。这些工作都是依托卷积神经网络来实现的。</p><p><strong>卷积运算（Convolutional Operation）</strong>是卷积神经网络最基本的组成部分。我们以边缘检测为例，来解释卷积是怎样运算的。</p><h4 id="边缘检测">边缘检测</h4><p>图片最常做的边缘检测有两类：<strong>垂直边缘（Vertical Edges）检测</strong>和<strong>水平边缘（Horizontal Edges）检测</strong>。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207101305453.png" srcset="/img/loading.gif" lazyload alt="image-20201207101305453"><figcaption>image-20201207101305453</figcaption></figure><p>图片的边缘检测可以通过与相应滤波器进行卷积来实现。以垂直边缘检测为例，原始图片尺寸为 6x6，中间的矩阵被称作<strong>滤波器（filter）</strong>，尺寸为 3x3，卷积后得到的图片尺寸为 4x4，得到结果如下（数值表示灰度，以左上角和右下角的值为例）：</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207103132826.png" srcset="/img/loading.gif" lazyload alt="image-20201207103132826"><figcaption>image-20201207103132826</figcaption></figure><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207103929622.png" srcset="/img/loading.gif" lazyload alt="image-20201207103929622"><figcaption>image-20201207103929622</figcaption></figure><p>可以看到，卷积运算的求解过程是从左到右，由上到下，每次在原始图片矩阵中取与滤波器同等大小的一部分 ，每一部分中的值与滤波器中的值对应相乘后求和，将结果组成一个矩阵。</p><p>下图对应一个垂直边缘检测的例子：</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207105004129.png" srcset="/img/loading.gif" lazyload alt="image-20201207105004129"><figcaption>image-20201207105004129</figcaption></figure><p>如果将最右边的矩阵当作图像，那么中间一段亮一些的区域对应最左边的图像中间的垂直边缘。</p><h4 id="更多边缘检测的例子">更多边缘检测的例子</h4><p>如果将灰度图左右的颜色进行翻转，再与之前的滤波器进行卷积，得到的结果也有区别。实际应用中，这反映了由明变暗和由暗变明的两种渐变方式。可以对输出图片取绝对值操作，以得到同样的结果。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207111642258.png" srcset="/img/loading.gif" lazyload alt="image-20201207111642258"><figcaption>image-20201207111642258</figcaption></figure><p>垂直边缘检测和水平边缘检测的滤波器如下所示：</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207112003086.png" srcset="/img/loading.gif" lazyload alt="image-20201207112003086"><figcaption>image-20201207112003086</figcaption></figure><p>其他常用的滤波器还有 Sobel 滤波器和 Scharr 滤波器。它们增加了中间行的权重，以提高结果的稳健性。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207112353055.png" srcset="/img/loading.gif" lazyload alt="image-20201207112353055"><figcaption>image-20201207112353055</figcaption></figure><p>滤波器中的值还可以设置为<strong>参数</strong>，通过模型训练来得到。这样，神经网络使用反向传播算法可以学习到一些低级特征，从而实现对图片所有边缘特征的检测，而不仅限于垂直边缘和水平边缘。</p><h3 id="填充">填充</h3><p>假设输入图片的大小为 <span class="math inline">\(n×n\)</span>，而滤波器的大小为 <span class="math inline">\(f×f\)</span>，则卷积后的输出图片大小为 <span class="math inline">\((n−f+1)×(n−f+1)\)</span> 。</p><p>这样就有两个问题：</p><ul><li>每次卷积运算后，输出图片的尺寸缩小；</li><li>原始图片的角落、边缘区像素点在输出中采用较少，输出图片丢失边缘位置的很多信息。</li></ul><p>为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行<strong>填充（Padding）</strong>，以增加矩阵的大小。通常将 0 作为填充值。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201207133745044.png" srcset="/img/loading.gif" lazyload alt="image-20201207133745044"><figcaption>image-20201207133745044</figcaption></figure><p>设每个方向扩展像素点数量为 <span class="math inline">\(p\)</span>，则填充后原始图片的大小为 <span class="math inline">\((n+2p)×(n+2p)\)</span>，滤波器大小保持 <span class="math inline">\(f×f\)</span> 不变，则输出图片大小为 <span class="math inline">\((n+2p−f+1)×(n+2p−f+1)\)</span>。</p><p>因此，在进行卷积运算时，我们有两种选择：</p><ul><li><strong>Valid 卷积</strong>：不填充，直接卷积。结果大小为 <span class="math inline">\((n−f+1)×(n−f+1)\)</span>；</li><li><strong>Same 卷积</strong>：进行填充，并使得卷积后结果大小与输入一致，这样可以得到 <span class="math inline">\(p=\frac{f−1}2\)</span> 。</li></ul><p>在计算机视觉领域，<span class="math inline">\(f\)</span> 通常为奇数。原因包括 Same 卷积中 <span class="math inline">\(p=\frac{f−1}2\)</span> 能得到自然数结果，并且滤波器有一个便于表示其所在位置的中心点。</p><h3 id="卷积步长">卷积步长</h3><p>卷积过程中，有时需要通过填充来避免信息损失，有时也需要通过设置<strong>步长（Stride）</strong>来压缩一部分信息。步长表示滤波器在原始图片的水平方向和垂直方向上每次移动的距离。</p><p>之前，步长被默认为 1。而如果我们设置步长为 2，则卷积过程如下图所示：</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201210105436586.png" srcset="/img/loading.gif" lazyload alt="image-20201210105436586"><figcaption>image-20201210105436586</figcaption></figure><p>设步长为 <span class="math inline">\(s\)</span>，填充长度为 <span class="math inline">\(p\)</span>，输入图片大小为 <span class="math inline">\(n×n\)</span>，滤波器大小为 <span class="math inline">\(f×f\)</span>，则卷积后图片的尺寸为： <span class="math display">\[ \biggl\lfloor \frac{n+2p-f}{s}+1 \biggr\rfloor \times \biggl\lfloor \frac{n+2p-f}{s}+1 \biggr\rfloor \]</span> 注意公式中有一个向下取整的符号，用于处理商不为整数的情况。向下取整反映着当取原始矩阵的图示蓝框完全包括在图像内部时，才对它进行运算。</p><p>目前为止我们学习的“卷积”实际上被称为<strong>互相关（cross-correlation）</strong>，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。</p><h3 id="高维卷积">高维卷积</h3><p>如果我们想要对三通道的 RGB 图片进行卷积运算，那么其对应的滤波器组也同样是三通道的。过程是将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212091752414.png" srcset="/img/loading.gif" lazyload alt="image-20201212091752414"><figcaption>image-20201212091752414</figcaption></figure><p>不同通道的滤波器可以不相同。例如只检测 R 通道的垂直边缘，G 通道和 B 通道不进行边缘检测，则 G 通道和 B 通道的滤波器全部置零。当输入有特定的高、宽和通道数时，滤波器可以有不同的高和宽，但通道数必须和输入一致。</p><p>如果想同时检测垂直和水平边缘，或者更多的边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。设输入图片的尺寸为 <span class="math inline">\(n×n×n_c\)</span>（<span class="math inline">\(n_c\)</span> 为通道数），滤波器尺寸为 <span class="math inline">\(f×f×n_c\)</span>，则卷积后的输出图片尺寸为 <span class="math inline">\((n−f+1)×(n−f+1)×n′_c\)</span>，<span class="math inline">\(n′_c\)</span> 为滤波器组的个数。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212092506485.png" srcset="/img/loading.gif" lazyload alt="image-20201212092506485"><figcaption>image-20201212092506485</figcaption></figure><blockquote><p>举栗：下面的图示显示了包含两个 filter 的卷积层的计算。<span class="math inline">\(7*7*3\)</span> 输入，经过两个 <span class="math inline">\(3*3*3\)</span> filter 的卷积（步幅为 <span class="math inline">\(2\)</span>），得到了 <span class="math inline">\(3*3*2\)</span> 的输出。图中的 Zero padding 是 <span class="math inline">\(1\)</span>，也就是在输入元素的周围补了一圈 <span class="math inline">\(0\)</span>。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212103233564.png" srcset="/img/loading.gif" lazyload alt="image-20201212103233564"><figcaption>image-20201212103233564</figcaption></figure><p>这个就是两个filters，我以目前图中划线的小方块为例。</p><p><span class="math inline">\(x[0] = 1\)</span> ，<span class="math inline">\(x[1]=-1\)</span>，<span class="math inline">\(x[2]=0\)</span>，<span class="math inline">\(bias=1\)</span>，所以加和得<span class="math inline">\(o[0]\)</span> 得第一个位置是 <span class="math inline">\(1\)</span></p></blockquote><h3 id="单层卷积网络">单层卷积网络</h3><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212111708339.png" srcset="/img/loading.gif" lazyload alt="image-20201212111708339"><figcaption>image-20201212111708339</figcaption></figure><p>与之前的卷积过程相比较，卷积神经网络的单层结构多了激活函数和偏移量；而与标准神经网络： <span class="math display">\[ Z^{[l]} = W^{[l]}A^{[l-1]}+b \]</span></p><p><span class="math display">\[ A^{[l]} = g^{[l]}(Z^{[l]}) \]</span></p><p>相比，滤波器的数值对应着权重 <span class="math inline">\(W^{[l]}\)</span>，卷积运算对应着 <span class="math inline">\(W^{[l]}\)</span> 与 <span class="math inline">\(A^{[l−1]}\)</span> 的乘积运算，所选的激活函数变为 ReLU。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212110720587.png" srcset="/img/loading.gif" lazyload alt="image-20201212110720587"><figcaption>image-20201212110720587</figcaption></figure><p>对于一个 3x3x3 的滤波器，包括偏移量 <span class="math inline">\(b\)</span> 在内共有 28 个参数。不论输入的图片有多大，用这一个滤波器来提取特征时，参数始终都是 28 个，固定不变。即<strong>选定滤波器组后，参数的数目与输入图片的尺寸无关</strong>。因此，卷积神经网络的参数相较于标准神经网络来说要少得多。这是 CNN 的优点之一。</p><h4 id="符号总结">符号总结</h4><ul><li><p><strong>输入矩阵</strong>格式：四个维度，依次为：<strong>[样本数、图像高度、图像宽度、图像通道数]</strong></p></li><li><p><strong>输出矩阵</strong>格式：四个维度，依次为：<strong>[样本数、图像高度、图像宽度、图像通道数]</strong>。与输出矩阵的维度顺序和含义相同，但是后三个维度（图像高度、图像宽度、图像通道数）的尺寸发生变化。</p></li><li><p><strong>权重矩阵</strong>（卷积核）格式：同样是四个维度，但维度的含义与上面两者都不同，为：<strong>[卷积核高度、卷积核宽度、输入通道数、输出通道数]</strong>（卷积核个数）</p></li><li><p><strong>输入矩阵、权重矩阵、输出矩阵这三者之间的相互决定关系</strong></p><ul><li><p>输入 x：[batch, height, width, in_channel]</p><p>权重 w：[height, width, in_channel, out_channel]</p><p>输出 y：[batch, height, width, out_channel]</p></li><li><p>卷积核的输入通道数（in depth）由输入矩阵的通道数所决定。（红色标注）</p></li><li><p>输出矩阵的通道数（out depth）由卷积核的输出通道数所决定。（绿色标注）</p></li><li><p>输出矩阵的高度和宽度（height, width）这两个维度的尺寸由输入矩阵、卷积核、扫描方式所共同决定。计算公式如下。（蓝色标注）</p></li></ul></li></ul><p><span class="math display">\[ n^{[l]}_H = \biggl\lfloor \frac{n^{[l-1]}_H+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \biggr\rfloor \]</span></p><p><span class="math display">\[ n^{[l]}_W = \biggl\lfloor \frac{n^{[l-1]}_W+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \biggr\rfloor \]</span></p><blockquote><p>以 AlexNet 模型的第一个卷积层为例，</p><ul><li>输入图片的尺寸统一为 227 x 227 x 3 （高度 x 宽度 x 颜色通道数），</li><li>本层一共具有96个卷积核，</li><li>每个卷积核的尺寸都是 11 x 11 x 3。</li><li>已知 stride = 4， padding = 0，</li><li>假设 batch_size = 256，</li><li>则输出矩阵的高度/宽度为 (227 - 11) / 4 + 1 = 55</li></ul><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212160525312.png" srcset="/img/loading.gif" lazyload alt="image-20201212160525312"><figcaption>image-20201212160525312</figcaption></figure></blockquote><blockquote><p>后期 GoogLeNet、ResNet 等经典模型中普遍使用一个像素大小的卷积核作为降低参数复杂度的手段。</p><p>从下面的运算可以看到，其实 1 x 1 卷积没有什么神秘的，其作用就是将输入矩阵的通道数量缩减后输出（512 降为 32），并保持它在宽度和高度维度上的尺寸（227 x 227）。</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212160640410.png" srcset="/img/loading.gif" lazyload alt="image-20201212160640410"><figcaption>image-20201212160640410</figcaption></figure></blockquote><p>总结下来，其实只需要认识到，虽然输入的每一张图像本身具有三个维度，但是对于卷积核来讲依然只是一个一维向量。卷积核做的，其实就是与感受野范围内的像素点进行点积（而不是矩阵乘法）。</p><table><thead><tr class="header"><th style="text-align:center"></th><th style="text-align:center">Batch</th><th style="text-align:center">Height</th><th style="text-align:center">Width</th><th style="text-align:center">In Depth</th><th style="text-align:center">Out Depth</th></tr></thead><tbody><tr class="odd"><td style="text-align:center">输入 x</td><td style="text-align:center">batch</td><td style="text-align:center">height</td><td style="text-align:center">width</td><td style="text-align:center">in_channel</td><td style="text-align:center"></td></tr><tr class="even"><td style="text-align:center">权重 w</td><td style="text-align:center"></td><td style="text-align:center">height</td><td style="text-align:center">width</td><td style="text-align:center">in_channel</td><td style="text-align:center">out_channel</td></tr><tr class="odd"><td style="text-align:center">输出 y</td><td style="text-align:center">batch</td><td style="text-align:center">height</td><td style="text-align:center">width</td><td style="text-align:center"></td><td style="text-align:center">out_channel</td></tr></tbody></table><h3 id="简单卷积网络实例">简单卷积网络实例</h3><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212163528828.png" srcset="/img/loading.gif" lazyload alt="image-20201212163528828"><figcaption>image-20201212163528828</figcaption></figure><p>其中，<span class="math inline">\(a^{[3]}\)</span> 的维度为 7x7x40，将 1960 个特征平滑展开成 1960 个单元的一列，然后连接最后一级的输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出 <span class="math inline">\(\hat{y}\)</span>。</p><p>随着神经网络计算深度不断加深，图片的高度和宽度 <span class="math inline">\(n^{[l]}_H\)</span>、<span class="math inline">\(n^{[l]}_W\)</span> 一般逐渐减小，而 <span class="math inline">\(n^{[l]}_c\)</span> 在增加。</p><p>一个典型的卷积神经网络通常包含有三种层：<strong>卷积层（Convolution layer）</strong>、<strong>池化层（Pooling layer）</strong>、<strong>全连接层（Fully Connected layer）</strong>。仅用卷积层也有可能构建出很好的神经网络，但大部分神经网络还是会添加池化层和全连接层，它们更容易设计。</p><h3 id="池化层">池化层</h3><p><strong>池化层</strong>的作用是缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。</p><p>采用较多的一种池化过程叫做<strong>最大池化（Max Pooling）</strong>。将输入拆分成不同的区域，输出的每个元素都是对应区域中元素的最大值，如下图所示：</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212223919692.png" srcset="/img/loading.gif" lazyload alt="image-20201212223919692"><figcaption>image-20201212223919692</figcaption></figure><p>池化过程类似于卷积过程，上图所示的池化过程中相当于使用了一个大小 <span class="math inline">\(f=2\)</span> 的滤波器，且池化步长 <span class="math inline">\(s=2\)</span>。卷积过程中的几个计算大小的公式也都适用于池化过程。如果有多个通道，那么就对每个通道分别执行计算过程。</p><p>对最大池化的一种直观解释是，元素值较大可能意味着池化过程之前的卷积过程提取到了某些特定的特征，池化过程中的最大化操作使得只要在一个区域内提取到某个特征，它都会保留在最大池化的输出中。但是，没有足够的证据证明这种直观解释的正确性，而最大池化被使用的主要原因是它在很多实验中的效果都很好。</p><p>另一种池化过程是<strong>平均池化（Average Pooling）</strong>，就是从取某个区域的最大值改为求这个区域的平均值：</p><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212230108937.png" srcset="/img/loading.gif" lazyload alt="image-20201212230108937"><figcaption>image-20201212230108937</figcaption></figure><p>池化过程的特点之一是，它有一组超参数，但是并<strong>没有参数需要学习</strong>。池化过程的超参数包括滤波器的大小 <span class="math inline">\(f\)</span>、步长 <span class="math inline">\(s\)</span>，以及选用最大池化还是平均池化。而填充 <span class="math inline">\(p\)</span> 则很少用到。</p><p>池化过程的输入维度为： <span class="math display">\[ n_H \times n_W \times n_c \]</span> 输出维度为： <span class="math display">\[ \biggl\lfloor \frac{n_H-f}{s}+1 \biggr\rfloor \times \biggl\lfloor \frac{n_W-f}{s}+1 \biggr\rfloor \times n_c \]</span></p><h3 id="卷积神经网络实例">卷积神经网络实例</h3><figure><img data-src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201212231101805.png" srcset="/img/loading.gif" lazyload alt="image-20201212231101805"><figcaption>image-20201212231101805</figcaption></figure><p>在计算神经网络的层数时，通常只统计具有权重和参数的层，因此池化层通常和之前的卷积层共同计为一层。</p><table><thead><tr class="header"><th style="text-align:center"></th><th style="text-align:center">Activation shape</th><th style="text-align:center">Activation Size</th><th style="text-align:center">#parameters</th></tr></thead><tbody><tr class="odd"><td style="text-align:center"><strong>Input</strong></td><td style="text-align:center">(32, 32, 3)</td><td style="text-align:center">3072</td><td style="text-align:center">0</td></tr><tr class="even"><td style="text-align:center"><strong>CONV1(f=5, s=1)</strong></td><td style="text-align:center">(28, 28, 6)</td><td style="text-align:center">4704</td><td style="text-align:center">158</td></tr><tr class="odd"><td style="text-align:center"><strong>POOL1</strong></td><td style="text-align:center">(14, 14, 6)</td><td style="text-align:center">1176</td><td style="text-align:center">0</td></tr><tr class="even"><td style="text-align:center"><strong>CONV2(f=5, s=1)</strong></td><td style="text-align:center">(10, 10, 16)</td><td style="text-align:center">1600</td><td style="text-align:center">416</td></tr><tr class="odd"><td style="text-align:center"><strong>FC3</strong></td><td style="text-align:center">(120, 1)</td><td style="text-align:center">120</td><td style="text-align:center">48120</td></tr><tr class="even"><td style="text-align:center"><strong>FC4</strong></td><td style="text-align:center">(84, 1)</td><td style="text-align:center">84</td><td style="text-align:center">10164</td></tr><tr class="odd"><td style="text-align:center"><strong>Softmax</strong></td><td style="text-align:center">(10, 1)</td><td style="text-align:center">10</td><td style="text-align:center">850</td></tr></tbody></table><p>个人推荐<a target="_blank" rel="noopener" href="http://scs.ryerson.ca/~aharley/vis/conv/">一个直观感受卷积神经网络的网站</a>。</p><h3 id="使用卷积的原因">使用卷积的原因</h3><p>相比标准神经网络，对于大量的输入数据，卷积过程有效地减少了 CNN 的参数数量，原因有以下两点：</p><ul><li><strong>参数共享（Parameter sharing）</strong>：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。</li><li><strong>稀疏连接（Sparsity of connections）</strong>：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。</li></ul><p>池化过程则在卷积后很好地聚合了特征，通过降维来减少运算量。</p><p>由于 CNN 参数数量较小，所需的训练样本就相对较少，因此在一定程度上不容易发生过拟合现象。并且 CNN 比较擅长捕捉区域位置偏移。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的健壮性。</p><h2 id="深度卷积网络实例探究">深度卷积网络：实例探究</h2><p>讲到的经典 CNN 模型包括：</p><ul><li>LeNet-5</li><li>AlexNet</li><li>VGG</li><li>ResNet（Residual Network，残差网络）</li><li>Inception Neural Network。</li></ul><p>详细介绍请看这篇 <a href="https://stuxiaozhang.github.io/2020/12/15/%E3%80%8A%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E3%80%8B/">《经典卷积神经网络》</a>。</p><h3 id="使用开源的实现方案">使用开源的实现方案</h3><p>很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。</p><h3 id="迁移学习">迁移学习</h3><p>在“搭建机器学习项目”课程中，迁移学习已经被提到过。计算机视觉是一个经常用到迁移学习的领域。在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做<strong>预训练</strong>，然后转换到自己感兴趣的任务上，有助于加速开发。</p><p>对于已训练好的卷积神经网络，可以将所有层都看作是<strong>冻结的</strong>，只需要训练与你的 Softmax 层有关的参数即可。大多数深度学习框架都允许用户指定是否训练特定层的权重。</p><p>而冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。</p><p>上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。</p><h3 id="数据扩增">数据扩增</h3><p>计算机视觉领域的应用都需要大量的数据。当数据不够时，<strong>数据扩增（Data Augmentation）</strong>就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。</p><p>其中，色彩转换是对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。另外，<strong>PCA 颜色增强</strong>指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。具体的 PCA 颜色增强做法可以查阅 AlexNet 的相关论文或者开源代码。</p><p>在构建大型神经网络的时候，数据扩增和模型训练可以由两个或多个不同的线程并行来实现。</p><h3 id="计算机视觉现状">计算机视觉现状</h3><p>通常，学习算法有两种知识来源：</p><ul><li>被标记的数据</li><li>手工工程</li></ul><p><strong>手工工程（Hand-engineering，又称 hacks）</strong>指精心设计的特性、网络体系结构或是系统的其他组件。手工工程是一项非常重要也比较困难的工作。在数据量不多的情况下，手工工程是获得良好表现的最佳方式。正因为数据量不能满足需要，历史上计算机视觉领域更多地依赖于手工工程。近几年数据量急剧增加，因此手工工程量大幅减少。</p><p>另外，在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：</p><ul><li>集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出</li><li>Multi-crop at test time：将数据扩增应用到测试集，对结果进行平均</li></ul><p>但是由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。</p><p>（当完成目标检测相关论文阅读后，再来继续学习）</p><h2 id="目标检测">目标检测</h2><p>目标检测是计算机视觉领域中一个新兴的应用方向，其任务是对输入图像进行分类的同时，检测图像中是否包含某些目标，并对他们准确定位并标识。</p><h3 id="目标定位">目标定位</h3><h2 id="特殊应用人脸识别和神经风格迁移">特殊应用：人脸识别和神经风格迁移</h2></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> <a class="hover-with-bg" href="/tags/CNN/">CNN</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a><br>转载请注明出处来源：<a href="https://stuxiaozhang.github.io">小张的宇宙空间站</a> ！</p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2020/12/15/%E3%80%8A%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E3%80%8B/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">《经典卷积神经网络》</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2020/11/23/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B03/"><span class="hidden-mobile">《深度学习》课程笔记3_搭建机器学习项目</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.staticfile.org/valine/1.4.14/Valine.min.js",function(){var i=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论我鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:null,emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"],appid:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appkey:"CgnvRL262D07ied40NiXm2VL"},{el:"#valine",path:window.location.pathname});new Valine(i)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>