<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="搭建机器学习项目
机器学习（ML）策略（1）
对于一个已经被构建好且产生初步结果的机器学习系统，为了能使结果更令人满意，往往还要进行大量的改进。鉴于之前的课程介绍了多种改进的方法，例如收集更多数据、调试超参数、调整神经网络的大小或结构、采用不同的优化算法、进行正则化等等，我们有可能浪费大量时间在一条错误的改进路线上。
想要找准改进的方向，使一个机器学习系统更快更有效地工作，就需要学习一些在构"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>《深度学习》课程笔记3_搭建机器学习项目 - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="《深度学习》课程笔记3_搭建机器学习项目"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2020-11-23 15:51" pubdate>2020年11月23日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 7.2k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 93 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">《深度学习》课程笔记3_搭建机器学习项目</h1><p class="note note-info">本文最后更新于：2021年1月2日</p><div class="markdown-body"><h1 id="搭建机器学习项目">搭建机器学习项目</h1><h2 id="机器学习ml策略1">机器学习（ML）策略（1）</h2><p>对于一个已经被构建好且产生初步结果的机器学习系统，为了能使结果更令人满意，往往还要进行大量的改进。鉴于之前的课程介绍了多种改进的方法，例如收集更多数据、调试超参数、调整神经网络的大小或结构、采用不同的优化算法、进行正则化等等，我们有可能浪费大量时间在一条错误的改进路线上。</p><p>想要找准改进的方向，使一个机器学习系统更快更有效地工作，就需要学习一些在构建机器学习系统时常用到的策略。</p><h3 id="正交化">正交化</h3><p><strong>正交化（Orthogonalization）</strong>的核心在于<strong>每次调整只会影响模型某一方面的性能，而对其他功能没有影响</strong>。这种方法有助于更快更有效地进行机器学习模型的调试和优化。</p><p>在机器学习（监督学习）系统中，可以划分四个“功能”：</p><ol type="1"><li>建立的模型在训练集上表现良好；</li><li>建立的模型在验证集上表现良好；</li><li>建立的模型在测试集上表现良好；</li><li>建立的模型在实际应用中表现良好。</li></ol><p>其中，</p><ul><li>对于第一条，如果模型在训练集上表现不好，可以尝试<strong>训练更大的神经网络</strong>或者<strong>换一种更好的优化算法（例如 Adam）</strong>；</li><li>对于第二条，如果模型在验证集上表现不好，可以进行<strong>正则化处理</strong>或者<strong>加入更多训练数据</strong>；</li><li>对于第三条，如果模型在测试集上表现不好，可以尝试<strong>使用更大的验证集</strong>进行验证；</li><li>对于第四条，如果模型在实际应用中表现不好，可能是因为<strong>测试集没有设置正确</strong>或者<strong>成本函数评估指标有误，需要改变测试集或成本函数</strong>。</li></ul><p>面对遇到的各种问题，正交化能够帮助我们更为精准有效地解决问题。</p><p>一个反例是早停止法（Early Stopping）。如果早期停止，虽然可以改善验证集的拟合表现，但是对训练集的拟合就不太好。因为对两个不同的“功能”都有影响，所以早停止法不具有正交化。虽然也可以使用，但是用其他正交化控制手段来进行优化会更简单有效。</p><h3 id="单值评价指标">单值评价指标</h3><p>构建机器学习系统时，通过设置一个量化的<strong>单值评价指标</strong>（single-number evaluation metric），可以使我们根据这一指标比较不同超参数对应的模型的优劣，从而选择最优的那个模型。</p><p>例如，对于二分类问题，常用的评价指标是<strong>查准率</strong>（Precision）和<strong>查全率（Recall）</strong>。</p><p>首先：</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201124093957384.png" srcset="/img/loading.gif" lazyload alt="image-20201124093957384"><figcaption>image-20201124093957384</figcaption></figure><table><tbody><tr class="odd"><td>True Positives（TP）</td><td>False Positives（FP）</td></tr><tr class="even"><td>True Negatives（TN）</td><td>False Negatives（FN）</td></tr></tbody></table><ul><li>TP的英文全称为True Positives，其指的是<strong>被分配为正样本，而且分配对了</strong>的样本，代表的是<strong>被正确分类的正样本</strong>。</li><li>TN的英文全称为True Negatives，其指的是<strong>被分配为负样本，而且分配对了</strong>的样本，代表的是<strong>被正确分类的负样本</strong>。</li><li>FP的英文全称为False Positives，其指的是<strong>被分配为正样本，但分配错了</strong>的样本，代表的是<strong>被错误分类的负样本</strong>。</li><li>FN的英文全称为False Negatives，其指的是<strong>被分配为负样本，但分配错了</strong>的样本，代表的是<strong>被错误分类的正样本</strong>。</li></ul><blockquote><p>True：看作是正确</p><p>Positive：看作是正</p></blockquote><div class="note note-warning"><ul><li><span class="math inline">\(查准率=\frac{分类器认为是正类并且确实是正类的部分}{分类器认为是正类}=\frac{TP}{TP+FP}\)</span></li><li><span class="math inline">\(查全率=\frac{分类器认为是正类并且确实是正类的部分}{确实是正类}=\frac{TP}{TP+FN}\)</span></li></ul></div><p>接下来，</p><p>假设我们有 A 和 B 两个分类器，其两项指标分别如下：</p><table><thead><tr class="header"><th>分类器</th><th>查准率（Precision）</th><th>查全率（Recall）</th></tr></thead><tbody><tr class="odd"><td>A</td><td>95%</td><td>90%</td></tr><tr class="even"><td>B</td><td>98%</td><td>85%</td></tr></tbody></table><p>实际应用中，我们通常使用综合了精确率和召回率的单值评价指标 <strong>F1 Score</strong> 来评价模型的好坏。F1 Score 其实就是精准率和召回率的<strong>调和平均数（Harmonic Mean）</strong>，比单纯的平均数效果要好。 <span class="math display">\[ F_1 = \frac{2}{\frac{1}{P}+\frac{1}{R}} = \frac{2PR}{P+R} \]</span> 因此，我们计算出两个分类器的 F1 Score。可以看出 A 模型的效果要更好。</p><table><thead><tr class="header"><th>分类器</th><th>精确率</th><th>召回率</th><th>F1 Score</th></tr></thead><tbody><tr class="odd"><td>A</td><td>95%</td><td>90%</td><td>92.4%</td></tr><tr class="even"><td>B</td><td>98%</td><td>85%</td><td>91.0%</td></tr></tbody></table><p>通过引入单值评价指标，我们可以更方便快速地对不同模型进行比较。</p><p>举栗：假如某个班级有男生<strong>80</strong>人，女生<strong>20</strong>人，共计<strong>100</strong>人。目标是找出所有女生. 现在某人挑选出<strong>50</strong>个人,其中<strong>20</strong>人是女生,另外还错误的把<strong>30</strong>个男生也当作女生挑选出来了. 作为评估者的你需要来评估(<strong>evaluation</strong>)下他的工作。</p><p><strong>答：</strong>假设女生是正样本，则男生是负样本。题中表明目的是选出所有女生，即一共挑选的50人它都以为是女生（正样本），而剩下的50人就被认定成男生（负样本）。其中20个女生是分类正确的正样本，30个是分类错误的正样本。进而得到，剩下的50个男生本来就是男生，即分类正确的负样本为50，分类错误的负样本为0，如下图所示：</p><table><thead><tr class="header"><th></th><th>正样本 Positive （女）</th><th>负样本 Negative （男）</th><th></th></tr></thead><tbody><tr class="odd"><td>分类正确 True</td><td>（True Positive） 20</td><td>（True Negative）50</td><td>20</td></tr><tr class="even"><td>分类错误 False</td><td>（False Negative）30</td><td>（False Negative）0</td><td>80</td></tr><tr class="odd"><td></td><td>50</td><td>50</td><td>100</td></tr></tbody></table><p>可以评估他的工作：</p><ul><li>查准率 <span class="math inline">\(P=\frac{TP}{TP+FP}=40\%\)</span></li><li>查全率 <span class="math inline">\(R=\frac{TP}{TP+FN}=100\%\)</span></li><li><span class="math inline">\(F_1=\frac{2PR}{P+R} = 57.1\%\)</span></li></ul><h3 id="优化指标和满足指标">优化指标和满足指标</h3><p>如果我们还想要将分类器的运行时间也纳入考虑范围，将其和精确率、召回率组合成一个单值评价指标显然不那么合适。</p><p>这时，我们可以将某些指标作为<strong>优化指标（Optimizing Matric）</strong>，寻求它们的最优值；而将某些指标作为<strong>满足指标（Satisficing Matric）</strong>，只要在一定阈值以内即可。</p><p>比如，你要考虑 N 个指标，有时候选择其中一个指标作为优化指标是合理的。所以想尽可能地去优化那个指标，然后剩下 N-1 个指标都是满足指标，意味着只要他么达到一定阈值之后，就不必在乎过了那个门槛之后的表现，去看优化指标就行。但是首先他们必须要达到这个门槛。</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201204154310114.png" srcset="/img/loading.gif" lazyload alt="image-20201204154310114"><figcaption>image-20201204154310114</figcaption></figure><p>在这个例子中，准确率就是一个优化指标，因为我们想要分类器尽可能做到正确分类；而运行时间就是一个满足指标，如果你想要分类器的运行时间不多于某个阈值，那最终选择的分类器就应该是以这个阈值为界里面准确率最高的那个，即为 B 。</p><h3 id="动态改变评价指标">动态改变评价指标</h3><p>对于模型的评价标准优势需要根据实际情况进行动态调整，以让模型在实际应用中获得更好的效果。</p><p>例如，有时我们不太能接受某些分类错误，于是改变单纯用错误率作为评价标准，给某些分类错误更高的权重，以从追求最小错误率转为追求最小风险。</p><h3 id="训练验证测试集划分">训练/验证/测试集划分</h3><p>我们一般将数据集分为训练集、验证集、测试集。构建机器学习系统时，我们采用不同的学习方法，在<strong>训练集</strong>上训练出不同的模型，然后使用<strong>验证集</strong>对模型的好坏进行评估，确信其中某个模型足够好时再用<strong>测试集</strong>对其进行测试。</p><p>因此，训练集、验证集、测试集的设置对于机器学习模型非常重要，合理的设置能够大大提高模型训练效率和模型质量。</p><h4 id="验证集和测试集的分布">验证集和测试集的分布</h4><p>验证集和测试集的数据来源应该相同（来自同一分布）、和机器学习系统将要在实际应用中面对的数据一致，且必须从所有数据中随机抽取。这样，系统才能做到尽可能不偏离目标。</p><blockquote><p>即 “瞄准一个目标”</p></blockquote><h4 id="验证集和测试集的大小">验证集和测试集的大小</h4><p>过去数据量较小（小于 1 万）时，通常将数据集按照以下比例进行划分：</p><ul><li>无验证集的情况：70% / 30%；</li><li>有验证集的情况：60% / 20% / 20%；</li></ul><p>这是为了保证验证集和测试集有足够的数据。现在的机器学习时代数据集规模普遍较大，例如 100 万数据量，这时将相应比例设为 98% / 1% / 1% 或 99% / 1% 就已经能保证验证集和测试集的规模足够。</p><p>测试集的大小应该设置得足够提高系统整体性能的可信度，验证集的大小也要设置得足够用于评估几个不同的模型。应该根据实际情况对数据集灵活地进行划分，而不是死板地遵循老旧的经验。</p><h3 id="比较人类表现水平">比较人类表现水平</h3><p>很多机器学习模型的诞生是为了取代人类的工作，因此其表现也会跟人类表现水平作比较。</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201204160303692.png" srcset="/img/loading.gif" lazyload alt="image-20201204160303692"><figcaption>image-20201204160303692</figcaption></figure><p>上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为<strong>贝叶斯最优误差（Bayes Optimal Error）</strong>。</p><p>贝叶斯最优误差一般认为是理论上可能达到的最优误差，换句话说，其就是理论最优函数，任何从 x 到精确度 y 映射的函数都不可能超过这个值。例如，对于语音识别，某些音频片段嘈杂到基本不可能知道说的是什么，所以完美的识别率不可能达到 100%。</p><p>因为人类对于一些自然感知问题的表现水平十分接近贝叶斯最优误差，所以当机器学习系统的表现超过人类后，就没有太多继续改善的空间了。</p><p>也因此，只要建立的机器学习模型的表现还没达到人类的表现水平时，就可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行偏差、方差分析。</p><p>当模型的表现超过人类后，这些手段起的作用就微乎其微了。</p><h4 id="可避免偏差">可避免偏差</h4><p>通过与贝叶斯最优误差，或者说，与人类表现水平的比较，可以表明一个机器学习模型表现的好坏程度，由此判断后续操作应该注重于减小偏差还是减小方差。</p><p>模型在<strong>训练集</strong>上的误差与人类表现水平<strong>（贝叶斯错误率）</strong>的<strong>差值</strong>被称作<strong>可避免偏差（Avoidable Bias）</strong>。可避免偏差低便意味着模型在训练集上的表现很好，而<strong>训练集与验证集之间错误率的差值</strong>越小，意味着模型在验证集与测试集上的表现和训练集同样好。</p><p>如果<strong>可避免偏差</strong>大于<strong>训练集与验证集之间错误率的差值</strong>，之后的工作就应该专注于减小偏差；反之，就应该专注于减小方差。</p><h4 id="理解人类表现水平">理解人类表现水平</h4><p>我们一般用<strong>人类水平误差（Human-level Error）</strong>来代表贝叶斯最优误差（或者简称贝叶斯误差）。对于不同领域的例子，不同人群由于其经验水平不一，错误率也不同。一般来说，<strong>我们将表现最好的作为人类水平误差</strong>。但是实际应用中，不同人选择人类水平误差的基准是不同的，这会带来一定的影响。</p><p>例如，如果某模型在训练集上的错误率为 8%，验证集的错误率为 10%。如果选择的人类水平误差为 1%，那么应该专注减少偏差；而如果选择的人类水平误差为 7.5%，则应该专注减少方差。也就是说，根据人类水平误差的不同选择，我们可能因此选择不同的优化操作。</p><p>这种问题只会发生在模型表现很好，接近人类水平误差的时候才会出现。人类水平误差给了我们一种估计贝叶斯误差的方式，而不是像之前一样将训练的错误率直接对着 0% 的方向进行优化。</p><p>当机器学习模型的表现超过了人类水平误差时，很难再通过人的直觉去判断模型还能够往什么方向优化以提高性能。</p><h3 id="总结">总结</h3><p>想让一个监督学习算法达到使用程度，应该做到以下两点：</p><ol type="1"><li>算法对训练集的拟合很好，可以看作可避免偏差很低；</li><li>推广到验证集和测试集效果也很好，即方差不是很大。</li></ol><p>根据正交化的思想，我们有一些措施可以独立地优化二者之一。</p><h2 id="机器学习ml策略2">机器学习（ML）策略（2）</h2><h3 id="错误分析">错误分析</h3><p>通过人工检查机器学习模型得出的结果中出现的一些错误，有助于深入了解下一步要进行的工作。这个过程被称作<strong>错误分析（Error Analysis）</strong>。</p><p>例如，你可能会发现一个猫图片识别器错误地将一些看上去像猫的狗误识别为猫。这时，立即盲目地去研究一个能够精确识别出狗的算法不一定是最好的选择，因为我们不知道这样做会对提高分类器的准确率有多大的帮助。</p><p>这时，我们可以从分类错误的样本中统计出狗的样本数量。根据狗样本所占的比重来判断这一问题的重要性。假如狗类样本所占比重仅为 5%，那么即使花费几个月的时间来提升模型对狗的识别率，改进后的模型错误率并没有显著改善；而如果错误样本中狗类所占比重为 50%，那么改进后的模型性能会有较大的提升。因此，花费更多的时间去研究能够精确识别出狗的算法是值得的。</p><p>这种人工检查看似简单而愚笨，但却是十分必要的，因为这项工作能够有效避免花费大量的时间与精力去做一些对提高模型性能收效甚微的工作，让我们专注于解决影响模型准确率的主要问题。</p><p>在对输出结果中分类错误的样本进行人工分析时，可以建立一个表格来记录每一个分类错误的具体信息，例如某些图像是模糊的，或者是把狗识别成了猫等，并统计属于不同错误类型的错误数量。这样，分类结果会更加清晰。</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201204205644683.png" srcset="/img/loading.gif" lazyload alt="image-20201204205644683"><figcaption>image-20201204205644683</figcaption></figure><p>总结一下，进行错误分析时，你应该观察错误标记的例子，看看假阳性(False Positive)和假阴性(False Negative)，统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的错误类型。总之，通过统计不同错误标记类型占总数的百分比，有助于发现哪些问题亟待解决，或者提供构思新优化方向的灵感。</p><h3 id="修正错误标记">修正错误标记</h3><p>我们用 mislabeled examples 来表示学习算法输出了错误的 Y 值。而在做误差分析时，有时会注意到数据集中有些样本被人为地错误标记（incorrectly labeled）了，这时该怎么做？</p><p>如果是在训练集中，由于机器学习算法对于随机误差的<strong>稳健性（Robust）</strong>（也称作“鲁棒性”），只要这些出错的样本数量较小，且分布近似随机，就不必花费时间一一修正。</p><p>而如果出现在验证集或者测试集，则可以在进行误差分析时，通过统计人为标记错误所占的百分比，来大致分析这种情况对模型的识别准确率的影响，并比较该比例的大小和其他错误类型的比例，以此判断是否值得去将错误的标记一一进行修正，还是可以忽略。</p><p>当你决定在验证集和测试集上手动检查标签并进行修正时，有一些额外的方针和原则需要考虑：</p><ul><li>在验证集和测试集上<strong>同时使用同样的修正手段</strong>，以保证验证集和测试集来自相同的分布；</li><li>同时检查判断正确和判断错误的例子（通常不用这么做）；</li><li>在修正验证集和测试集时，鉴于训练集的分布不必和验证/测试集完全相同，可以不去修正训练集。</li></ul><h3 id="快读搭建系统并迭代">快读搭建系统并迭代</h3><p>对于每个可以改善模型的合理方向，如何选择一个方向集中精力处理成了问题。如果想搭建一个全新的机器学习系统，建议根据以下步骤快速搭建好第一个系统，然后开始迭代：</p><ol type="1"><li>设置好训练、验证、测试集及衡量指标，确定目标；</li><li>快速训练出一个初步的系统，用训练集来拟合参数，用验证集调参，用测试集评估；</li><li>通过偏差/方差分析以及错误分析等方法，决定下一步优先处理的方向。</li></ol><h3 id="在不同的分布上训练和测试">在不同的分布上训练和测试</h3><p>有时，我们很难得到来自同一个分布的训练集和验证/测试集。还是以猫识别作为例子，我们的训练集可能由网络爬取得到，图片比较清晰，而且规模较大（例如 20 万）；而验证/测试集可能来自用户手机拍摄，图片比较模糊，且数量较少（例如 1 万），难以满足作为训练集时的规模需要。</p><p>虽然验证/测试集的质量不高，但是机器学习模型最终主要应用于识别这些用户上传的模糊图片。考虑到这一点，在划分数据集时，可以将 20 万张网络爬取的图片和 5000 张用户上传的图片作为训练集，而将剩下的 5000 张图片一半作验证集，一半作测试集。比起混合数据集所有样本再随机划分，这种分配方法虽然使训练集分布和验证/测试集的分布并不一样，但是能保证<strong>验证/测试集更接近实际应用场景</strong>，在长期能带来更好的系统性能。</p><h3 id="数据不匹配">==数据不匹配==</h3><p>之前的学习中，我们通过比较人类水平误差、训练集错误率、验证集错误率的相对差值来判断进行偏差/方差分析。但在训练集和验证/测试集分布不一致的情况下，无法根据相对差值来进行偏差/方差分析。这是因为训练集错误率和验证集错误率的差值<u>可能来自于算法本身（归为方差）</u>，也<u>可能来自于样本分布不同，和模型关系不大</u>。</p><p>在可能存在训练集和验证/测试集分布不一致的情况下，为了解决这个问题，我们可以再定义一个<strong>训练-验证集（Training-dev Set）</strong>。训练-验证集和训练集的分布相同（或者是训练集分割出的子集），但是不参与训练过程。</p><p>现在，我们有了 <em>训练集</em> 错误率、 <em>训练-验证集</em> 错误率，以及 <em>验证集</em> 错误率。其中， <em>训练集</em> 错误率和 <em>训练-验证集</em> 错误率的差值反映了方差；而 <em>训练-验证集</em> 错误率和 <em>验证集</em> 错误率的差值反映了样本分布不一致的问题，从而说明<strong>模型擅长处理的数据和我们关心的数据来自不同的分布</strong>，我们称之为<strong>数据不匹配（Data Mismatch）</strong>问题。</p><p>人类水平误差、<em>训练集</em>错误率、<em>训练-验证集</em>错误率、<em>验证集</em>错误率、<em>测试集</em>错误率之间的差值所反映的问题如下图所示：</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201205104721879.png" srcset="/img/loading.gif" lazyload alt="image-20201205104721879"><figcaption>image-20201205104721879</figcaption></figure><h4 id="处理方法">处理方法</h4><p>这里有两条关于如何解决数据不匹配问题的建议：</p><ul><li>做错误分析，尝试了解训练集和验证/测试集的具体差异（主要是人工查看训练集和验证集的样本）；</li><li>尝试将训练数据调整得更像验证集，或者收集更多类似于验证/测试集的数据。</li></ul><p>如果你打算将训练数据调整得更像验证集，可以使用的一种技术是<strong>人工合成数据</strong>。我们以语音识别问题为例，实际应用场合（验证/测试集）是包含背景噪声的，而作为训练样本的音频很可能是清晰而没有背景噪声的。为了让训练集与验证/测试集分布一致，我们可以给训练集人工添加背景噪声，合成类似实际场景的声音。</p><p>人工合成数据能够使数据集匹配，从而提升模型的效果。但需要注意的是，不能给每段语音都增加同一段背景噪声，因为这样模型会对这段背景噪音出现过拟合现象，使得效果不佳。</p><h3 id="迁移学习">迁移学习</h3><p><strong>迁移学习（Transfer Learning）</strong>是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。</p><p>例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数（<span class="math inline">\(W^{[L]}\)</span>、<span class="math inline">\(b^{[L]}\)</span>），随后用新的训练集进行训练，就完成了以上的迁移学习。</p><p>如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即 <span class="math inline">\(W^{[L]}\)</span>、<span class="math inline">\(b^{[L]}\)</span>，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为<strong>预训练（Pre-Training）</strong>，之后的权重更新过程称为<strong>微调（Fine-Tuning）</strong>。</p><p>你也可以不止加入一个新的输出层，而是多向神经网络加几个新层。</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201204213709492.png" srcset="/img/loading.gif" lazyload alt="image-20201204213709492"><figcaption>image-20201204213709492</figcaption></figure><p>在下述场合进行迁移学习是有意义的：</p><ol type="1"><li>两个任务有同样的输入（比如都是图像或者都是音频）；</li><li><strong>拥有更多数据的任务迁移到数据较少的任务</strong>；</li><li>某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。</li></ol><h3 id="多任务学习">多任务学习</h3><p>迁移学习中的步骤是串行的；而<strong>多任务学习（Multi-Task Learning）</strong>使用单个神经网络模型，利用共享表示采用并行训练同时学习多个任务。多任务学习的基本假设是<strong>多个任务之间具有相关性</strong>，并且任务之间可以利用相关性相互促进。例如，属性分类中，抹口红和戴耳环有一定的相关性，单独训练的时候是无法利用这些信息，多任务学习则可以利用任务相关性联合提高多个属性分类的精度。</p><p>以汽车自动驾驶为例，需要实现的多任务是识别行人、车辆、交通标志和信号灯。如果在输入的图像中检测出车辆和交通标志，则输出的 y 为： <span class="math display">\[ y = \begin{bmatrix} 0 \\ 1 \\ 1 \\ 0 \end{bmatrix}\quad \]</span></p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201205115842523.png" srcset="/img/loading.gif" lazyload alt="image-20201205115842523"><figcaption>image-20201205115842523</figcaption></figure><p>多任务学习模型的成本函数为： <span class="math display">\[ \frac{1}{m} \sum^m_{i=1} \sum^c_{j=1} L(\hat y_j^{(i)}, y_j^{(i)}) \]</span> 其中，j 代表任务下标，总有 c 个任务。对应的损失函数为： <span class="math display">\[ L(\hat y_j^{(i)}, y_j^{(i)}) = -y_j^{(i)} log \hat y_j^{(i)} - (1 -y_j^{(i)})log(1 - \hat y_j^{(i)}) \]</span> 多任务学习是使用单个神经网络模型来实现多个任务。实际上，也可以分别构建多个神经网络来实现。多任务学习中可能存在训练样本 Y 某些标签空白的情况，这不会影响多任务学习模型的训练。</p><p>多任务学习和 Softmax 回归看上去有些类似，容易混淆。它们的区别是，Softmax 回归的输出向量 y 中只有一个元素为 1；而多任务学习的输出向量 y 中可以有多个元素为 1。</p><blockquote><p>例如一个图像多个标签。</p></blockquote><p>在下述场合进行多任务学习是有意义的：</p><ol type="1"><li>训练的一组任务可以共用低层次特征；</li><li><em>通常</em>，每个任务的数据量接近；</li><li>能够训练一个足够大的神经网络，以同时做好所有的工作。多任务学习会降低性能的唯一情况（即和为每个任务训练单个神经网络相比性能更低的情况）是神经网络还不够大。</li></ol><p>在多任务深度网络中，低层次信息的共享有助于减少计算量，同时共享表示层可以使得几个有共性的任务更好的结合相关性信息，任务特定层则可以单独建模任务特定的信息，实现共享信息和任务特定信息的统一。</p><p>在实践中，多任务学习的使用频率要远低于迁移学习。计算机视觉领域中的物体识别是一个多任务学习的例子hh。</p><h3 id="端到端学习">端到端学习</h3><p>在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而<strong>端到端深度学习（End-to-end Deep Learning）</strong>只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。</p><p>如果数据量较少，传统机器学习分块模型所构成的流水线效果会很不错。但如果训练样本足够大，并且训练出的神经网络模型足够复杂，那么端到端深度学习模型的性能会比传统机器学习分块模型更好。</p><p>而如果数据集规模适中，还是可以使用流水线方法，但是可以混合端到端深度学习，通过神经网络绕过某些模块，直接输出某些特征。</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20201204213920952.png" srcset="/img/loading.gif" lazyload alt="image-20201204213920952"><figcaption>image-20201204213920952</figcaption></figure><h4 id="优点与缺点">优点与缺点</h4><p>应用端到端学习的优点：</p><ul><li>只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析；</li><li>所需手工设计的组件更少，简化设计工作流程；</li></ul><p>缺点：</p><ul><li>需要大量的数据；</li><li>排除了可能有用的人工设计组件；</li></ul><p>根据以上分析，决定一个问题是否应用端到端学习的<strong>关键点</strong>是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数？</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2020/12/06/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B04/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">《深度学习》课程笔记4_卷积神经网络</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2020/11/16/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B02/"><span class="hidden-mobile">《深度学习》课程笔记2_改善深层神经网络</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>