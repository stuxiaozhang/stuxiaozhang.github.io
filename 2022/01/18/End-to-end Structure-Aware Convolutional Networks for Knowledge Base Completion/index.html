<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion本文是美国康涅狄格大学的研究者发表在 AAAI 2019 上的文章，提出了 WGCN、Conv-TransE 及两者的结合 SACN，文章的主要思想是将图卷积与 ConvE 结合，在用卷积做 KGE 时既考虑图结构信息（GCN），又考虑翻译特"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>【SACN】End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="【SACN】End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-01-18 09:51" pubdate>2022年1月18日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 3.4k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 26 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">【SACN】End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion</h1><p class="note note-info">本文最后更新于：2022年1月26日</p><div class="markdown-body"><h1 id="End-to-end-Structure-Aware-Convolutional-Networks-for-Knowledge-Base-Completion"><a href="#End-to-end-Structure-Aware-Convolutional-Networks-for-Knowledge-Base-Completion" class="headerlink" title="End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion"></a>End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion</h1><p>本文是美国康涅狄格大学的研究者发表在 AAAI 2019 上的文章，提出了 WGCN、Conv-TransE 及两者的结合 SACN，文章的主要思想是将图卷积与 ConvE 结合，在用卷积做 KGE 时既考虑图结构信息（GCN），又考虑翻译特性（Conv-TransE）。</p><div class="note note-primary"><p><strong>问：</strong>这个图的节点属性是 KB 里本来有的吗？那以前的方法没把它算进去吗？</p><ul><li>不是…应该是作者自己构建了带有属性三元组的数据集 FB15k-237-Attr, 但是是如何构建的，貌似没有在文章和code中看到…</li></ul></div><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>文章认为，知识图谱补全任务:</p><ol><li>以前的方法只建模关系三元组，忽略了大量<strong>图节点相关属性</strong></li><li>以前的方法<strong>没有考虑 KG 的图结构信息</strong></li><li>ConvE 模型中采用的 2D 卷积操作没能保留翻译特性 (TransE)</li></ol><p>针对这三个问题，文章提出用加权的图卷积网络 WGCN 解决图结构 (connectivity structure) 信息没有考虑在内的问题，省略了 ConvE 2D 卷积中的 reshape 操作用于保留翻译特性。整体的模型称为 SACN (Structure-Aware Convolutional Network)，是一个 End-to-end 的结构</p><ul><li>WGCN 作为 Encoder: 利用一个带权重的 GCN 的方法（利用图的结构并保留节点的属性）</li><li>Conv-TransE 作为 Decoder: 利用 ConvE 的方法，但是去掉了实体和关系的矩阵 reshape 部分（为了保留 TransE 的 <code>h+r=t</code> 的特性）。</li></ul><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>作者<strong>比较了 ConvE 和 ConvKB 的区别</strong>：ConvE 是第一个在不同嵌入维度的嵌入上使用 2D 卷积的模型，希望提取更多的特征交互。ConvKB 将 ConvE 中的二维卷积替换为一维卷积，从而将卷积限制为相同的嵌入维数，并保持 TransE 的平移特性。ConvKB 可被视为 Conv-TransE 的特例，它只使用宽度等于1的过滤器。尽管 ConvKB 被证明比 ConvE 更好，但两个数据集（FB15k-237和WN18RR）的结果并不一致，因此我们将这些结果从对比表中删除。</p><p>ConvE 和 ConvKB 的另一个主要区别在于模型中使用的损失函数。ConvE 使用了交叉熵损失，该损失可以通过解码器中的 1-N 评分来加速，而 ConvKB 使用了铰链损失，该损失是从正示例和采样的负示例中计算出来的。作者采用 ConvE 的解码器，因为可以很容易地将 GCN 的编码器和 ConvE 的解码器集成到端到端的训练框架中，而 ConvKB 不适合。</p><div class="note note-primary"><p>Knowledge Graph Embedding: 将实体和关系的语义编码在一个连续的低维向量空间（称为嵌入 embeddings）中。然后可以使用这些嵌入来预测新的关系。</p></div><h2 id="SACN"><a href="#SACN" class="headerlink" title="SACN"></a>SACN</h2><h3 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h3><p>回忆一下 GCN 的定义，主要思想为：将每个节点作为聚合的中心节点，对每个中心节点，聚合邻居节点的本层特征表示，来作为中心节点的下一层特征表示，即</p><script type="math/tex;mode=display">\begin{array}{c}
h_{i}^{l+1}=\sigma\left(\sum_{j \in N_{i}} g\left(h_{i}^{l}, h_{j}^{l}\right)\right) \\
g\left(h_{i}^{l}, h_{j}^{l}\right)=h_{j}^{l} W^{l} \\
h_{j}^{l} \in R^{F^{l}}, W^{l} \in R^{F^{l} \times F^{l+1}}
\end{array}</script><p>通过求和操作，将线性变换后的邻居节点的向量表示共享给中心节点，实现 GCN 层中的聚合操作。通过 GCN 层的逐层堆叠，来实现前向传递。值得一提的是，每层 GCN 都聚合了邻居的信息，在第一层聚合了一阶邻居信息之后，第二层聚合邻居的时候，它的邻居节点已经有了邻居节点的邻居节点的信息，因此第二层 GCN 聚合了二阶邻居的信息。GCN 层堆叠次数越多，中心节点所聚合的邻居范围也越广。</p><p>GCN 的本质和 PageRank 是一样的，就是信息累积(聚合)，用邻居节点表示当前节点。在 WGCN 这里模型做了一点小小的提升，就是在信息累积时候加上了<u>权重</u>，用于控制在多大程度上接受从邻居节点流过来的信息（文中称为当前节点与邻居节点的交互强度），之前的 GCN 只是单纯地把汇过来的信息求平均。这个权重由两节点的关系类型决定。</p><h3 id="WGCN-Weighted-Graph-Convolutional-Layer"><a href="#WGCN-Weighted-Graph-Convolutional-Layer" class="headerlink" title="WGCN: Weighted Graph Convolutional Layer"></a>WGCN: Weighted Graph Convolutional Layer</h3><p>WGCN 是加权的 GCN，<strong>在聚合时对不同类型的关系进行不同的加权，并在网络训练期间自适应学习加权</strong>。通过这种自适应，WGCN 可以控制来自聚合中使用的相邻节点的信息量。WGCN 将多关系 KB 图视为多个单关系子图，其中每个子图都包含特定类型的关系。WGCN 确定在组合节点的 GCN 嵌入时给每个子图的权重。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220118114511145.png" srcset="/img/loading.gif" lazyload alt=""></p><p>上图展示了 SACN 的整个过程。在这个例子中，网络的 WGCN 层计算中间图中的红色节点的嵌入。这些层按照 KB 关系中的指定聚合相邻实体节点的嵌入。边的三种颜色（蓝色、黄色和绿色）表示图形中的三种不同关系类型。根据该层中的权重 $\alpha_{t}$，将对应的三个实体节点以不同的权值相加，得到红色节点的嵌入。具有相同颜色（相同关系类型）的边使用相同的 $\alpha_t$。每个层都有自己的一组关系权重 $\alpha_t$。因此，节点 $v_i$ 的第 $l$ 层的输出可以如下写入:</p><script type="math/tex;mode=display">h_{i}^{l+1}=\sigma\left(\sum_{j \in \mathbf{N}_{\mathbf{i}}} \alpha_{t}^{l} g\left(h_{i}^{l}, h_{j}^{l}\right)\right)</script><ul><li>其中，$h<em>{j}^{l}$ 是节点 $v_i$ 的输入， $v_j$ 是 $v_i$ 的邻居节点(一共 $N_i$ 个)，$\alpha</em>{t}^{l}$ 是第 $l$ 层，第 $t$ 种边（关系）类型的权重参数, $g$ 是聚合邻居信息的函数:</li></ul><script type="math/tex;mode=display">g\left(h_{i}^{l}, h_{j}^{l}\right)=h_{j}^{l} W^{l}</script><ul><li>$W^{l} \in \mathbb{R}^{F^{l} \times F^{l+1}}$ 是连接系数矩阵，用于 $F^{l}$ 到 $F^{l+1}$ 的线性变换.</li></ul><p>每个节点在接收邻居信息的时候应当<strong>保留自己的信息</strong>，和 R-GCN 一样，加上 self-loop，则节点 $v_i$ 的传播过程可以被定义为：</p><script type="math/tex;mode=display">h_{i}^{l+1}=\sigma\left(\sum_{j \in \mathbf{N}_{\mathbf{i}}} \alpha_{t}^{l} h_{j}^{l} W^{l}+h_{i}^{l} W^{l}\right)</script><p>$l$ 层的输出是一个节点特征矩阵：$H^{l+1} \in \mathbb{R}^{N \times F^{l+1}}$ ，$h_i^{l+1}$ 是 $H^{l+1}$ 的第 $i$ 行，代表第 $l+1$ 层中节点 $v_i$ 的特征。</p><p>以上的为不同类型的边加权重的过程可以看做一个矩阵乘法：通过一个邻接矩阵同时为所有节点计算 embeddings，见下图：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220118222657043.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>对于每种关系（边）类型，邻接矩阵 $A_t$ 是一个二元矩阵，如果存在连接 $v_i$ 和 $v_j$ 的边，则邻接矩阵中第 $ij$ 的位置为 1，否则为0。最终邻接矩阵如下所示：</p><script type="math/tex;mode=display">A^{l}=\sum_{t=1}^{T}\left(\alpha_{t}^{l} A_{t}\right)+I</script><ul><li>其中 $I$ 是大小为 $N×N$ 的单位矩阵, $A^l$ 是子图的邻接矩阵加上自连接的加权和。</li></ul><p>故，由此可以等到每一层线性变换的所有一节邻居：</p><script type="math/tex;mode=display">H^{l+1}=\sigma\left(A^{l} H^{l} W^{l}\right)</script><h3 id="Node-Attributes"><a href="#Node-Attributes" class="headerlink" title="Node Attributes"></a>Node Attributes</h3><p>在知识图谱中，属性节点的形式为 <code>(entity, relation, attribute)</code>，例如：<code>(s = Tom, r = people.person.gender, a = male)</code>。但是如果用向量表达节点属性会出现两个问题：</p><ol><li>每个节点的属性数通常很小，并且每个节点的属性数不同。会产生属性向量稀疏的问题。</li><li>属性向量中的0值会产生歧义：该节点没有该属性，或者该属性缺失值。这些0会影响嵌入的准确性。</li></ol><p>本文还使用了<strong>节点的属性作为图的节点</strong>，如属性 <code>(Tom,gender,male)</code>。这样做的目的是将属性也作为节点，起到“桥”的作用，相同属性的节点可以共享信息。还有作者为了减少过多的属性节点，对节点进行了合并， 将 gender 也作为了图中的节点，而不是建立 male 和 female 两个属性，理由是 gender 已经能够确定实体的 person，而不必过多区分性别。（即作者把属性三元组变为了两元组（实体，属性名）</p><p>这样，WGCN 不仅利用了图形连接结构（关系和关系类型），而且还有效地利用了节点属性（一种图形结构）。这就是我们将 WGCN 命名为结构感知卷积网络的原因。</p><div class="note note-primary"><p>节点属性是怎么合并的？能不能让model自己学？</p></div><h3 id="ConvE-TransE"><a href="#ConvE-TransE" class="headerlink" title="ConvE-TransE"></a>ConvE-TransE</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220126144946922.png" srcset="/img/loading.gif" lazyload alt=""></p><p>Decoder 的过程如图：将 WGCN 得到的实体 s 的 embedding 和预训练的关系 r 的 embedding 进行 concat 操作，变成一个 2*n 维的矩阵。对这个矩阵进行卷积操作，通过多个相同尺寸的卷积核，得到 feature maps。然后将 feature maps 拉直成一个向量，通过全连接层进行维度缩减。将这个融合了 s 和 r 的向量与 WGCN 生成的所有向量分别进行点积操作，计算 $(s, r)$ 与所有待选o的相似度。相似度通过 sigmoid 缩放到 0~1 范围内，取相似度最高的作为预测的实体 o。</p><p>SACN 的评分网络是一个卷积神经模型，称为 Conv-TransE。Conv-TransE 和 ConvE 的 区别是在叠加 $e_s$ 和 $e_r$ 后，<strong>没有 reshape 操作</strong>，然后进行卷积计算：</p><script type="math/tex;mode=display">\begin{aligned}
m_{c}\left(e_{s}, e_{r}, n\right)=& \sum_{\tau=0}^{K-1} \omega_{c}(\tau, 0) \hat{e}_{s}(n+\tau) +\omega_{c}(\tau, 1) \hat{e}_{r}(n+\tau)
\end{aligned}</script><ul><li>其中，$K$ 是指 kernel width，$n$ 索引输出向量中的条目, $\omega_{c}$ 是卷积核参数。</li></ul><p>卷积操作相当于一维卷积后 $e<em>s$ 和 $e_r$ 的和，因此，它<strong>保留了 $e_s$ 和 $e_r$ embeddings 的翻译性质</strong>。输出形成了 $M</em>{c}\left(e<em>{s}, e</em>{r}\right)=\left[m<em>{c}\left(e</em>{s}, e<em>{r}, 0\right), \ldots, m</em>{c}\left(e<em>{s}, e</em>{r}, F^{L}-1\right)\right]$, 将卷积的输出向量与所有核对齐，得到特征矩阵 $\mathbf{M}\left(e<em>{s}, e</em>{r}\right) \in \mathbb{R}^{C \times F^{L}}$。将特征映射矩阵 $\mathbf{M}\left(e<em>{s}, e</em>{r}\right)$ reshape 为向量 $\operatorname{vec}(\mathbf{M}) \in \mathbb{R}^{C F^{L}}$, 用 $W$ 进行线性变换，投影到 $F^{L}$ 维空间。然后通过适当的距离度量将计算出与 $e_o$ 匹配的 embeddings，得到每个实体的得分。</p><p>Conv-TransE 方法的评分函数定义如下：</p><script type="math/tex;mode=display">\psi\left(e_{s}, e_{o}\right)=f\left(\operatorname{vec}\left(\mathbf{M}\left(e_{s}, e_{r}\right)\right) W\right) e_{o} \\
p\left(e_{s}, e_{r}, e_{o}\right)=\sigma\left(\psi\left(e_{s}, e_{o}\right)\right)</script><hr><p>作者也总结了一些经典模型的评分函数，其中 $*$ 表示卷积操作，如下图：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220120165512658.png" srcset="/img/loading.gif" lazyload style="zoom:33%"></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="datasets"><a href="#datasets" class="headerlink" title="datasets"></a>datasets</h3><p>文中共使用了三个数据集，包括：</p><ol><li>FB15k-237: freebase三元组</li><li>WN18RR: wordnet三元组</li><li>FB15k-237-Attr: 作者从FB24k中抽取了实体的属性</li></ol><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220126143913306.png" srcset="/img/loading.gif" lazyload style="zoom:33%"></p><h3 id="Link-prediction"><a href="#Link-prediction" class="headerlink" title="Link prediction"></a>Link prediction</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220120170457232.png" srcset="/img/loading.gif" lazyload alt=""></p><p>从表中可以看到：</p><ol><li>ConvE-TransE 要比其他四个 baseline 模型性能好。</li><li>将结构信息添加到 SACN 模型中，也比其他的 baseline 模型性能好。</li><li>将<strong>节点属性</strong>添加到 SACN 模型中，即使用 FB15k-237-Attr 来训练 SACN。也比其他的 baseline 模型性能好。</li><li>为了更好地与 ConvE 进行比较，作者还将属性应用到 ConvE 中。在这里，属性将被视为实体三元组。实验结果得出: 并没有提升 ConvE 性能。(估计是效果不好所以结果就没放到图表中…)</li></ol><h3 id="Kernel-Size-Analysis"><a href="#Kernel-Size-Analysis" class="headerlink" title="Kernel Size Analysis"></a>Kernel Size Analysis</h3><p>卷积核形状的设置对模型效果有影响，卷积核增大，效果提升。但最佳卷积核大小可能取决于任务。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220120221259246.png" srcset="/img/loading.gif" lazyload style="zoom:40%"></p><h3 id="Node-Indegree-Analysis"><a href="#Node-Indegree-Analysis" class="headerlink" title="Node Indegree Analysis"></a>Node Indegree Analysis</h3><p>度大的节点说明它有更多的相邻节点，这种节点比度小的节点可以从相邻节点接收更多的信息。即入度越大，图的密度越大，模型的效果越好。从表中实验结果可以得知：</p><ol><li><p>对于度数较小的节点，其信息来自 SACN 的 WGCN 层的邻居信息的聚合。它的 embeddings 可以可靠地估计。</p></li><li><p>对于度数较大的节点，WGCN 聚合的信息就比较多，较多的邻居节点使较重要的邻居信息被过度“平滑”掉了，就会没有区分度。所以从 SACN 学习到的嵌入比从 ConvE-TransE 学习到的嵌入更差。作者认为这个问题的一个解决方案是 neighbor selection，如 PinSAGE。</p><blockquote><p>PinSAGE 的基本思想可以<a href="https://stuxiaozhang.github.io/2021/12/27/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8/#PinSAGE">参考这里</a>.</p></blockquote></li></ol><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220120222031304.png" srcset="/img/loading.gif" lazyload style="zoom:45%"></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>文章提出了一种端到端结构感知卷积网络（SACN）。编码网络是一个加权图卷积网络，利用知识图的连通结构、节点属性和关系类型。具有可学习权重的WGCN具有从相邻图节点聚合信息的优点。此外，在网络中添加实体属性作为节点，从而将属性转化为知识结构信息，便于集成到节点嵌入中。SACN的评分网络是一个卷积神经模型，称为Conv-TransE。它使用卷积网络保留实体和关系之间的翻译特性，以学习用于链接预测的节点嵌入。</p><p>作者提到了未来的改进方向：将 PinSAGE 的思想加入到模型中，它在聚合邻居的向量表示时考虑了邻居的重要性，同时也使模型具有更大的可扩展性。</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/Papers/">Papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/GNN/">GNN</a> <a class="hover-with-bg" href="/tags/KG/">KG</a> <a class="hover-with-bg" href="/tags/SACN/">SACN</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/01/18/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E7%B4%A0%E6%9D%90%E6%95%B4%E7%90%86/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">论文写作素材整理</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2022/01/18/SACN%EF%BC%9AEnd-to-end%20Structure-Aware%20Convolutional%20Networks%20for%20Knowledge%20Base%20Completion/"><span class="hidden-mobile">【SACN】End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>