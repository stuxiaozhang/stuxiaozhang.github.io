<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding
这篇文章是腾讯 AI Lab 发表在 AAAI 2019 上的一篇文章。Knowledge Graph Embedding 的目的是使用低维向量建模实体和关系，用于下游任务。目前方法大多要求所有实体在训练时可见，这在每天更新"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>【LAN】Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="【LAN】Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-01-05 16:32" pubdate>2022年1月5日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4.5k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 36 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">【LAN】Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding</h1><p class="note note-info">本文最后更新于：2022年1月27日</p><div class="markdown-body"><h1 id="logic-attention-based-neighborhood-aggregation-for-inductive-knowledge-graph-embedding">Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding</h1><p>这篇文章是腾讯 AI Lab 发表在 AAAI 2019 上的一篇文章。Knowledge Graph Embedding 的目的是使用低维向量建模实体和关系，用于下游任务。目前方法大多要求所有实体在训练时可见，这在每天更新的 Knowledge Base 中是不切实际的。本篇论文中，作者使用同时训练邻域聚集模型的方式来去除这种限制，并提出一种基于规则和注意力机制的聚集模型，即逻辑注意力网络（LAN）。在两个知识图谱补全任务上，LAN 被证明优于传统聚集模型。</p><h2 id="basic-idea">Basic Idea</h2><p>传统的 KGE 模型(Transductive KGE)是 transductive learning, 在训练时需要看到全部的实体, 这种限制阻碍他们推广到新出现的实体。而对于归纳性的 KGE 模型(Inductive KGE)，新出现的实体相当于 Inductive KGE model 的输入。当前关于 Inductive model 的工作是利用额外的节点属性来嵌入 unseen node；还有 aggregator 对邻居一视同仁，要么不必要地要求对它们进行排序。而且这些模型不能直接应用于具有多关系边的 KG。</p><p>因此，作者提出了 LAN 来建模 Inductive KGE。Inductive KGE 问题归结为设计一个 KG 特定的<strong>邻域聚合器(neighbourhood aggregator)</strong> 来捕获基本的邻域信息。作者定义的理想的邻域聚合器应该有以下三个属性：</p><ul><li><strong>Permutation Invariant (置换不变)</strong>: 这也是 GNN 中的一个基本的性质，即：<strong>聚合与邻域节点的顺序无关。</strong></li><li><strong>Redundancy Aware (邻域冗余感知)</strong>：aggregator 应该学会利用实体邻域的<strong>冗余信息</strong>。如图：一个人为芝加哥公牛队效力意味着他是一名篮球运动员。利用实体邻域中的这种冗余是有益的，从而使聚合提供信息。好的聚合器应该能利用这种非显示的冗余信息。</li><li><strong>Query Relation Aware (查询关系感知)</strong>: 对于常见的 KG 补全任务，查询关系是预先给出的，如图中的查询关系: <code>live_in</code>。一个聚合器可能会利用这些信息集中在附近的相关事实，例如，一个entity <code>play for</code> <code>Chicago Bulls</code>。这条性质和上一条有所区别，因为 <code>live_in</code> 这个关系并不一定真的与 <code>play_for</code> 有很强烈的因果或是包含关系，二者只是有一定的概率一同出现。结合后文的算法，这条性质应该旨在说明<strong>聚合器需要建模不同关系之间的概率关系</strong>。</li></ul><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220107143410224.png" srcset="/img/loading.gif" lazyload alt="image-20220107143410224" style="zoom:50%"></p><p>图中，虚线圆圈和箭头表示现有的KG，实线表示由新出现的实体带来的KG。</p><h2 id="framework">Framework</h2><p>当一个新的实体出现了一些涉及KB内的实体和关系的三元组时，可以在其新建立的邻域上应用聚合器，并使用输出嵌入来推断关于它的新事实。</p><p>模型的 framework 如下：</p><p><img src="C:/Users/HP/AppData/Roaming/Typora/typora-user-images/image-20220105202132271.png" srcset="/img/loading.gif" lazyload alt="image-20220105202132271" style="zoom:67%"></p><p>如图，给定一个训练三元组，编码器 <span class="math inline">\((s,r,o)\)</span> 用 aggregator 将 <span class="math inline">\(s\)</span> 和 <span class="math inline">\(o\)</span> 编码为两个嵌入。解码器通过评分函数计算三元组的合理性，并向编码器提供反馈以调整 aggregator 的参数。</p><h3 id="encoder">Encoder</h3><p>对于一个实体 <span class="math inline">\(e_i\)</span>，编码器输入它的 neighbor embeddings 的集合，输出 <span class="math inline">\(e_i\)</span> 的 embedding....?</p><p>为了反应关系 <span class="math inline">\(r\)</span> 对 <span class="math inline">\(e_j\)</span> 的影响，定义了一个特定于关系的 Transforming function <span class="math inline">\(T_r(\cdot)\)</span>: <span class="math display">\[ T_{r}\left(\mathbf{e}_{j}^{I}\right)=\mathbf{e}_{j}^{I}-\mathbf{w}_{r}^{\top} \mathbf{e}_{j}^{I} \mathbf{w}_{r} \]</span> 其中，<span class="math inline">\(\mathbf{w}_{r}\)</span> 是关系 <span class="math inline">\(r\)</span> 的变换向量并被限制为单位向量。其实这个公式来源于 TransH 的得分函数，详情可以参考<a href="https://stuxiaozhang.github.io/2021/08/18/TransH%EF%BC%9AKnowledge%20Graph%20Embedding%20by%20Translating%20on%20Hyperplanes/">这篇笔记</a>。因为 TransH 其不涉及矩阵积运算，并且计算复杂度较低。</p><p>在转换 neighbor embeddings 之后，这些 transformed embeddings 被送到聚合器 A 以输出目标实体 <span class="math inline">\(e_i\)</span> 的嵌入 <span class="math inline">\(\mathbf{e}_{i}^{O}\)</span>，即: <span class="math display">\[ \mathbf{e}_{i}^{O}=A\left(\left\{T_{r}\left(\mathbf{e}_{j}^{I}\right) \mid\left(r, e_{j}\right) \in N_{\mathcal{K}}(i)\right\}\right) \]</span> 根据定义，聚合器 A 本质上接受向量 <span class="math inline">\(\mathbf{X}=\left\{\mathbf{x}_{j}\right\}\left(\mathbf{x}_{j} \in \mathbb{R}^{d}\right)\)</span>的集合作为输入 并将它们映射到单个向量。以前曾经用过以下两种方法作为聚合器：</p><ul><li><p>Pooling Functions. 虽然满足置换不变性质，但是它<strong>视邻居为等价的</strong>，这些类似的池化函数既不知道邻域中的潜在冗余，也不知道查询关系.</p></li><li><p>RNNs. 在 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.02216">GraphSAGE (Inductive representation learning on large graphs 这篇论文)</a>中，作者采用 LSTM 作为邻域聚合器，为了训练和应用基于 LSTM 的聚合器，它们必须随机排列邻居，这违反了 permutation variance property.</p><blockquote><p>我觉得这块是不是写错了。应该是 LSTM 违反了 permutation <strong>in</strong>variance property.</p></blockquote></li><li><p>作者提出了 LAN 作为聚合器，并做了实验，在下文中描述。</p></li></ul><h3 id="decoder">Decoder</h3><p>编码器输出 <span class="math inline">\(\mathbf{s}^{O}\)</span> 和 <span class="math inline">\(\mathbf{O}^{O}\)</span> embeddings 后，解码器需要评价训练三元组的合理性。为了避免邻域中关系 <span class="math inline">\(r\)</span> 的潜在混合，作者用 query relation 指代训练三元组中的关系，并用 <span class="math inline">\(q\)</span> 表示它。 从嵌入矩阵 <span class="math inline">\(\mathbf{W}_r\)</span> 总找到 <span class="math inline">\(q\)</span> 的表示后，使用评分函数对三元组 <span class="math inline">\((s,q,o)\)</span> 进行打分. 评分函数用了基于 TransE 的评分函数：</p><p><span class="math display">\[ \phi^{O}(s, q, o)=-\left|\mathbf{s}^{O}+\mathbf{q}-\mathbf{o}^{O}\right|_{L 1} \]</span> 为了检验所研究的聚合器是否在不同的评分函数之间推广/泛化，作者实验了几种备选方案。</p><h2 id="logic-attention-network">Logic Attention Network</h2><p>传统的邻域聚合器不能保留所有需要的属性。所以作者提出了 LAN，且满足提出的理想聚合器的三个属性.</p><h3 id="incorporating-neighborhood-attention">Incorporating Neighborhood Attention</h3><p>传统的邻域聚合器仅依赖于 transformed embeddings 的集合。它们忽略了邻域 <span class="math inline">\(N_{K(i)}\)</span> 和查询关系 <span class="math inline">\(q\)</span> 中的其他有用信息. 作者提出：将聚合器从 <span class="math inline">\(A(X)\)</span> 推广到 <span class="math inline">\(A(X;N_{K(i)},q)\)</span>。具体而言，<strong>对于实体 <span class="math inline">\(e_i\)</span>，其邻居 <span class="math inline">\(e_j\)</span> 应根据其代表 <span class="math inline">\(e_i\)</span> 的重要性对 <span class="math inline">\(e^O_i\)</span> 做出不同的贡献。</strong></p><p>为了保持置换不变性质，对 transformed embeddings 采用<strong>基于 attention 的聚合</strong>方法。然后在估计注意权重时利用 <span class="math inline">\(N_{K(i)}\)</span> 和 <span class="math inline">\(q\)</span> 中的附加信息。公式如下： <span class="math display">\[ \mathbf{e}_{i}^{O}=\sum_{\left(r, e_{j}\right) \in N_{\mathcal{K}}(i)} \alpha_{j \mid i, q} T_{r}\left(\mathbf{e}_{j}^{I}\right) \]</span> 其中，$_{j i, q} $ 是为给定 <span class="math inline">\(e_i\)</span> 和查询关系 <span class="math inline">\(q\)</span> 的每个邻居 <span class="math inline">\(e_j\)</span> 指定的注意力权重。</p><p>为了将更大的权重 <span class="math inline">\(\alpha_{j \mid i, q}\)</span> 分配给更重要的邻居，从 <span class="math inline">\(e_i\)</span> 的角度来看，作者在渐进的层面上提出两个问题：</p><ol type="1"><li>什么类型的邻居关系可能导致成为潜在的重要邻居？</li><li>根据这些关系，哪个特定的邻居（在 transformed embeddings 中）可能包含重要信息？</li></ol><p>受这两个问题的启发，采用以下两种机制来估计 $_{j i, q} $</p><h4 id="logic-rule-mechanism">Logic Rule Mechanism</h4><p>KG 中的关系不是独立存在的，<strong>一个相邻关系可能意味着另一个相邻关系的存在</strong>，尽管它们不一定将 <span class="math inline">\(e\)</span> 连接到同一个邻居。</p><p>例如：一个相邻关系 <code>‘play_for’</code> 也许表示 entity <code>athlete</code> 的家乡城市，即关系 <code>‘live_in’</code>。所以作者定义了 <span class="math inline">\(r_{1} \Rightarrow r_{2}\)</span> 来度量 <span class="math inline">\(r_1\)</span> 和 <span class="math inline">\(r_2\)</span> 潜在的依赖关系： <span class="math display">\[ \mathcal{P}\left(r_{1} \Rightarrow r_{2}\right)=\frac{\sum_{e \in \mathcal{E} } \mathbb{1}\left(r_{1} \in N_{\mathcal{R} }(e) \wedge r_{2} \in N_{\mathcal{R} }(e)\right)}{\sum_{e \in \mathcal{E} } \mathbb{1}\left(r_{1} \in N_{\mathcal{R} }(e)\right)} \]</span> 其中，<span class="math inline">\(\mathbb{1}(x)\)</span> 是示性函数，x 为真时等于1，其余为0。如果具有相邻关系 <span class="math inline">\(r_1\)</span> 的实体，同时 <span class="math inline">\(r_2\)</span> 也是相邻关系的实体越多，则 <span class="math inline">\(\mathcal{P}\left(r_{1} \Rightarrow r_{2}\right)\)</span> 越大。</p><p><span class="math display">\[ \alpha_{j \mid i, q}^{\text {Logic }}=\frac{\mathcal{P}(r \Rightarrow q)}{\max \left(\left\{\mathcal{P}\left(r^{\prime} \Rightarrow r\right) \mid r^{\prime} \in N_{\mathcal{R}}\left(e_{i}\right) \wedge r^{\prime} \neq r\right\}\right)} . \]</span> 一方面，对于查询关系 <span class="math inline">\(q\)</span>， <span class="math inline">\(r\)</span> 与 <span class="math inline">\(q\)</span> 的相关程度应该很高，即这样重要的相邻关系 <span class="math inline">\(r\)</span> 应该有一个大的 <span class="math inline">\(\mathcal{P}\left(r \Rightarrow q \right)\)</span> 。另一方面，对于重要邻居的相邻关系 <span class="math inline">\(r\)</span>，<span class="math inline">\(r\)</span> 不应该被邻域中的其他关系 <span class="math inline">\(r&#39;\)</span> 所暗示/找到. 我理解为：其他关系 <span class="math inline">\(r&#39;\)</span> 既然没用，就让其与 <span class="math inline">\(r\)</span> 区分开来，即 <span class="math inline">\(r&#39;\)</span> 与 <span class="math inline">\(r\)</span> 的相关程度很低: <span class="math inline">\(\mathcal{P}\left(r \Rightarrow q \right)\)</span> 很小.</p><blockquote><p>例如：在上面的栗子中，如果查询关系 <span class="math inline">\(q\)</span> 是 <code>‘live_in’</code>，则应去考虑重要的相邻关系 <span class="math inline">\(r\)</span> <code>‘play_for’</code> 。另一方面，例如，无论查询关系是否是 <code>‘live_in’</code>，都不应为 <code>work_as</code> 这个相邻关系分配太多的权重，因为 <code>‘play_for’</code> 已经为其提供了足够的信息。</p></blockquote><p>所以说： **$_{j i, q} $ 提升了重要关系 <span class="math inline">\(r\)</span> 对 <span class="math inline">\(q\)</span> (分子)的影响，并降低了相同邻域(分母)中其他关系 <span class="math inline">\(r&#39;\)</span> 找到关系 <span class="math inline">\(r\)</span> 的影响。**通过这种方式，Logic Rule Mechanism 达成了查询关系感知和邻域冗余感知。</p><h4 id="neural-network-mechanism">Neural Network Mechanism</h4><p><strong>Logic Rule Mechanism 将注意力权重引导到关系的粗粒度上</strong>，而 <strong>Neural Network Mechanism 考虑隐藏在转换的邻居嵌入中的细粒度信息 来确定哪个邻居重要。</strong></p><p>给定一个查询关系 <span class="math inline">\(q \in \mathcal{R}\)</span>，<span class="math inline">\(e_i\)</span> 和 邻居节点 <span class="math inline">\(e_j\)</span> 之间关系的重要性用下面公式衡量： <span class="math display">\[ \alpha_{j \mid i, q}^{\mathrm{NN}}=\operatorname{softmax}\left(\alpha_{j \mid i, q}^{\prime}\right)=\frac{\exp \left(\alpha_{j \mid i, q}^{\prime}\right)}{\sum_{j^{\prime} \in N_{\mathcal{E}}(i)} \exp \left(\alpha_{j^{\prime} \mid i, q}^{\prime}\right)} . \]</span> 其中，未归一化的注意力权重 <span class="math inline">\(\alpha_{j \mid i, q}^{\prime}\)</span> 通过 Attention neural network 给出： <span class="math display">\[ \alpha_{j \mid i, q}^{\prime}=\mathbf{u}_{a}^{\top} \cdot \tanh \left(\mathbf{W}_{a} \cdot\left[\mathbf{z}_{q} ; T_{r}\left(\mathbf{e}_{j}^{I}\right)\right]\right) \]</span> 其中，<span class="math inline">\(\mathbf{u}_{a}\)</span> 和 <span class="math inline">\(\mathbf{W}_{a}\)</span> 是全局的 attention 参数，<span class="math inline">\(\mathbf{z}_{q}\)</span> 是查询关系 <span class="math inline">\(q\)</span> 的特定于关系的 attention 参数。所有这些 attention 参数都被视为编码器的参数，并直接从数据中学习。</p><p><strong>注意：</strong>与 Logic Rule Mechanism 的 <span class="math inline">\(\alpha_{j \mid i, q}^{\text {Logic }}\)</span> 不同，<span class="math inline">\(\alpha_{j \mid i, q}^{\mathrm{NN}}\)</span> 的计算更多的集中于 <strong>邻居节点 <span class="math inline">\(e_j\)</span> 本身</strong>。栗，图2中，邻居节点 <code>Chicago_Bulls</code> 可能有助于找到 <code>live_in</code> 的概率，因为 <code>live_in</code> 芝加哥的同时还有其他运动员 <code>play_for</code> <code>Chicago_Bulls</code> 。</p><p>最后为了结合两种加权机制，采用了 double-view attention，将（2）公式更改为： <span class="math display">\[ \mathbf{e}_{i}^{O}=\sum_{\left(r, e_{j}\right) \in N_{\mathcal{K}}(i)}\left(\alpha_{j \mid i, q}^{\mathrm{Logic}}+\alpha_{j \mid i, q}^{\mathrm{NN}}\right) T_{r}\left(\mathbf{e}_{j}^{I}\right) \]</span></p><h3 id="training-objective">Training Objective</h3><p>训练模型需要 正三元组和负三元组。对正三元组随机破坏来获得 负三元组: <span class="math display">\[ \Delta_{(s, q, o)}^{\prime}=\left\{\left(s^{\prime}, q, o\right) \mid s^{\prime} \in \mathcal{E}\right\} \cup\left\{\left(s, q, o^{\prime}\right) \mid o^{\prime} \in \mathcal{E}\right\} \]</span> 为了鼓励 Decoder 对正三元组给出高分，对负三元组给出低分，对每个三元组 <span class="math inline">\((s,q,o)\)</span> 应用 基于 margin 的 rank loss: <span class="math display">\[ l^{O}(s, q, o)=\left[\gamma-\phi^{O}(s, q, o)+\phi^{O}\left(s^{\prime}, q, o^{\prime}\right)\right]_{+} \]</span> 其中，<span class="math inline">\([x]_+=max\{0,x\}\)</span> ，<span class="math inline">\(\gamma\)</span> 是有关 margin 的超参数 <span class="math display">\[ \min \sum_{(s, q, o) \in \Delta} \sum_{\left(s^{\prime}, q, o^{\prime}\right) \in \Delta_{(s, q, o)}^{\prime}} l^{O}(s, q, o) \]</span></p><h4 id="subtask-on-input-embeddings">Subtask on Input Embeddings</h4><p>上述培训目标仅优化聚合器的输出，即输出实体。然而，输入实体嵌入 <span class="math inline">\(\mathbf{s}^{I}\)</span> 并不直接知道整个KG的结构。为了使输入嵌入和聚合更有意义，作者为 LAN 设置了一个子任务。</p><p>首先定义了第二个评分函数，它类似于上面的评分函数，不同之处在于: <span class="math inline">\(\mathbf{w}_{a}\)</span> 的输入嵌入 <span class="math inline">\(\mathbf{e}^{I}\)</span> 用于表示 subject 和 object，即 <span class="math display">\[ \phi^{I}(s, q, o)=-\left|\mathbf{s}^{I}+\mathbf{q}-\mathbf{o}^{I}\right|_{L 1} . \]</span> 查询关系 <span class="math inline">\(q\)</span> 的嵌入由与第一个评分函数相同的嵌入矩阵 <span class="math inline">\(\mathbf{w}_{r}\)</span> 获得。然后为子任务定义了类似于上面的公式: 基于 margin 的 rank loss <span class="math inline">\(l^{I}(s, q, o)\)</span>。最后，<strong>将子任务与主任务相结合</strong>，重新制定了 LAN 的整个 Training Objective <span class="math display">\[ \min \sum_{(s, q, o) \in \Delta} \sum_{\left(s^{\prime}, q, o^{\prime}\right) \in \Delta_{(s, q, o)}^{\prime}}\left[l^{O}(s, q, o)+l^{I}(s, q, o)\right] . \]</span></p><h2 id="experiments">Experiments</h2><h3 id="configurations">Configurations</h3><p>对于两个KG任务，需要构建 unseen entities 数据集：</p><ol type="1"><li><p>Sampling unseen entities. 随机分别按不同比例抽取数据构成新测试集 <span class="math inline">\(\mathcal{T}\)</span>，然后构造不可见实体的数据集 <span class="math inline">\(\mathcal{U&#39;}\)</span>. 其中 <span class="math inline">\(\mathcal{T}\)</span> 中是 subjects 和 objects 的实体加到 <span class="math inline">\(\mathcal{U&#39;}\)</span> 中。如果一个实体在原数据集 <span class="math inline">\(\mathcal{U}\)</span> 中没有邻居节点，就删掉。</p><blockquote><p>我觉得 subjects 和 objects 就是头实体 &amp; 尾实体.</p></blockquote></li><li><p>Filtering and splitting data sets. 确保看不见的实体不会出现在最终的训练集或验证集中。我们将原始的训练集分成两个数据集，新的训练集和验证集。</p><p>过滤和分割数据集。第二步是确保看不见的实体不会出现在最终的训练集或验证集中。我们将原始的训练集分成两个数据集，新的训练集和辅助集。对于原始训练集中的三元组（s，r，o），如果s，o∈ E、 它被添加到新的训练集中。如果是∈ U∧ o∈ E或s∈ E∧ o∈ U、 它被添加到辅助集合中，作为T中不可见实体的现有邻居。最后，对于原始验证集中的三元组（s，r，o），如果∈ U或o∈ U、 它将从验证集中删除。</p></li></ol><h3 id="triplet-classification">Triplet classification</h3><p><img src="C:/Users/HP/AppData/Roaming/Typora/typora-user-images/image-20220106152223375.png" srcset="/img/loading.gif" lazyload alt="image-20220106152223375" style="zoom:60%"></p><p>一方面，与平均值相比，LSTM 的性能较差，尽管平均值涉及的参数较少。这说明了为KG设计邻域聚合器时，排列不变性的必要性。另一方面，LAN 在所有数据集上取得最佳效果，证明了其有效性。</p><h3 id="link-prediction">Link Prediction</h3><p><img src="C:/Users/HP/AppData/Roaming/Typora/typora-user-images/image-20220106201114787.png" srcset="/img/loading.gif" lazyload alt="image-20220106201114787" style="zoom:80%"></p><p>从实验结果中可以看到，LSTM 性能最差。LAN 在 Hits@k 指标表现最好，而 Mean Rank 指标下的表现不好，这是因为 MR 的指标对于排名较低的位置更敏感，所以出现了 ==MRR== 指标，这样就可以看到 LAN 带来的持续改进。可以看到 MRR 指标下 LAN的 有效性。</p><h4 id="necessity-of-query-relation-awareness">Necessity of Query Relation Awareness</h4><p>需要确认 aggregator 是否感知查询关系。Query-Attention 与 LAN 一样，只是删除了 logic rule mechanism。Global-Attention 也是注意网络，除了 Neural Network Mechanism 公式中的 <span class="math inline">\(\mathbf{z}_{q}\)</span> 用零向量掩盖。</p><p>实验结果如图，Global-Attention 优于 MEAN，证明了不管查询是什么，注意力机制都可以有效地识别全局重要的邻居。但 Query-Attention 优于 Global-Attention，证明了查询关系感知的重要性。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220106212544942.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h4 id="effectiveness-of-logic-rule-mechanism">Effectiveness of Logic Rule Mechanism</h4><p>为了验证 Logic Rule Mechanism 的有效性，作者设置了只有 Mechanism 的模型。实验结果如表4，Logic Rules Only 模型比其他两个有显著优势，说明了 Logic Rule Mechanism 在为邻居分配有意义权重方面的有效性。</p><h4 id="generalization-to-other-scoring-functions">Generalization to Other Scoring Functions</h4><p>为了验证 LAN 相对于基线的优越性是否可以推广到其他评分函数，作者对评分函数进行了替换。在不同的评分函数下，LAN 在所有评估指标上的表现都一致地优于 MEAN。而且可以看到，TransE 的效果均为最好。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220106212615422.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h4 id="influence-of-the-proportion-of-unseen-entities">Influence of the Proportion of Unseen Entities</h4><p>可以合理地假设，当 Unseen Entities 与训练实体的比率增加时（即观察到的KG变得更稀疏），所有模型的性能都会恶化。</p><p>为了确定 LAN 在稀疏KG上是否会受到较少的影响，作者对具有不同采样率R的数据集进行链接预测。结果如图3所示。可以看到，Unseen Entities 比例的增加肯定对所有模型都有负面影响。然而，LAN 的性能并没有像 MEAN 和 LSTM 那样急剧下降，这表明 LAN 在稀疏KG上<strong>更具鲁棒性</strong>。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220106215911416.png" srcset="/img/loading.gif" lazyload style="zoom:90%"></p><h3 id="case-studies-on-neighbors-weights">Case Studies on Neighbors’ Weights</h3><p>可视化LAN如何为邻居指定权重。从表6中可以看到：</p><ol type="1"><li>首先，通过查询关系，LAN 可以为具有更多相关关系的邻居赋予更高的权重。在第一种情况下，当查询是origin时，最上面的两个邻居由 <code>place_lived</code> 和 <code>breed_origin</code> 参与，这有助于暗示找到 <code>origin</code>。</li><li>此外，在所有这三种情况下，具有关系 <code>gender</code> 的邻居获得的权重最低，因为它们与查询关系无关。</li><li>其次，LAN 可以将更高的权重赋予信息量更大的相邻实体。当查询关系是 <code>profession</code> 时，邻居 <code>Aristotle</code>, <code>Metaphysics</code> and <code>Aesthetics</code> 都是和答案 <code>Philosopher</code> 相关的。</li><li>第三个例子：权重最高的是 <code>(institution, University of Calgary)</code>，因为查询关系 <code>placed_live</code> 帮助aggregator专注于邻居关系 <code>institution</code> ，然后 邻居实体 <code>University of Calgary</code> 帮助找到答案 <code>Calgary</code></li></ol><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220106220513216.png" srcset="/img/loading.gif" lazyload></p><h2 id="代码">代码</h2><h2 id="summary">Summary</h2><p>作者制定了有效的邻域聚合器所需的三个特征。为了满足这三个特点，我们提出了LAN，它以排列不变的方式将不同的权重赋予实体的邻居，同时考虑邻居的冗余和查询关系。权值是在粗略的关系层次上根据逻辑规则估计的，在近邻层次上根据神经注意网络估计的。实验表明，LAN在两个典型的KG完成任务上显著优于基线模型。</p><div class="note note-primary"><p>我觉得 Logic Rule Mechanism 有没有可能再复杂点？</p></div></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/Papers/">Papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/KG/">KG</a> <a class="hover-with-bg" href="/tags/GNN/">GNN</a> <a class="hover-with-bg" href="/tags/LAN/">LAN</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/01/18/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E7%B4%A0%E6%9D%90%E6%95%B4%E7%90%86/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">论文写作素材整理</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/12/29/R-GCN%EF%BC%9AModeling%20Relational%20Data%20with%20Graph%20Convolutional%20Networks/"><span class="hidden-mobile">【R-GCN】Modeling Relational Data with Graph Convolutional Networks</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>