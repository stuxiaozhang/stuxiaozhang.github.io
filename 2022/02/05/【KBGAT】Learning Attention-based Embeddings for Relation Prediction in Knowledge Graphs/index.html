<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="【KBGAT】Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs这篇文章是印度的一个研究机构发表在 ACL 2019 上的文章，提出使用图注意力进行关系预测。
Basic Idea1. 解决了什么问题？(why？)
翻译模型和基于 CNN 的模型都是单独处理每个三元组，没有引入 KG 中临近"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>【KBGAT】Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="【KBGAT】Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-02-05 12:22" pubdate>2022年2月5日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.7k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 22 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">【KBGAT】Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</h1><p class="note note-info">本文最后更新于：2022年2月12日</p><div class="markdown-body"><h1 id="【KBGAT】Learning-Attention-based-Embeddings-for-Relation-Prediction-in-Knowledge-Graphs"><a href="#【KBGAT】Learning-Attention-based-Embeddings-for-Relation-Prediction-in-Knowledge-Graphs" class="headerlink" title="【KBGAT】Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs"></a>【KBGAT】Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</h1><p>这篇文章是印度的一个研究机构发表在 ACL 2019 上的文章，提出使用图注意力进行关系预测。</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><h3 id="1-解决了什么问题？-why？"><a href="#1-解决了什么问题？-why？" class="headerlink" title="1. 解决了什么问题？(why？)"></a>1. 解决了什么问题？(why？)</h3><ul><li>翻译模型和基于 CNN 的模型都是单独处理每个三元组，<strong>没有引入 KG 中临近实体表示中包含的潜在的丰富的语义关系。</strong></li><li>随着模型深度的增加，远方实体的贡献呈指数下降。</li></ul><h3 id="2-用什么方法解决？（how？）"><a href="#2-用什么方法解决？（how？）" class="headerlink" title="2. 用什么方法解决？（how？）"></a>2. 用什么方法解决？（how？）</h3><ul><li>将不同的权重（注意力）分配给附近的节点，并通过迭代方式通过层传播注意力。</li><li>提出的关系组合在n跳邻居之间引入辅助边，这样就很容易允许实体之间的知识流。加强现有的知识表示在语义相似关系簇的效果。</li><li>作者设计了一个encoder-decoder模型（图注意力模型和 ConvKB 的组合）</li></ul><p>文章目标有三：1) 捕捉给定节点的多跳关系；2）压缩封装某实体在不同关系下的多样性；3）加强现有的知识表示在语义相似关系簇的效果。</p><p>模型的做法通俗讲：为邻居节点分配不同的权重；通过层传播 Attention。为了处理多跳关系，通过关系组合在 KG 中添加辅助边，便于实体的 flow（后面有解释是为了聚合更多的信息）：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220207223553740.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><p>整体的模型也是 end-to-end 的结构，图 attention 作为编码器，ConvKB 作为解码器。</p><h3 id="3-我的想法"><a href="#3-我的想法" class="headerlink" title="3. 我的想法"></a>3. 我的想法</h3><ul><li>作者为多跳添加了辅助边，是为了缓解对于初始实体嵌入的遗忘，采用了 PTransE 中的将路径中所有关系嵌入的<strong>总和</strong>。除了 SUM，有没有其他的更好的表达形式？</li></ul><h2 id="Model-KBGAT"><a href="#Model-KBGAT" class="headerlink" title="Model: KBGAT"></a>Model: KBGAT</h2><h3 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h3><p>作者介绍了 GAT 的流程：<strong>GCN 中所有邻居的贡献是相等的，而 GAT 为邻居分配不同的重要性，其实本质就是加权的 GCN。</strong></p><p>某条边的绝对 attention 值，该值是该边的特征的重要性：</p><script type="math/tex;mode=display">e_{i j}=a\left(\mathbf{W} \overrightarrow{x_{i}}, \mathbf{W} \overrightarrow{x_{j}}\right)</script><p>GAT 某层某节点的表示：</p><script type="math/tex;mode=display">\overrightarrow{x_{i}^{\prime}}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \overrightarrow{x_{j}}\right)</script><ul><li>其中 $\alpha<em>{ij}$ 是 $e</em>{ij}$，其中 $\alpha$ 使用了 softmax 函数</li></ul><p>然后 GAT 采用多头注意力来稳定学习过程。多头注意力就是对多个注意力的结果进行拼接：</p><script type="math/tex;mode=display">\overrightarrow{x_{i}^{\prime}}=\|_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \overrightarrow{x_{j}}\right)</script><ul><li>其中, $k$ 是注意力头数，$||$ 表示 concatenation，$\sigma$ 表示任何非线性函数，$\alpha_{i j}^{k}$ 是由第 $k$ 注意机制计算的 $e_i$ 和 $e_j$ 之间的归一化注意力系数，$\mathbf{W}^{k}$ 表示第 $k$ 注意力机制的相应线性变换矩阵。</li></ul><p>GAT 最后一层的输出是使用<u>平均替代拼接</u>来计算的，以实现多头注意:</p><script type="math/tex;mode=display">\overrightarrow{x_{i}^{\prime}}=\sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \overrightarrow{x_{j}}\right)</script><ul><li>平均：$\frac{1}{K} \sum_{k=1}^{K}$</li></ul><h3 id="引入关系的重要性"><a href="#引入关系的重要性" class="headerlink" title="引入关系的重要性"></a>引入关系的重要性</h3><p><strong>GAT 最大的问题就是只提供了表示节点的方法，忽略了关系（边）的特征。</strong>因此模型定义了一个单个的 attention 层，用于整合关系和邻居节点的信息：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220210152641498.png" srcset="/img/loading.gif" lazyload style="zoom:40%"></p><p>通过在 entity 和 relation 特征向量的 拼接 + 线性变换 来得到 与 $e_i$ 相关的初始的三元组表示:</p><script type="math/tex;mode=display">\vec{c}_{i j k}=\mathbf{W}_{1}\left[\vec{h}_{i}\left\|\vec{h}_{j}\right\| \vec{g}_{k}\right]</script><ul><li>其中，$\vec{c}<em>{i j k}$ 是三元组 $t^{k}</em>{ij}=(e<em>i, r_k, e_j)$ 的向量表示, $\vec{h}</em>{i}$、$\vec{h}<em>{j} $和 $\vec{g}</em>{k}$ 分别表示实体 $e<em>i$、$e_j$ 和关系 $r_k$ 的嵌入。$\mathbf{W}</em>{1}$ 表示线性变换矩阵。</li></ul><p>接着用这个初始表示经过一个 LeakyReLU 函数得到每个三元组的绝对 attention 值 $b_{i j k}$:</p><script type="math/tex;mode=display">b_{i j k}=\operatorname{LeakyReLU}\left(\mathbf{W}_{2} c_{i j k}\right)</script><p>绝对 attention 值 $b<em>{i j k}$ 通过 softmax 变成相对 attention 值 $\alpha</em>{i j k}$:</p><script type="math/tex;mode=display">\begin{aligned}
\alpha_{i j k} &=\operatorname{softmax}_{j k}\left(b_{i j k}\right) \\
&=\frac{\exp \left(b_{i j k}\right)}{\sum_{n \in \mathcal{N}_{i}} \sum_{r \in \mathcal{R}_{i n}} \exp \left(b_{i n r}\right)}
\end{aligned}</script><ul><li>其中，$\mathcal{N}<em>{i}$ 表示实体 $e_i$ 的邻域，$\mathcal{R}</em>{i j}$ 表示连接实体 $e<em>{i}$ 和 $e</em>{j}$ 的关系集。</li></ul><p>所以，<strong>新实体 $e<em>i$ 的新嵌入表示为：每个三元组 $t^{k}</em>{ij}$ 表示 与 它们的注意值加权的总和</strong>:</p><script type="math/tex;mode=display">\overrightarrow{h_{i}^{\prime}}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \sum_{k \in \mathcal{R}_{i j}} \alpha_{i j k} c_{i j k}\right)</script><ul><li>注意：KG 中原有的边和添加的辅助边都有 attention 值。(看图2)</li></ul><p>引入多头注意力机制. 本质上是 $M$ 个独立的注意力机制计算嵌入，然后将嵌入连接起来，得到以下表示：</p><script type="math/tex;mode=display">\overrightarrow{h_{i}^{\prime}}=\|_{m=1}^{M} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j k}^{m} c_{i j k}^{m}\right)</script><ul><li>上述过程就是图中的1的过程。</li></ul><p>这就是图4中展示的图注意力层：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220211204903552.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>作者采用一个线性变化来获得关系嵌入矩阵</strong>：</p><script type="math/tex;mode=display">G^{\prime}=G . \mathbf{W}^{R}</script><ul><li><p>这是图4中2所示的部分。</p><blockquote><p>这个地方源码没看懂，不是三元组变成一个向量表示了吗？为啥这个地方又加入了关系嵌入向量？</p></blockquote></li></ul><p>在模型的最后一层，用求平均代替拼接来获得实体的最终嵌入向量：</p><script type="math/tex;mode=display">\overrightarrow{h_{i}^{\prime}}=\sigma\left(\frac{1}{M} \sum_{m=1}^{M} \sum_{j \in \mathcal{N}_{i}} \sum_{k \in \mathcal{R}_{i j}} \alpha_{i j k}^{m} c_{i j k}^{m}\right)</script><ul><li>这是图4中4所示的部分。</li></ul><p>然而，<strong>在学习新的嵌入时，实体会丢失其初始嵌入信息</strong>。为了解决这个问题，使用加权矩阵 $\mathbf{W}^{E}$ 对 $\mathbf{H}^{i}$ 进行线性变换以获得 $\mathbf{H}^{t}$ ，其中 $\mathbf{H}^{i}$ 表示模型的输入实体嵌入，$\mathbf{H}^{t}$ 表示转换实体嵌入，$T^i$ 表示初始实体嵌入的维度，$T^f$ 表示最终实体嵌入的维度。将这个初始实体嵌入信息添加到从最终注意力层 $\mathbf{H}^{f}$ 获得的实体嵌入中：</p><script type="math/tex;mode=display">\mathbf{H}^{\prime \prime}=\mathbf{W}^{E} \mathbf{H}^{t}+\mathbf{H}^{f}</script><ul><li>这是图4中3的部分，加入了初始的实体嵌入信息，3与4进行 concate。</li></ul><p>在模型的结构中，<strong>通过在两个实体之间引入 n 跳邻居的辅助关系，将无向边变为有向边，这个辅助关系的嵌入是路径中所有关系嵌入的总和</strong>。模型迭代地从实体的遥远邻居那里积累知识。一般来说，对于n层模型，传入的信息是在n-hop邻域上累积的。对于每个主要迭代，作者在每个广义 GAT 层之后和第一层之前规范化实体嵌入。</p><p>栗：图2 展示了学习新实体嵌入的聚合过程，以及在n跳邻居之间引入辅助边。在模型的第一层中，所有实体都从其入边的邻居捕获信息。在第二层中，<code>U.S</code> 从实体 <code>Barack Obama</code>, <code>Washington D.C</code>, <code>Chevrolet</code>, <code>Ethan Horvath</code> 收集信息，这些实体已经拥有前一层中关于其邻居 <code>Michelle Obama</code> 和 <code>Samuel L. Jackson</code> 的信息。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220207212303640.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h3 id="Training-Objective"><a href="#Training-Objective" class="headerlink" title="Training Objective"></a>Training Objective</h3><p>模型训练目标借用了 TransE 的评分函数的思想:</p><script type="math/tex;mode=display">L(\Omega)=\sum_{t_{i j} \in S} \sum_{t_{i j}^{\prime} \in S^{\prime}} \max \left\{d_{t_{i j}^{\prime}}-d_{t_{i j}}+\gamma, 0\right\}</script><ul><li>其中，$\gamma$ 是 margin 的超参数，$S$ 是正确三元组集，$S’$ 是不正确的三元组集.</li></ul><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>模型使用 ConvKB 作为解码器。卷积层的目的是分析一个三元组在每个维度上的全局嵌入特性，并推广我们模型中的过渡特性。具有多个特征映射的评分函数为：</p><script type="math/tex;mode=display">f\left(t_{i j}^{k}\right)=\left(\|_{m=1}^{\Omega} \operatorname{ReLU}\left(\left[\vec{h}_{i}, \vec{g}_{k}, \vec{h}_{j}\right] * \omega^{m}\right)\right) \cdot \mathbf{W}</script><ul><li>其中, $\omega^{m}$ 表示第m个卷积滤波器，$\Omega$ 是超参数，表示使用的过滤器数量，$∗$ 是一个卷积操作，$\mathbf{W}$ 表示一个线性变换矩阵，用于计算三元组的最终分数。</li></ul><p>该模型采用 soft-margin 损失作为损失函数：（loss 不是基于 margin 的）</p><script type="math/tex;mode=display">\begin{array}{l}
\mathcal{L}=\sum_{t_{i j}^{k} \in\left\{S \cup S^{\prime}\right\}} \log \left(1+\exp \left(l_{t_{i j}^{k}} f\left(t_{i j}^{k}\right)\right)\right)+\frac{\lambda}{2}\|\mathbf{W}\|_{2}^{2} \\
\text { where } l_{t_{i j}^{k}}=\left\{\begin{array}{ll}
1 & \text { for } t_{i j}^{k} \in S \\
-1 & \text { for } t_{i j}^{k} \in S^{\prime}
\end{array}\right.
\end{array}</script><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>模型遵循一个两步训练过程，即首先训练编码器 GAT，以编码有关图中的实体和关系的信息。然后训练解码器 ConvKB，以执行关系预测任务。原始的GAT更新方程仅聚合从1跳邻域传递的信息，而本文的广义GAT使用来自n跳邻域的信息。使用辅助关系在稀疏图中聚集更多关于邻域的信息。</p><h3 id="Link-Prediction"><a href="#Link-Prediction" class="headerlink" title="Link Prediction"></a>Link Prediction</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220207222311444.png" srcset="/img/loading.gif" lazyload alt=""></p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220207221741300.png" srcset="/img/loading.gif" lazyload style="zoom:63%"></p><h3 id="Attention-Values-vs-Epochs"><a href="#Attention-Values-vs-Epochs" class="headerlink" title="Attention Values vs Epochs"></a>Attention Values vs Epochs</h3><p>在学习过程的初始阶段，注意力是随机分布的。随着训练的进行，模型从邻居那里收集更多的信息，它将更多的注意力放在直接邻居身上，并从更遥远的邻居那里获取次要信息。一旦模型收敛，它将学习从节点的n-hop邻域收集多跳和集群关系信息。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220207222737558.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>没看懂….</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>文章提出了一个端到端的模型用于链接预测，图 attention（GAT）作为 encoder，ConvKB 作为解码器。此外，扩展了图 attention，为多跳添加了辅助边，以捕获给定实体的多跳邻域中的实体和关系特征。图 attention 其实就是加权的图卷积（WGCN），还有 PageRank，核心思想都是信息流动，用邻居节点表示当前节点。要说不同的话，就是 KBGAT 用的权重是通过一个定义的单个的 attention 层计算出来的，而 WGCN 没有详细介绍它的权重是怎么来的（作为参数训练还是怎样）。</p><p>作者提出的未来方向：扩展模型，以便更好地处理层次图，并在我们的图形注意模型中捕捉实体（如母题）之间的高阶关系。</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/Papers/">Papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/KG/">KG</a> <a class="hover-with-bg" href="/tags/GNN/">GNN</a> <a class="hover-with-bg" href="/tags/KBGAT/">KBGAT</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/02/12/%E3%80%90AttnPath%E3%80%91Incorporating%20Graph%20Attention%20Mechanism%20into%20Knowledge%20Graph%20Reasoning%20Based%20on%20%20Deep%20Reinforcement%20Learning/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">【AttnPath】Incorporating Graph Attention Mechanism into Knowledge Graph Reasoning Based on Deep Reinforcement Learning</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2022/02/03/Deep%20Learning%20with%20PyTorch%20A%2060%20Minute%20Blitz%EF%BC%9A%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="hidden-mobile">Deep Learning with PyTorch：A 60 Minute Blitz 学习笔记</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>