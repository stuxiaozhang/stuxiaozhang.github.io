<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150132.png"><link rel="icon" href="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150132.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="Learning transferable architectures for scalable image recognition

CVPR 2018

这篇文章出自Google Brain，是对他们之前发表在ICLR2017的论文《Neural Architecture Search with Reinforcement Learning》的改进.

简单的阅读笔记在这。

"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>【NASNet】Learning transferable architectures for scalable image recognition - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150632.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="【NASNet】Learning transferable architectures for scalable image recognition"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-07-16 09:48" pubdate>2022年7月16日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 19 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">【NASNet】Learning transferable architectures for scalable image recognition</h1><p class="note note-info">本文最后更新于：2022年7月18日</p><div class="markdown-body"><h1 id="learning-transferable-architectures-for-scalable-image-recognition">Learning transferable architectures for scalable image recognition</h1><ul><li>CVPR 2018</li></ul><p>这篇文章出自Google Brain，是对他们之前发表在ICLR2017的论文《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.01578v2">Neural Architecture Search with Reinforcement Learning</a>》的改进.</p><blockquote><p><a href="https://stuxiaozhang.github.io/2022/04/05/Neural%20Architecture%20Search%20with%20reinforcement%20learning/">简单的阅读笔记在这。</a></p></blockquote><blockquote><p>我的想法：</p><ol type="1"><li>为什么NASNet的cell必须是5个(小)块组成？这是不是有些局限？</li><li>改进的ScheduledDropPath中，cell中的每个路径以一个在训练中呈线性增加的概率被丢弃。这块能不能有些改进？</li></ol></blockquote><h2 id="basic-idea">Basic Idea</h2><p>这篇文章研究了一种新的卷积结构设计范式，并描述了一种优化卷积结构的可扩展方法。作者认为直接将NAS或任何其他搜索方法应用于大型数据集的计算代价比较昂贵，所以文章建议先在一个代理数据集（例如较小的CIFAR-10数据集）上搜索一个好的体系结构，然后再迁移到ImageNet这样的大数据集上去。作者通过设计了一个NASNet搜索空间来实现这种可迁移性，使得体系结构的复杂性与网络的深度和输入图像的大小无关。更具体地说，搜索空间中的所有卷积网络都是由具有相同结构但不同权重的卷积层（或cell）组成的。所以说，搜索最佳卷积结构被简化为搜索最佳cell结构。这么做的优势在于比搜索整个网络结构快得多，而且更容易泛化到其他问题上去。</p><p>总的来说本文贡献如下：</p><ol type="1"><li><p>这篇文章关键的贡献在于设计了一种新的搜索空间，即NASNet搜索空间。不像之前的工作直接搜索整个网络结构，这篇文章是先搜索一个最好的网络层（或者叫卷积cell）然后再将其堆叠起来构建网络。</p><blockquote><p>作者的灵感来自于：SOTA的CNN架构设计往往是由重复的motifs组成的，包括卷积滤波器组、非线性以及谨慎选择的连接的一个组合，比如ResNet中的残差模块，Inception中的Inception模块等。</p></blockquote></li><li><p>文章中还提出了一种新的正则化技术ScheduledDropPath以提高NASNet模型的泛化能力。从结果上来看，搜索得到的NASNet在CIFAR-10上实现了SOTA，迁移到ImageNet上后也实现了SOTA。</p></li><li><p>NASNet学到的特征也可以迁移到其他任务上，比如在目标检测上同样超过了SOTA。</p></li></ol><h2 id="method">Method</h2><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717101629.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>这篇文章采用的主要搜索方法还是<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.01578v2">他们团队前一篇论文《Neural Architecture Search with Reinforcement Learning》</a>提出的如图1所示的NAS框架。控制器为一个RNN，其采样不同结构的子网络。通过训练子网络直至收敛得到在验证集上的精度<span class="math inline">\(R\)</span>，用此精度更新控制器，从而控制器随着时间的推移可以生成更好的体系结构。这里控制器权重使用策略梯度（policy gradient）进行更新。</p><p>这篇文章的主要贡献是设计了一个新的搜索空间NASNet，以便在CIFAR-10数据集上找到的最佳架构可以扩展到更大、更高分辨率的图像数据集上去。至于NASNet搜索空间的灵感来源，则是因为SOTA的CNN架构设计往往是由重复的motifs组成的，包括卷积滤波器组、非线性以及谨慎选择的连接的一个组合，比如ResNet中的残差模块，Inception中的Inception模块等。这些观察表明，控制器RNN可能预测用这些motifs表达的一般卷积cell。这个cell可以串联起来处理任意空间尺寸和滤波器深度的输入。本文的方法中，CNN的总体架构是手动预先确定的，它们由多次重复的卷积cell组成，每个卷积cell具有相同的结构，但权重不同。文中也提出了两种motifs，分别是Normal Cell和Reduction Cell，区别就是一个不用池化、一个用了：</p><ol type="1"><li>Normal Cell：输出Feature Map和输入Feature Map的尺寸相同</li><li>Reduction Cell：输出Feature Map对输入Feature Map进行了一次降采样，其中特征图高度和宽度减少了两倍（用了stride=2）</li></ol><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717102839.png" srcset="/img/loading.gif" lazyload style="zoom:70%"></p><p>如图2所示，以CIFAR-10和ImageNet为例给了两种结构，因为ImageNet的图片尺寸更大，所以用了更多的Reduction Cell。而且每当空间尺寸减小时，输出中的滤波器数量加倍，以保持大致恒定的隐藏状态的维度。重要的是，文中将motif重复次数<span class="math inline">\(N\)</span>和初始卷积滤波器的数量视为自由参数（人为事先指定的），可以根据图像分类问题的规模进行调整。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717140400.png" srcset="/img/loading.gif" lazyload></p><p>如图为NASNet搜索空间示意图。网络的motifs是在称为block的阶段中递归构建的。每个block由控制器RNN选择一对隐藏状态（深灰色）、对这些隐藏状态执行的操作（黄色）和组合操作（绿色）组成。生成的隐藏状态保留在将在后续块上选择的潜在隐藏状态集中。</p><p>所以实际中改变的就只是Normal和Reduction Cell的结构，这个正好可以用RNN进行搜索。cell的结构可以在如下定义的搜索空间内搜索。</p><p>在NASNet的搜索空间中，每个cell接收两个初始隐藏状态<span class="math inline">\(h_i\)</span>和<span class="math inline">\(h_{i-1}\)</span>作为输入，这两个状态是前两个较低层或输入图像中两个cell的输出。给定这两个初始隐藏状态，控制器RNN递归预测卷积cell的其余结构（图3）。控制器对每个单元的预测被分组为B块，其中每个块有5个预测步骤，由5个不同的softmax分类器进行，对应于块元素的离散选择：</p><p><strong>Step 1.</strong> 从<span class="math inline">\(h_{i}\)</span>、<span class="math inline">\(h_{i-1}\)</span>或在先前块中创建的隐藏状态集中选择隐藏状态。</p><p><strong>Step 2.</strong> 从与Step 1相同的选项中选择第二个隐藏状态。</p><p><strong>Step 3.</strong> 选择要应用于在Step 1中选择的隐藏状态的操作</p><p><strong>Step 4.</strong> 选择要应用于在Step 2中选择的隐藏状态的操作</p><p><strong>Step 5.</strong> 选择一种方法来组合Step 3和4的输出以创建新的隐藏状态</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717154853.png" srcset="/img/loading.gif" lazyload></p><p>上图是用于递归构造卷积cell的一个block的控制器模型体系结构。 每个模块需要选择5个离散参数，每个参数对应于softmax层的输出。 右侧显示的示例构造块。 卷积cell包含B个块，因此控制器包含5B个softmax层，用于预测卷积cell的体系结构。实验中，B=5。</p><p>该算法将新创建的隐藏状态附加到现有的隐藏状态集，作为后续块中的潜在输入。控制器RNN将上述5个预测步骤重复B次，对应于卷积cell中的B个块。在步骤3和4中，控制器RNN选择要应用于隐藏状态的操作从下面的操作中选择：</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717132223.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><p>在步骤5中，控制器RNN选择一种方法来组合两个隐藏状态，或者（1）两个隐藏状态之间的element-wise相加，或者（2）沿滤波器维度两个隐藏状态之间的级联。为了使控制器RNN能够同时预测Normal Cell和Reduction Cell，只需使控制器总共有2×5B个预测，其中第一个5B预测用于Normal Cell，第二个5B预测用于Reduction Cell。最后，这项工作还是用了之前工作用到的强化学习方案。</p><h2 id="experiments">Experiments</h2><p>首先所有架构搜索都是在CIFAR-10分类任务上进行的。然后跟前一篇论文一样，还是用近端策略优化（PPO）训练RNN。实验用500个GPU（P100）跑了超过4天。</p><p>如图5所示是搜索得到的Normal Cell和Reduction Cell，可以看到深度可分离卷积的大量使用。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717155130.png" srcset="/img/loading.gif" lazyload></p><p>图5. 用CIFAR-10确定的B = 5个块的最佳卷积cell（NASNet-A）的体系结构。每个卷积单元都是B个块的结果。 单个块对应于两个基本操作（黄色）和一个组合操作（绿色）。</p><p>在学习了卷积cell之后，可以探索几个超参数来为给定任务构建最终网络：（1）cell重复次数N和（2）初始卷积cell中的滤波器数。 选择初始滤波器的数量之后，只要stride为2，就将滤波器的数量加倍。</p><p>然后作者在训练NASNet时，又发现了ScheduledDropPath，作为DropPath的一个改进版本，是NASNet的一种有效的正则化方法。在Drop-Path中，训练过程中每条路径以固定的概率被随机丢弃。 在这个<u>改进版本的ScheduledDropPath中，cell中的每个路径以一个在训练过程中呈线性增加的概率被丢弃。</u></p><blockquote><p>这块有没有可能试着改进一下？</p></blockquote><h3 id="cifar-10分类任务结果">CIFAR-10分类任务结果</h3><p>如表1所示是实验结果，可以看到带cutout的大模型NASNet-A实现了SOTA的准确率</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717155624.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h3 id="imagenet分类任务结果">ImageNet分类任务结果</h3><p>作者强调他们还是使用了CIFAR-10上的最优网络，只是在ImageNet上从头重新开始训练。表2、表3和图5分别展示了结果。基本上NASNet都实现了新的SOTA（不管是大模型亦或是轻量级模型），也实现了更好的trade-off。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717155710.png" srcset="/img/loading.gif" lazyload></p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717155723.png" srcset="/img/loading.gif" lazyload></p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717155818.png" srcset="/img/loading.gif" lazyload></p><h3 id="架构搜索方法的效率">架构搜索方法的效率</h3><p>文章还研究了强化学习在CIFAR-10图像分类问题上用于架构搜索的有效性，并将其与暴力随机搜索进行了比较（基于等量计算资源）。结果如图7所示，用RL获得的最佳模型明显优于RS发现的最佳模型。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220717155925.png" srcset="/img/loading.gif" lazyload style="zoom:40%"></p><h2 id="summary">Summary</h2><p>本文提出的方法的关键见解是设计一个搜索空间，该空间将架构的复杂性与网络的深度分离。 由此产生的搜索空间可以在小型数据集（即CIFAR-10）上识别出良好的架构，并将学习到的架构迁移到一系列具有不同数据和计算规模的图像分类任务中去。与人工设计的架构相比，最终的架构在CIFAR-10和ImageNet数据集中的性能都达到或超过了SOTA的性能。同时，可以以更少的计算预算使用学习到的架构来执行ImageNet分类，并且超过了针对移动和嵌入式平台的简化架构。</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/papers/">papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/RL-NAS/">RL-NAS</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/07/17/%E3%80%90Aging%20Evolution%E3%80%91Regularized%20Evolution%20for%20Image%20Classifier%20Architecture%20Search/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">【Aging Evolution】Regularized Evolution for Image Classifier Architecture Search</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2022/07/15/Understanding%20and%20Simplifying%20One-Shot%20Architecture%20Search/"><span class="hidden-mobile">Understanding and Simplifying One-Shot Architecture Search</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>