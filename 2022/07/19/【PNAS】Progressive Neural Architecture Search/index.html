<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150132.png"><link rel="icon" href="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150132.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="Progressive Neural Architecture Search

ECCV 2018

这篇文章还是出自Google，进一步改善之前发表在AAAI2019的论文《Regularized Evolution for Image Classiﬁer Architecture Search》里所提出的方法的搜索速度。

关于《Regularized Evolution for "><meta name="author" content="小张同学"><meta name="keywords" content=""><title>【PNAS】Progressive Neural Architecture Search - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150632.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="【PNAS】Progressive Neural Architecture Search"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-07-19 11:19" pubdate>2022年7月19日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.7k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 20 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">【PNAS】Progressive Neural Architecture Search</h1><p class="note note-info">本文最后更新于：2022年10月7日</p><div class="markdown-body"><h1 id="progressive-neural-architecture-search">Progressive Neural Architecture Search</h1><ul><li>ECCV 2018</li></ul><p>这篇文章还是出自Google，进一步改善之前发表在AAAI2019的论文<a target="_blank" rel="noopener" href="http://128.84.4.27/abs/1802.01548">《Regularized Evolution for Image Classiﬁer Architecture Search》</a>里所提出的方法的搜索速度。</p><blockquote><p><a href="https://stuxiaozhang.github.io/2022/07/17/%E3%80%90Aging%20Evolution%E3%80%91Regularized%20Evolution%20for%20Image%20Classifier%20Architecture%20Search/">关于《Regularized Evolution for Image Classiﬁer Architecture Search》简单的阅读笔记。</a></p></blockquote><h2 id="basic-idea">Basic Idea</h2><p>这篇文章提出了一种新的学习CNN架构的方法，比最近基于强化学习和进化算法的SOTA的方法更高效。本文的方法使用了基于序列模型的优化（SMBO）策略，在该策略中，按照增加复杂性的顺序搜索结构，同时学习代理模型以引导结构空间搜索。在相同搜索空间下的直接比较表明，就评估的模型数量而言，本文提出的方法的效率比之前NASNet用到的RL方法高5倍，而就总计算而言则高了8倍。然后搜索到的结构在CIFAR-10和ImageNet上也达到了SOTA的分类精度。</p><h2 id="method">Method</h2><p>NASNet的搜索空间（任务）是搜索一个好的卷积Cell，而不是一个完整的CNN。一个Cell包含B个blocks，其中一个block是应用于两个输入（张量）的组合运算符（例如相加），每个输入（张量）可以在组合之前进行变换（例如，卷积）。然后，根据训练集的大小和最终CNN所需的运行时间，将该单元结构堆叠一定次数。</p><h3 id="search-space">Search Space</h3><h4 id="cell-topologies">Cell Topologies</h4><p>实际一个cell就是一个完全卷积的网络，它将一个<span class="math inline">\(H\times W\times F\)</span>张量映射到另一个<span class="math inline">\(H&#39;\times W&#39;\times F&#39;\)</span>张量（自然stride=1时<span class="math inline">\(H、W、F\)</span>与<span class="math inline">\(H&#39;、W&#39;、F&#39;\)</span>就是一样的，stride=2时则有<span class="math inline">\(H&#39; = H / 2、W &#39;= W / 2、F&#39; =F/ 2\)</span>）。</p><p>cell可以由由B个块组成的DAG（有向无环图）表示，每个块是从2个输入张量到1个输出张量的映射。可以将一个cell中的块b指定为5元组(<span class="math inline">\((I_{1};I_{2};O_{1};O_{2};C)\)</span>，其中<span class="math inline">\(I_{1},I_{2}\in \mathcal{I}_{b}\)</span>指定块的输入，<span class="math inline">\(O_{1},O_{2}\in \mathcal{O}\)</span>指定应用于输入<span class="math inline">\(I_{i}\)</span>的操作，<span class="math inline">\(C\in \mathcal{C}\)</span>指定如何将<span class="math inline">\(O_{1}\)</span>和<span class="math inline">\(O_{2}\)</span>组合以生成与该块输出相对应的特征图（张量），用<span class="math inline">\(H_{b}^{c}\)</span>表示。可能的输入的集合<span class="math inline">\(\mathcal{I}_{b}\)</span>是这个cell中所有先前块的集合<span class="math inline">\(\{H_{1}^{c},\dots,H_{b-1}^{c}\}，\)</span>加上先前cell的输出<span class="math inline">\(H_{B}^{c-1}\)</span>，加上更先前单元的输出<span class="math inline">\(H_{B}^{c-2}\)</span>。</p><figure><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220719143837.png" srcset="/img/loading.gif" lazyload alt="这里引用一下NASNet的图"><figcaption>这里引用一下NASNet的图</figcaption></figure><p>算子空间<span class="math inline">\(\mathcal{O}\)</span>是以下8个函数的集合（比NASNet的少是因为去掉了一些没用到的函数），每个函数对一个张量进行运算：</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220719132755.png" srcset="/img/loading.gif" lazyload></p><p>可能的组合运算符<span class="math inline">\(\mathcal{C}\)</span>的空间，NASNet中同时考虑了元素级相加（elementwise addition）和级联（concatenation）。但因为NASNet的结果中并没有使用到级联，所以为了减少搜索空间，总是使用加法作为组合运算符。也就是说一个块可以减少为用一个4元组表示。</p><p>第b个块的可能结构的空间为<span class="math inline">\(\mathcal{B}_{b}\)</span>；其大小<span class="math inline">\(|\mathcal{B}_{b}|=|\mathcal{I}_{b}|^{2}\times|\mathcal{O}|^{2}\times|\mathcal{C}|\)</span>，其中<span class="math inline">\(|\mathcal{I}_{b}|=(2+b-1)∣,|\mathcal{O}|=8\)</span>和<span class="math inline">\(|\mathcal{C}|=1\)</span>。对于b=1，有<span class="math inline">\(\mathcal{I}_{1}=\{H_{B}^{c-1},H_{B}^{c-2}\}\)</span>，这是前两个cell的 最终输出，因此有<span class="math inline">\(|\mathcal{B}_{1}\)</span>个可能的块结构。如果允许最多<span class="math inline">\(B=5\)</span>个块的cell，那么cell结构的总数由<span class="math inline">\(|\mathcal{B}_{1:5}|=2^{2}\times 8^{2} \times 3^{2}\times 8^{2} \times 4^{2}\times 8^{2} \times 5^{2}\times 8^{2} \times 6^{2}\times 8^{2}=5.6\times 10^{14}\)</span>给出。但是，此空间存在一定的对称性，可将其修剪到更合理的大小。事实上cell的总数约为<span class="math inline">\(10^{12}\)</span>。这比NASNet中使用的搜索空间（<span class="math inline">\(10^{18}\)</span>）小得多，但是它仍然是一个非常大的搜索空间，需要高效的优化方法。</p><h4 id="从cell到cnn">从cell到CNN</h4><p>要评估一个cell需要将其转换为CNN。 为此使用stride=1或stride=2堆叠预定数量的基本cell（具有相同的结构，但未固定权重），如图1（右）所示。然后相应地调整stride=2的cell之间的stride=1的cell的数量，最多重复N次。 在网络的顶部使用全局平均池化，然后使用softmax分类层。 然后在数据集上训练堆叠模型。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220719145318.png" srcset="/img/loading.gif" lazyload></p><p>图1. 左：由渐进神经体系结构搜索发现的最佳cell结构，包括5个块。 右：在CIFAR-10和ImageNet上，由cell构建CNN时，采用与NASNet类似的策略。 注意这里学习的是单个cell的类型，而不区分Normal Cell和Reduction Cell。</p><p>CNN的整体构建过程与NASNet相同，只是这里只使用一种cell类型（不区分Normal Cell和Reduction Cell，而是通过使用stride为2的Normal Cell来模拟Reduction Cell），cell搜索空间稍小（因为使用较少的算子和合并操作）。</p><h3 id="progressive-neural-architecture-search-1">Progressive Neural Architecture Search</h3><p>许多先前的方法直接在完整cell或更糟糕的是完整的CNN的空间中搜索。作者认为，在指数级的大搜索空间中直接搜索是困难的，特别是在一开始并不知道什么是好模型的时候。</p><p>因此作者建议按先搜索最简单模型的递进顺序搜索空间。首先从<span class="math inline">\(\mathcal{B}_{1}\)</span>开始构造所有可能的cell结构（即由1个块组成），然后将它们添加到队列中。接着训练并评估队列中的所有模型（并行方式），然后通过添加<span class="math inline">\(\mathcal{B}_{2}\)</span>所有可能的块结构来扩展每个模型；这生成了一组<span class="math inline">\(|\mathcal{B}_{1}|\times|\mathcal{B}_{2}|=256\times 576=147,456\)</span>个深度为2的候选cell。因为负担不起训练和评估所有这些子网络的代价，所以这里用了一个学习到的<strong>预测函数</strong>（根据迄今为止访问过的cell的性能对其训练，且其训练和应用所需的时间可以忽略不计）。然后使用这个预测函数来评估所有候选cell，并选择K个最有希望的cell。将它们添加到队列中，并重复该过程，直到找到具有足够数量的块（B个）的cell。伪代码参见算法1，图2是一个示例。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220719114508.png" srcset="/img/loading.gif" lazyload></p><p>下图是当最大块数为B=3时PNAS搜索过程。此处<span class="math inline">\(S_b\)</span>表示具有B块的候选cells集。首先考虑具有1个块的所有单元，<span class="math inline">\(S_1=B_1\)</span>；训练和评估所有这些cells，并更新预测值。在迭代2中，将<span class="math inline">\(S_1\)</span>中的每个单元展开，以获得具有2个块的所有单元，<span class="math inline">\(S_2&#39;=B_{1:2}\)</span>，预测他们的分数，选择前K个得到<span class="math inline">\(S_2\)</span>，训练和评估他们，并更新预测值。在迭代3中，展开<span class="math inline">\(S_2\)</span>中的每个单元，以获得具有3个块的单元子集，<span class="math inline">\(S_3’⊆ B_{1:3}\)</span>，预测他们的分数，选择前K名获得<span class="math inline">\(S_3\)</span>，训练并评估他们，然后返回获胜者。<span class="math inline">\(B_b=| B_b |\)</span>是b级可能的块数，K是波束大小（在搜索树的每个级别上训练和评估的模型数）。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220719151948.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><h3 id="基于代理模型的性能预测">基于代理模型的性能预测</h3><p>如上所述需要一种机制来预测cell的最终性能，然后才能真正训练它。这种预测器至少有三个期望的特性：</p><ul><li><em>处理可变大小的输入</em>：即需要预测器来处理可变长度的输入字符串。特别是，它应该能够预测任何具有b+1个块的cell的性能，即使它只在具有最多b个块的cell上训练过。</li><li><em>与真实性能相关</em>：事实上不一定要求低MSE，只需要预测器按照与真实性能值大致相同的顺序排列模型即可。</li><li><em>样本效率</em>：希望训练和评估尽可能少的cell，这意味着预测器的训练数据将是稀缺的</li></ul><p>要求预测器能够立即处理可变大小的字符串，RNN就可以。这里作者使用了LSTM读取长度为4b的序列（表示每个块的<span class="math inline">\(I_{1}、I_{2} O_{1}\)</span>和<span class="math inline">\(O_{2}\)</span>），每个步骤的输入是大小为<span class="math inline">\(|\mathcal{I}_{b}|\)</span>或<span class="math inline">\(|\mathcal{O}|\)</span>的一个one-hot向量，然后是嵌入查找（embedding lookup）。对tokens <span class="math inline">\(I_{1},I_{2}\in\mathcal{I}\)</span>使用维度D的共享嵌入，而对<span class="math inline">\(O_{1},O_{2}\in|\mathcal{O}|\)</span>使用另一个共享嵌入。最终的LSTM隐藏状态通过一个全连接层和sigmoid来回归验证精度。作者还尝试了一个更简单的MLP basline，如下所示将cell转换为一个固定长度的向量：将每个token嵌入到一个D维向量中，concat每个块的嵌入以获得一个4D维的向量，然后对块进行平均。</p><p>训练预测器时，一种方法是使用新的数据，通过几步SGD来更新预测器的参数。 但是，由于样本量很小，因此作者将5个预测器合为一组，每个预测器（从头开始）拟合搜索过程每一步可用数据的4/5。作者声称这减少了预测的方差。最后作者认为未来可以研究其他类型的预测器，例如具有字符串核的高斯过程，这可能可以更有效地训练和产生具有不确定性估计的预测。</p><blockquote><p>听不懂</p></blockquote><h2 id="summary">Summary</h2><p>这项工作的主要贡献是展示如何通过在日益复杂的搜索空间中使用渐进搜索，结合学习的预测函数，有效地识别最有希望探索的模型，来加速搜索良好的CNN结构。结果模型实现了与以前工作相同的性能水平，但计算成本很小。</p><p>未来的工作有很多可能的方向，包括：使用更好的代理predictor，例如string kernels的高斯过程；使用基于模型的早停止，因此可以在到达E1时代之前停止训练“无希望”的模型；使用“热启动”，从较小的父模型初始化训练较大的b+1模型；使用贝叶斯优化，其中我们使用获取函数，如预期改进或置信上限，对候选模型进行排序，而不是贪婪地挑选前K个；自适应地改变在每个步骤中评估的模型K的数量（例如，随着时间的推移减少）；速度-精度权衡的自动探索，等等。</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/Papers/">Papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/PNAS/">PNAS</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/07/28/git/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Git笔记</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2022/07/17/%E3%80%90Aging%20Evolution%E3%80%91Regularized%20Evolution%20for%20Image%20Classifier%20Architecture%20Search/"><span class="hidden-mobile">【Aging Evolution】Regularized Evolution for Image Classifier Architecture Search</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>