<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150132.png"><link rel="icon" href="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150132.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="Understanding and Simplifying One-Shot Architecture Search

ICML 2018

本文重在探究为什么One-Shot模型中的权重能被众多不同的架构共享，并且是有效的。通过实验分析，证明了在没有超网络或RL的情况下，从复杂的搜索空间中有效地识别有效的网络结构是可能的。
Basic Idea
这篇论文是基于参数共享的，作者训练了一"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>Understanding and Simplifying One-Shot Architecture Search - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220330150632.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="Understanding and Simplifying One-Shot Architecture Search"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-07-15 21:25" pubdate>2022年7月15日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 3k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 21 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">Understanding and Simplifying One-Shot Architecture Search</h1><p class="note note-info">本文最后更新于：2022年7月16日</p><div class="markdown-body"><h1 id="understanding-and-simplifying-one-shot-architecture-search">Understanding and Simplifying One-Shot Architecture Search</h1><ul><li>ICML 2018</li></ul><p>本文重在探究<strong>为什么One-Shot模型中的权重能被众多不同的架构共享，并且是有效的</strong>。通过实验分析，证明了在没有超网络或RL的情况下，从复杂的搜索空间中有效地识别有效的网络结构是可能的。</p><h2 id="basic-idea">Basic Idea</h2><p>这篇论文是基于参数共享的，作者训练了一个可以表述所有子结构的大网络。搜索空间的大小随选择的数量呈指数增长，而one-shot模型的大小仅呈线性增长。相同的权重用于评估许多不同的体系结构，从而将运行体系结构搜索所需的资源减少了数量级。</p><p>但是作者基于此也提出了一个问题：<u>为什么不同的结构可以共享一个权重集合？</u>即，一组固定的权重可以在广泛的体系结构中很好地工作的想法也是违反直觉的。SMASH（采用超网）和ENAS（采用RL控制器）也尝试解决这个问题。而本文作者的<strong>目标是了解权重共享在体系结构搜索方法中所起的作用</strong>。而实验表明，要获得好的结果，既不需要超网，也不需要RL控制器。为此作者训练了一个大的one-shot模型，包含了搜索空间里的每个可能的操作。然后剔除一些操作，测量其对模型预测准确率的影响。作者发现网络自动将其能力集中在对产生良好预测最有用的操作上。剔除不太重要的操作对模型的预测的影响很小，而剔除很重要的操作对模型预测的影响很大。实际上，可以通过观察网络结构在训练集中无标签样例的行为，来预测网络在验证集上的准确率。</p><h2 id="one-shot-architecture-search">One-Shot Architecture Search</h2><p>One-Shot Model 四步：</p><ol type="1"><li>设计一个搜索空间，允许使用单个 One-Shot Model 表示各种架构。</li><li>训练 One-Shot Model ，使其预测架构的验证精度。</li><li>使用预先训练的 One-Shot Model 评估验证集上的候选架构。</li><li>从头开始重新训练最有前途的架构，并在测试集上评估其性能。</li></ol><h3 id="search-space-design">1. Search Space Design</h3><p>给 One-Shot Model 设计一个良好的搜索空间的要求：</p><ol type="1"><li>搜索空间应该足够大和有表现力，以捕获各种候选架构。</li><li>One-Shot Model 产生的验证集精度必须能够预测独立模型训练产生的精度。</li><li>在有限资源条件（即内存和时间）下，one-shot应该足够小。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220716120154.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>如上例所示：不同于分别训练三个模型，作者训练一个包括了这三个操作的模型（one-shot model），然后在验证阶段，选择性地剔除其中两个操作的输出，来模拟仅包含输入2的网络。一般而言，可以选择enable或disable输入连接的任何组合。这样，搜索空间的大小随输入的跨连接的数量呈指数增长，而one-shot模型的大小呈线性增长。在concat后总是进行 <span class="math inline">\(1×1\)</span> 卷积，无论有多少输入跨连接，卷积中的输出滤波器的数量都保持不变。之后对 <span class="math inline">\(1×1\)</span> 卷积的输出运用不同的操作，并将结果sum起来。在评估阶段，可以将其中的一些操作置零或者从网络中删除。在上例中，操作方式有3x3卷积、5x5卷积、最大池化和Identity，但只有5x5卷积操作留了下来。</p><p>这个方法对于更大的模型也是适用的，如下图。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220716103322.png" srcset="/img/loading.gif" lazyload></p><p>网络可以看做有几个相同的cell堆叠在一起组成的（图左1），每一个cell中有固定数目的<em>choice block</em>（图左2），这些<em>choice block</em>的输入来自于前驱cell的输出和同一个cell下前驱<em>choice block</em>的输出。作者设置的cell中有4个<em>choice block</em>，即 <span class="math inline">\(N_{choice}= 4\)</span>（图里好像只画了3个），每个<em>choice block</em>最多可以从五个可能的输入中进行选择：两个来自前驱cell的输出，最多三个来自同一个cell下前驱<em>choice block</em>的输出（例如图左2最下面五个输入进行concat）。每个<em>choice block</em>包括七种操作（图左3），有identity(应该是跳跃连接)，3x3深度可分离卷积，5x5深度可分离卷积，7x7深度可分离卷积、1x7卷积跟7x1卷积，最大池化，平均池化。</p><h3 id="training-the-one-shot-model">2. Training the One-Shot Model</h3><p>One-shot模型是用带动量的SGD训练的标准大型神经网络。为了确保特定架构的one-shot模型精度与stand-alone模型精度之间良好关联，需要讨论以下几个方面。</p><p><strong>互相适应的鲁棒性（Robustness to Co-adaptation）</strong>： 在评估阶段，我们通过zero out一些连接，得到了一些特定的结构。尽管移除了不重要的操作，也可能会导致模型的预测性能严重下降，one-shot模型和独立模型之间的准确率的关系也会退化。为了解决这个问题，作者引入了<strong>path dropout机制</strong>，训练one-shot模型的时候，在每一批次中随机将一些操作剔除。在训练开始 disable path dropout，随着训练的进行逐步线性的增加 dropout rate，这样可以达到了一个较好的结果。在训练结束时dropout rate 设置为 <span class="math inline">\(r^{1/k}\)</span>，其中 <span class="math inline">\(0&lt;r&lt;1\)</span> 为一个超参数，<span class="math inline">\(k\)</span> 为给定一个操作下输入路径的数量。<u>fan-in的值越大，dropout rate越高</u>。对于一个cell，不同的operation的都是彼此独立的剔除（这样有益处），对于一个model包含多个cell，则相同的operation将被一并剔除。</p><p><strong>Stabilizing Model Training</strong>：在早期实验中，模型的训练非常的不稳定，作者发现小心的使用BN可以使训练稳定，文章中采用了BN-Relu-Conv这种规则。因为在评估阶段会剔除一些操作，这样就是BN统计量发生了变化，因此批BN在评估时的应用方式与在训练时完全相同——动态计算batch的统计信息。</p><p>作者发现如果在单个批处理中为每个示例剔除掉相同的路径，one-shot模型训练就会变得不稳定。相反如果每个示例剔除不同路径，它是可以稳定的。因此对于不同的样本子集，作者dropout不同的操作：作者将一个batch的样本分成多个小batch（文中称为ghost batch），一个batch有1024个样本，分成32个ghost batch，每个有32个样本，每个ghost batch剔除不同的操作。</p><p><strong>Preventing Over-regularization</strong>：让L2正则化只对选择的子模型做正则化。</p><h3 id="evaluating-candidate-architectures">3. Evaluating Candidate Architectures</h3><p>训练了one-shot模型后，使用它来评估许多不同架构在held-out验证集的性能。作者在实验中， 按照论文 <code>SMASH:One-shot model architecture search through hypernet-works</code> 的方法，从固定的概率分布中进行独立的结构采样。作者也注意到，随机采样也可以用进化算法和基于神经网络的强化学习代替。</p><h3 id="final-model-selection-and-training">4. Final Model Selection and Training</h3><p>完成搜索之后，从头训练表现最好的结构，同时也可以扩展架构以增加其性能，也可以缩小架构以减少计算成本。作者在实验中，增加了过滤器的数量来扩展架构。</p><h2 id="experiments">Experiments</h2><h3 id="dropout-rate的影响">1. Dropout Rate的影响</h3><p>和vanilla SGD相比，仅引入了一个新的超参数 Dropout Rate，需要细心调节以实现one-shot模型与stand-alone模型之间精度的良好关系。为了证明其重要性，为此作者训练了具有不同Dropout Rate的One shot模型，且在训练过程中Dropout Rate保持稳定。结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220716140704.png" srcset="/img/loading.gif" lazyload></p><p>从图中可以发现当Dropout Rate过低时（大多数路径在训练步骤都保留了），少数架构的准确度比较高，大多数的架构的精度非常低，One-shot模型准备不足，无法在评估时将模型的大部分路径清零。</p><p>当Dropout Rate过高时，尽管架构的准确率有所增加，但是one-shot模型将最有用的capacity集中到最有用路径上的程度大大降低了。模型较浅时，高Dropout Rate会产生不错的结果，然而，随着搜索空间越来越复杂，模型越来越深，使用高Dropout Rate变得越来越成问题。</p><h3 id="实验结果对比">2. 实验结果对比</h3><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220716144029.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p><p>实验结果可以看到，与SMASH和除一种ENAS变体外的所有ENAS，算是具有竞争力，效果还不错。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220716181907.png" srcset="/img/loading.gif" lazyload></p><h2 id="理解-one-shot-模型">理解 One-shot 模型</h2><blockquote><p>来自 https://www.cnblogs.com/marsggbo/p/13195496.html</p></blockquote><p>由上图我们可以看到（以最左图为例），one-shot模型的准确率从0.1~0.8， 而stand-alone（即retrain之后的子模型）的准确率范围却只是0.92~0.945。为什么one-shot模型之间的准确率差别会更大呢？</p><p>文章对此给出了一个猜想：<strong>one-shot模型会学习哪一个操作对模型更加有用，而且最终的准确率也是依赖于这些操作的</strong>。换句话说：</p><ul><li>在移除一些不太重要的操作时，可能会使one-shot模型准确率有所降低，但是最后对stand-alone模型性能的预测影响不大。</li><li>而如果把一些最重要的操作移除之后，不仅对one-shot模型影响很大，对最后的stand-alone模型性能的预测影响也大。</li></ul><p>为了验证这一猜想，文章做了如下实验：</p><p>首先将几乎保留了所有操作的(dropout概率是 <span class="math inline">\(r=10^{−8}\)</span>)模型叫做<strong>reference architectures</strong>，注意这里用的是复数，也就是说这个reference architectures有很多种，即有的是移除了不太重要的操作后的结构，有的时移除了非常重要的操作候的结构，那么不同结构的准确率应该是不一样的。不过在没有retrain的情况下，什么操作都没有移除的one-shot模型（All on）应该是最好的（或者是表现靠前的，这里我们认为是最好的）。</p><p>注意这里的移除某些操作后得到的模型还是One-shot模型，而不是采样后的模型。采样后的模型是指从这个完整的one-shot中按照某种策略得到的模型。文中把这种模型叫做<strong>candidate architectures</strong>。</p><p>我们以分类任务为例，假设<strong>reference architectures</strong>对某个样本的预测输出是 <span class="math inline">\((p_1,p_2,...,p_n)\)</span>，其中 <span class="math inline">\(n\)</span> 表示类别数量；而<strong>candidate architectures</strong>的输出为 <span class="math inline">\((q_1,q_2,...,q_n)\)</span>。注意candidate architecture的输出应该是没有retrain的结果。</p><p>所以如果上面的猜想是正确的，那么表现最好的<strong>candidate architecture</strong>的预测应该要和所有操作都保留的one-shot模型的预测结果要十分接近。文中使用<strong>对称散度</strong>来判断相似性，散度公式为 <span class="math inline">\(D_{\mathrm{KL}}(p \| q)=\sum_{i=1}^{n} p_{i} \log \frac{p_{i}}{q_{i}}\)</span> ，那么对称散度就是<span class="math inline">\(D_{\mathrm{KL}}(p \| q)+D_{\mathrm{KL}}(q \| p)\)</span>。对称散度结果是在64个随机样本上得到的平均值，散度值越接近于0，表示二者输出越相近。</p><p>最后的结果如图示，可以看到在训练集上散度值低的模型（即预测值和保留大多数操作的完整模型很接近），在验证集上的准确率也相对高一些。</p><p><img src="https://cdn.jsdelivr.net/gh/stuxiaozhang/blogimage/img/20220716181807.png" srcset="/img/loading.gif" lazyload></p><blockquote><p>这块也没太理解。。。</p></blockquote></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/papers/">papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/G-NAS/">G-NAS</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/07/17/Regularized%20Evolution%20for%20Image%20Classifier%20Architecture%20Search/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">【Regularized Evo】Regularized Evolution for Image Classifier Architecture Search</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2022/07/12/%E3%80%90Large-Scale%20Evolution%E3%80%91Large-Scale%20Evolution%20of%20Image%20Classifiers/"><span class="hidden-mobile">【Large-Scale Evolution】Large-Scale Evolution of Image Classifiers</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>