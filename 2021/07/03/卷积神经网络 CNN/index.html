<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="卷积神经网络 CNN卷积神经网络是一种用来处理局部和整体相关性的计算网络结构，被应用在图像识别、自然语言处理甚至是语音识别领域，因为图像数据具有显著的局部与整体关系，其在图像识别领域的应用获得了巨大的成功。
以图像分类任务为例，下表所示卷积神经网络中，一般包含5种类型的网络层次结构：




CNN层次结构
输出尺寸
作用




输入层
$W_1\times H_1\times 3$
卷积网络的"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>卷积神经网络 CNN - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="卷积神经网络 CNN"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-07-03 15:53" pubdate>2021年7月3日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 5.7k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 75 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">卷积神经网络 CNN</h1><p class="note note-info">本文最后更新于：2021年7月7日</p><div class="markdown-body"><h2 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络 CNN"></a>卷积神经网络 CNN</h2><p>卷积神经网络是一种用来处理局部和整体相关性的计算网络结构，被应用在图像识别、自然语言处理甚至是语音识别领域，因为图像数据具有显著的局部与整体关系，其在图像识别领域的应用获得了巨大的成功。</p><p>以图像分类任务为例，下表所示卷积神经网络中，一般包含5种类型的网络层次结构：</p><div class="table-container"><table><thead><tr><th style="text-align:center">CNN层次结构</th><th style="text-align:center">输出尺寸</th><th style="text-align:left">作用</th></tr></thead><tbody><tr><td style="text-align:center">输入层</td><td style="text-align:center">$W_1\times H_1\times 3$</td><td style="text-align:left">卷积网络的原始输入，可以是原始或预处理后的像素矩阵</td></tr><tr><td style="text-align:center">卷积层</td><td style="text-align:center">$W_1\times H_1\times K$</td><td style="text-align:left"><strong>参数共享、局部连接，利用平移不变性从全局特征图提取局部特征</strong></td></tr><tr><td style="text-align:center">激活层</td><td style="text-align:center">$W_1\times H_1\times K$</td><td style="text-align:left"><strong>将卷积层的输出结果进行非线性映射</strong></td></tr><tr><td style="text-align:center">池化层</td><td style="text-align:center">$W_2\times H_2\times K$</td><td style="text-align:left"><strong>进一步筛选特征，可以有效减少后续网络层次所需的参数量</strong></td></tr><tr><td style="text-align:center">全连接层</td><td style="text-align:center">$(W_2 \cdot H_2 \cdot K)\times C$</td><td style="text-align:left"><strong>将多维特征展平为2维特征，通常低维度特征对应任务的学习目标（类别或回归值）</strong></td></tr></tbody></table></div><blockquote><p>$W_1\times H_1\times 3$对应原始图像或经过预处理的像素值矩阵，3对应RGB图像的通道;$K$表示卷积层中卷积核（滤波器）的个数;$W_2\times H_2$ 为池化后特征图的尺度，在全局池化中尺度对应$1\times 1$;$(W_2 \cdot H_2 \cdot K)$是将多维特征压缩到1维之后的大小，$C$对应的则是图像类别个数。</p></blockquote><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><p><strong>输入层(Input Layer)通常是输入卷积神经网络的原始数据或经过预处理的数据</strong>，可以是图像识别领域中原始三维的多彩图像，也可以是音频识别领域中经过傅利叶变换的二维波形数据，甚至是自然语言处理中一维表示的句子向量。以图像分类任务为例，输入层输入的图像一般包含RGB三个通道，是一个由长宽分别为$H$和$W$组成的3维像素值矩阵$H\times W \times 3$，卷积网络会将输入层的数据传递到一系列卷积、池化等操作进行特征提取和转化，最终由全连接层对特征进行汇总和结果输出。根据计算能力、存储大小和模型结构的不同，卷积神经网络每次可以批量处理的图像个数不尽相同，若指定输入层接收到的图像个数为$N$，则输入层的输出数据为$N\times H\times W\times 3$。</p><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>卷积层(Convolution Layer)通常用作对输入层输入的数据进行<strong>特征提取，通过卷积核矩阵对原始数据中隐含关联性的一种抽象。</strong>卷积操作原理上其实是<strong>对两张像素矩阵进行点乘求和的数学操作</strong>，其中一个矩阵为输入的数据矩阵，另一个矩阵则为卷积核（滤波器或特征矩阵），求得的结果表示为原始图像中提取的特定局部特征。</p><blockquote><p>下图表示卷积操作过程中的不同填充策略，上半部分采用零填充(Zero padding)，下半部分采用有效卷积（舍弃不能完整运算的边缘部分）。</p></blockquote><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210704173241487.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p><h4 id="卷积层的基本参数"><a href="#卷积层的基本参数" class="headerlink" title="卷积层的基本参数"></a>卷积层的基本参数</h4><p>卷积层中需要用到卷积核（滤波器或特征检测器）与图像特征矩阵进行点乘运算，利用卷积核与对应的特征感受域进行划窗式运算时，需要设定卷积核对应的大小、步长、个数以及填充的方式.</p><div class="table-container"><table><thead><tr><th style="text-align:center">参数名</th><th style="text-align:left">作用</th><th style="text-align:left">常见设置</th></tr></thead><tbody><tr><td style="text-align:center">卷积核大小 (Kernel Size)</td><td style="text-align:left">卷积核的大小定义了卷积的感受野</td><td style="text-align:left">在过去常设为5，如LeNet-5；现在多设为3，通过堆叠$3\times3$的卷积核来达到更大的感受域</td></tr><tr><td style="text-align:center">卷积核步长 (Stride)</td><td style="text-align:left">定义了卷积核在卷积过程中的步长</td><td style="text-align:left">常见设置为1，表示滑窗距离为1，可以覆盖所有相邻位置特征的组合；当设置为更大值时相当于对特征组合降采样</td></tr><tr><td style="text-align:center">填充 (Padding)</td><td style="text-align:left">在卷积核尺寸不能完美匹配输入的图像矩阵时需要进行一定的填充策略</td><td style="text-align:left">设置为’SAME’表示对不足卷积核大小的边界位置进行某种填充（通常零填充）以保证卷积输出维度与与输入维度一致；当设置为’VALID’时则对不足卷积尺寸的部分进行舍弃，输出维度就无法保证与输入维度一致</td></tr><tr><td style="text-align:center">输入通道数 (In Channels)</td><td style="text-align:left">指定卷积操作时卷积核的深度</td><td style="text-align:left">默认与输入的特征矩阵通道数（深度）一致；在某些压缩模型中会采用通道分离的卷积方式</td></tr><tr><td style="text-align:center">输出通道数 (Out Channels)</td><td style="text-align:left">指定卷积核的个数</td><td style="text-align:left">若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</td></tr></tbody></table></div><div class="note note-info"><p>卷积操作维度变换公式：</p><script type="math/tex;mode=display">O_d =\begin{cases} \lceil \frac{(I_d - k_{size})+ 1)}{s}\rceil ,& \text{padding=VALID}\\ \lceil \frac{I_d}{s}\rceil,&\text{padding=SAME} \end{cases}</script><p>其中，$I<em>d$为输入维度，$O_d$为输出维度，$k</em>{size}$为卷积核大小，$s$为步长</p></div><h4 id="二维卷积与三维卷积"><a href="#二维卷积与三维卷积" class="headerlink" title="二维卷积与三维卷积"></a>二维卷积与三维卷积</h4><p><strong>二维卷积</strong></p><p>二维卷积操作如下图所示，为了更直观的说明，分别展示在单通道和多通道输入中，对单个通道输出的卷积操作。在单通道输入的情况下，若输入卷积核尺寸为 $(k_h, k_w, 1)$，卷积核在输入图像的空间维度上进行滑窗操作，每次滑窗和 $(k_h, k_w)$窗口内的值进行卷积操作，得到输出图像中的一个值。在多通道输入的情况下，假定输入图像特征通道数为3，卷积核尺寸则为$(k_h, k_w, 3)$，每次滑窗与3个通道上的$(k_h, k_w)$窗口内的所有值进行卷积操作，得到输出图像中的一个值。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210705083954891.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><p><strong>三维卷积</strong></p><p>3D卷积操作如图所示，同样分为单通道和多通道，且假定只使用1个卷积核，即输出图像仅有一个通道。对于单通道输入，与2D卷积不同之处在于，输入图像多了一个深度(depth)维度，卷积核也多了一个$k_d$维度，因此3D卷积核的尺寸为$(k_h, k_w, k_d)$，每次滑窗与$(k_h, k_w, k_d)$窗口内的值进行相关操作，得到输出3D图像中的一个值。对于多通道输入，则与2D卷积的操作一样，每次滑窗与3个channels上的$(k_h, k_w, k_d)$窗口内的所有值进行相关操作，得到输出3D图像中的一个值。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210705084053317.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><h4 id="卷积核是否一定越大越好？"><a href="#卷积核是否一定越大越好？" class="headerlink" title="卷积核是否一定越大越好？"></a>卷积核是否一定越大越好？</h4><p>在早期的卷积神经网络中（如LeNet-5、AlexNet），用到了一些较大的卷积核（$11\times11$和$5\times 5$），受限于当时的计算能力和模型结构的设计，无法将网络叠加得很深，因此卷积网络中的卷积层需要设置较大的卷积核以获取更大的感受域。但是这种大卷积核反而会导致计算量大幅增加，不利于训练更深层的模型，相应的计算性能也会降低。后来的卷积神经网络（VGG、GoogLeNet等），发现通过堆叠2个$3\times 3$卷积核可以获得与$5\times 5$卷积核相同的感受视野，同时参数量会更少（$3×3×2+1$ &lt; $ 5×5×1+1$），$3\times 3$卷积核被广泛应用在许多卷积神经网络中。因此可以认为，在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核会更加有效。</p><p>但是，这并不是表示更大的卷积核就没有作用，在某些领域应用卷积神经网络时仍然可以采用较大的卷积核。譬如在自然语言处理领域，由于文本内容不像图像数据可以对特征进行很深层的抽象，往往在该领域的特征提取只需要较浅层的神经网络即可。在将卷积神经网络应用在自然语言处理领域时，通常都是较为浅层的卷积层组成，但是文本特征有时又需要有较广的感受域让模型能够组合更多的特征（如词组和字符），此时直接采用较大的卷积核将是更好的选择。</p><p>综上所述，卷积核的大小并没有绝对的优劣，需要视具体的应用场景而定，但是极大和极小的卷积核都是不合适的，单独的$1\times 1$极小卷积核只能用作分离卷积而不能对输入的原始特征进行有效的组合，极大的卷积核通常会组合过多的无意义特征从而浪费了大量的计算资源。</p><h4 id="怎样才能减少卷积层参数量？"><a href="#怎样才能减少卷积层参数量？" class="headerlink" title="怎样才能减少卷积层参数量？"></a>怎样才能减少卷积层参数量？</h4><p>减少卷积层参数量的方法可以简要地归为以下几点：</p><ul><li><u>使用堆叠小卷积核代替大卷积核</u>：VGG网络中2个$3\times 3$的卷积核可以代替1个$5\times 5$的卷积核</li><li>使用<u>分离卷积</u>操作：将原本$K\times K\times C$的卷积操作分离为$K\times K\times 1$和$1\times1\times C$的两部分操作</li><li><u>添加$1\times 1$的卷积</u>操作：与分离卷积类似，但是通道数可变，在$K\times K\times C_1$卷积前添加$1\times1\times C_2$的卷积核（满足$C_2 &lt;C_1$）</li><li><u>在卷积层前使用池化操作</u>：池化可以降低卷积层的输入特征维度</li></ul><h4 id="卷积神经网络的参数设置"><a href="#卷积神经网络的参数设置" class="headerlink" title="卷积神经网络的参数设置"></a>卷积神经网络的参数设置</h4><p>卷积神经网络中常见的参数在其他类型的神经网络中也是类似的，但是参数的设置还得结合具体的任务才能设置在合理的范围.</p><div class="table-container"><table><thead><tr><th style="text-align:center">参数名</th><th style="text-align:center">常见设置</th><th style="text-align:left">参数说明</th></tr></thead><tbody><tr><td style="text-align:center">学习率(Learning Rate)</td><td style="text-align:center">$0-1$</td><td style="text-align:left">反向传播网络中更新权值矩阵的步长，在一些常见的网络中会在固定迭代次数或模型不再收敛后对学习率进行指数下降(如$lr=lr\times 0.1$)。当学习率越大计算误差对权值矩阵的影响越大，容易在某个局部最优解附近震荡；越小的学习率对网络权值的更新越精细，但是需要花费更多的时间去迭代</td></tr><tr><td style="text-align:center">批次大小(Batch Size)</td><td style="text-align:center">$1-N$</td><td style="text-align:left">批次大小指定一次性流入模型的数据样本个数，根据任务和计算性能限制判断实际取值，在一些图像任务中往往由于计算性能和存储容量限制只能选取较小的值。在相同迭代次数的前提下，数值越大模型越稳定，泛化能力越强，损失值曲线越平滑，模型也更快地收敛，但是每次迭代需要花费更多的时间</td></tr><tr><td style="text-align:center">数据轮次(Epoch)</td><td style="text-align:center">$1-N$</td><td style="text-align:left">数据轮次指定所有训练数据在模型中训练的次数，根据数据集规模和分布情况会设置为不同的值。当模型较为简单或训练数据规模较小时，通常轮次不宜过高，否则模型容易过拟合；模型较为复杂或训练数据规模足够大时，可适当提高数据的训练轮次。</td></tr><tr><td style="text-align:center">权重衰减系数(Weight Decay)</td><td style="text-align:center">$0-0.001$</td><td style="text-align:left">模型训练过程中反向传播权值更新的权重衰减值</td></tr></tbody></table></div><h4 id="提高卷积神经网络的泛化能力"><a href="#提高卷积神经网络的泛化能力" class="headerlink" title="提高卷积神经网络的泛化能力"></a>提高卷积神经网络的泛化能力</h4><p>卷积神经网络与其他类型的神经网络类似，在采用反向传播进行训练的过程中比较依赖输入的数据分布，当数据分布较为极端的情况下容易导致模型欠拟合或过拟合，下表记录了提高卷积网络泛化能力的方法。</p><div class="table-container"><table><thead><tr><th style="text-align:center">方法</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:center">使用<strong>更多数据</strong></td><td style="text-align:left">在有条件的前提下，尽可能多地获取训练数据是最理想的方法，更多的数据可以让模型得到充分的学习，也更容易提高泛化能力</td></tr><tr><td style="text-align:center">使用<strong>更大批次</strong></td><td style="text-align:left">在相同迭代次数和学习率的条件下，每批次采用更多的数据将有助于模型更好的学习到正确的模式，模型输出结果也会更加稳定</td></tr><tr><td style="text-align:center"><strong>调整数据分布</strong></td><td style="text-align:left">大多数场景下的数据分布是不均匀的，模型过多地学习某类数据容易导致其输出结果偏向于该类型的数据，此时通过调整输入的数据分布可以一定程度提高泛化能力</td></tr><tr><td style="text-align:center"><strong>调整目标函数</strong></td><td style="text-align:left">在某些情况下，目标函数的选择会影响模型的泛化能力，如目标函数$f(y,y’)=</td><td>y-y’</td><td>$在某类样本已经识别较为准确而其他样本误差较大的侵害概况下，不同类别在计算损失结果的时候距离权重是相同的，若将目标函数改成$f(y,y’)=(y-y’)^2$则可以使误差小的样本计算损失的梯度比误差大的样本更小，进而有效地平衡样本作用，提高模型泛化能力</td></tr><tr><td style="text-align:center"><strong>调整网络结构</strong></td><td style="text-align:left">在浅层卷积神经网络中，参数量较少往往使模型的泛化能力不足而导致欠拟合，此时通过叠加卷积层可以有效地增加网络参数，提高模型表达能力；在深层卷积网络中，若没有充足的训练数据则容易导致模型过拟合，此时通过简化网络结构减少卷积层数可以起到提高模型泛化能力的作用</td></tr><tr><td style="text-align:center"><strong>数据增强</strong></td><td style="text-align:left">数据增强又叫数据增广，在有限数据的前提下通过平移、旋转、加噪声等一些列变换来增加训练数据，同类数据的表现形式也变得更多样，有助于模型提高泛化能力，需要注意的是数据变化应尽可能不破坏元数数据的主体特征(如在图像分类任务中对图像进行裁剪时不能将分类主体目标裁出边界)。</td></tr><tr><td style="text-align:center"><strong>权值正则化</strong></td><td style="text-align:left">权值正则化就是通常意义上的正则化，一般是在损失函数中添加一项权重矩阵的正则项作为惩罚项，用来惩罚损失值较小时网络权重过大的情况，此时往往是网络权值过拟合了数据样本(如$Loss=f(WX+b,y’)+\frac{\lambda}{\eta}\sum{</td><td>W</td><td>}$)。</td></tr><tr><td style="text-align:center"><strong>屏蔽网络节点</strong></td><td style="text-align:left">该方法可以认为是网络结构上的正则化，通过随机性地屏蔽某些神经元的输出让剩余激活的神经元作用，可以使模型的容错性更强。</td></tr></tbody></table></div><blockquote><p>对大多数神经网络模型同样通用</p></blockquote><h4 id="卷积神经网络凸显共性的原因？"><a href="#卷积神经网络凸显共性的原因？" class="headerlink" title="卷积神经网络凸显共性的原因？"></a>卷积神经网络凸显共性的原因？</h4><p><strong>局部连接／权值共享／池化操作／多层次结构。</strong></p><p><strong>局部连接使网络可以提取数据的局部特征；权值共享大大降低了网络的训练难度，一个Filter只提取一个特征，在整个图片（或者语音／文本） 中进行卷积；池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。</strong></p><h5 id="局部连接"><a href="#局部连接" class="headerlink" title="局部连接"></a>局部连接</h5><p><strong>感受野（Receptive Field）的定义是卷积神经网络每一层输出的特征图（feature map）上的像素点在输入图片上映射的区域大小。</strong>通俗点的解释是，特征图上的一个点对应输入图上的区域。</p><p>在图像卷积操作中，神经元在空间维度上(指同一层)是局部连接，但在深度上是全连接。局部连接的思想，是受启发于生物学里的视觉系统结构，视觉皮层的神经元就是仅用局部接受信息。对于二维图像，局部像素关联性较强。这种<strong>局部连接保证了训练后的滤波器能够对局部特征有最强的响应，使神经网络可以提取数据的局部特征.</strong></p><p>下图是一个很经典的图示，左边是全连接，右边是局部连接。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/5.27.1.png" srcset="/img/loading.gif" lazyload style="zoom:100%"></p><p>对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为 $10^6$ 个，采用全连接则有 $1000 × 1000 × 10^6 = 10^{12}$ 个权值参数，如此巨大的参数量几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中 10 × 10 的局部图像相连接，那么此时的权值参数数量为 $10 × 10 × 10^6 = 10^8$，将直接减少4个数量级。</p><h5 id="权值共享"><a href="#权值共享" class="headerlink" title="权值共享"></a>权值共享</h5><p><strong>权值共享，即计算同一深度的神经元时采用的卷积核参数是共享的。</strong>权值共享在一定程度上讲是有意义的，<strong>是由于在神经网络中，提取的底层边缘特征与其在图中的位置无关。</strong>但是在另一些场景中是无意的，如在人脸识别任务，我们期望在不同的位置学到不同的特征。</p><p>需要注意的是，权重只是对于同一深度切片的神经元是共享的。在卷积层中，通常采用多组卷积核提取不同的特征，即对应的是不同深度切片的特征，而不同深度切片的神经元权重是不共享。相反，偏置这一权值对于同一深度切片的所有神经元都是共享的。</p><p><u>权值共享带来的好处是大大降低了网络的训练难度。</u>如下图，假设在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中 $10^6$ 个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核的大小）。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/5.27.2.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>这里就体现了卷积神经网络的奇妙之处，使用少量的参数，却依然能有非常出色的性能。上述仅仅是提取图像一种特征的过程。如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像不同尺度下的特征，称之为特征图（feature map）。</p><h5 id="池化操作"><a href="#池化操作" class="headerlink" title="池化操作"></a>池化操作</h5><p>池化操作与多层次结构一起，实现了数据的降维，将低层次的局部特征组合成为较高层次的特征，从而对整个图片进行表示。如下图：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/5.27.3.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>池化层又称为降采样层(Downsampling Layer)。池化的作用是对感受域内的特征进行筛选，<strong>提取区域内最具代表性的特征，能够有效地降低输出特征尺度，进而减少模型所需要的参数量</strong>。按操作类型通常分为最大池化(Max Pooling)、平均池化(Average Pooling)和求和池化(Sum Pooling)，它们分别提取感受域内最大、平均与总和的特征值作为输出，最常用的是最大池化。</p><div class="table-container"><table><thead><tr><th style="text-align:center">池化类型</th><th style="text-align:center">示意图</th><th style="text-align:left">作用</th></tr></thead><tbody><tr><td style="text-align:center">一般池化(General Pooling)</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/general_pooling.png" srcset="/img/loading.gif" lazyload alt="general_pooling"></td><td style="text-align:left">通常包括最大池化(Max Pooling)和平均池化(Mean Pooling)。以最大池化为例，池化范围$(2\times2)$和滑窗步长$(stride=2)$ 相同，仅提取一次相同区域的范化特征。</td></tr><tr><td style="text-align:center">重叠池化(Overlapping Pooling)</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/overlap_pooling.png" srcset="/img/loading.gif" lazyload alt="overlap_pooling"></td><td style="text-align:left">与一般池化操作相同，但是池化范围$P<em>{size}$与滑窗步长$stride$关系为$P</em>{size}&gt;stride$，同一区域内的像素特征可以参与多次滑窗提取，得到的特征表达能力更强，但计算量更大。</td></tr><tr><td style="text-align:center">空间金字塔池化$^*$(Spatial Pyramid Pooling)</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/spatial_pooling.png" srcset="/img/loading.gif" lazyload alt="spatial_pooling"></td><td style="text-align:left">在进行多尺度目标的训练时，卷积层允许输入的图像特征尺度是可变的，紧接的池化层若采用一般的池化方法会使得不同的输入特征输出相应变化尺度的特征，而卷积神经网络中最后的全连接层则无法对可变尺度进行运算，因此需要空间金字塔池化对不同输出尺度采用不同的滑窗大小和步长以确保输出尺度相同。</td></tr></tbody></table></div><h4 id="卷积和池化有什么区别？"><a href="#卷积和池化有什么区别？" class="headerlink" title="卷积和池化有什么区别？"></a>卷积和池化有什么区别？</h4><p>卷积和池化在结构上具有一定的相似性，都是对感受域内的特征进行提取，并且根据步长设置获取到不同维度的输出，但是其内在操作是有本质区别的，如下表所示。</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">卷积</th><th style="text-align:center">池化</th></tr></thead><tbody><tr><td style="text-align:center"><strong>结构</strong></td><td style="text-align:center">零填充时输出维度不变，而通道数改变</td><td style="text-align:center">通常特征维度会降低，通道数不变</td></tr><tr><td style="text-align:center"><strong>稳定性</strong></td><td style="text-align:center">输入特征发生细微改变时，输出结果会改变</td><td style="text-align:center">感受域内的细微变化不影响输出结果</td></tr><tr><td style="text-align:center"><strong>作用</strong></td><td style="text-align:center">感受域内提取局部关联特征</td><td style="text-align:center">感受域内提取泛化特征，降低维度</td></tr><tr><td style="text-align:center"><strong>参数量</strong></td><td style="text-align:center">与卷积核尺寸、卷积核个数相关</td><td style="text-align:center">不引入额外参数</td></tr></tbody></table></div><h3 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h3><p><strong>激活层(Activation Layer)负责对卷积层抽取的特征进行激活</strong>，由于卷积操作是由输入矩阵与卷积核矩阵进行相差的线性变化关系，需要<strong>激活层对其进行非线性的映射</strong>。激活层主要由激活函数组成，<u>即在卷积层输出结果的基础上嵌套一个非线性函数，让输出的特征图具有非线性关系。</u>卷积神经网络中通常采用 ReLU 来充当激活函数（还包括 tanh 和 sigmoid 等）。ReLU 的函数形式如公式所示，能够限制小于0的值为0，同时大于等于0的值保持不变。</p><script type="math/tex;mode=display">f(x)=\begin{cases}
   0 &\text{if } x<0 \\
   x &\text{if } x\ge 0
\end{cases}</script><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p><strong>全连接层(Full Connected Layer)负责对卷积神经网络学习提取到的特征进行汇总，将多维的特征输入映射为二维的特征输出</strong>，高维表示样本批次，低位常常对应任务目标。</p><h4 id="全连接、局部连接、全卷积与局部卷积"><a href="#全连接、局部连接、全卷积与局部卷积" class="headerlink" title="全连接、局部连接、全卷积与局部卷积"></a>全连接、局部连接、全卷积与局部卷积</h4><p>大多数神经网络中高层网络通常会采用全连接层(Full Connected Layer)，通过多对多的连接方式对特征进行全局汇总，可以有效地提取全局信息。但是全连接的方式需要大量的参数，是神经网络中最占资源的部分之一，因此就需要由局部连接(Local Connected Layer)，仅在局部区域范围内产生神经元连接，能够有效地减少参数量。根据卷积操作的作用范围可以分为全卷积(Global Convolution)和局部卷积(Local Convolution)。实际上这里所说的全卷积就是标准卷积，即在整个输入特征维度范围内采用相同的卷积核参数进行运算，全局共享参数的连接方式可以使神经元之间的连接参数大大减少;局部卷积又叫平铺卷积(Tiled Convolution)或非共享卷积(Unshared Convolution)，是局部连接与全卷积的折衷。四者的比较如下表所示。</p><div class="table-container"><table><thead><tr><th style="text-align:center">连接方式</th><th style="text-align:center">示意图</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:center">全连接</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/full-connected.png" srcset="/img/loading.gif" lazyload alt="full-connected"></td><td style="text-align:left">层间神经元完全连接，每个输出神经元可以获取到所有输入神经元的信息，有利于信息汇总，常置于网络末层；连接与连接之间独立参数，大量的连接大大增加模型的参数规模。</td></tr><tr><td style="text-align:center">局部连接</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/local-connected.png" srcset="/img/loading.gif" lazyload alt="local-connected"></td><td style="text-align:left">层间神经元只有局部范围内的连接，在这个范围内采用全连接的方式，超过这个范围的神经元则没有连接；连接与连接之间独立参数，相比于全连接减少了感受域外的连接，有效减少参数规模</td></tr><tr><td style="text-align:center">全卷积</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/conv.png" srcset="/img/loading.gif" lazyload alt="conv"></td><td style="text-align:left">层间神经元只有局部范围内的连接，在这个范围内采用全连接的方式，连接所采用的参数在不同感受域之间共享，有利于提取特定模式的特征；相比于局部连接，共用感受域之间的参数可以进一步减少参数量。</td></tr><tr><td style="text-align:center">局部卷积</td><td style="text-align:center"><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/local-conv.png" srcset="/img/loading.gif" lazyload alt="local-conv"></td><td style="text-align:left">层间神经元只有局部范围内的连接，感受域内采用全连接的方式，而感受域之间间隔采用局部连接与全卷积的连接方式；相比与全卷积成倍引入额外参数，但有更强的灵活性和表达能力；相比于局部连接，可以有效控制参数量</td></tr></tbody></table></div><h4 id="FC-amp-CNN-的区别"><a href="#FC-amp-CNN-的区别" class="headerlink" title="FC &amp; CNN 的区别"></a>FC &amp; CNN 的区别</h4><p>在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为 1 x 1 的卷积；而前层是卷积层的全连接层可以转化为卷积核为 h x w 的全局卷积，h 和 w 分别为前层卷积结果的高和宽</p><p><strong><em>注</em></strong>: 有关卷积操作“实现”全连接层，有必要多啰嗦几句。</p><p>以VGG-16为例，对于224x224x3的输入：</p><p>最后一层卷积可得输出为7x7x512，如后层是一层含4096个神经元的FC，则可用卷积核为7x7x512x4096的全局卷积来实现这一全连接运算过程，其中该卷积核参数设为：“filter size = 7, padding = 0, stride = 1, D_in = 512, D_out = 4096”，经过此卷积操作后可得输出为1x1x4096。</p><blockquote><p>前层是卷积层的全连接层可以转化为卷积核为 h x w 的全局卷积，h 和 w 分别为前层卷积结果的高和宽</p></blockquote><p>如需再次叠加一个2048的FC，则可设定参数为“filter size = 1, padding = 0, stride = 1, D_in = 4096, D_out = 2048”的卷积层操作。</p><blockquote><p>前层是全连接的全连接层可以转化为卷积核为 1 x 1 的卷积</p></blockquote></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> <a class="hover-with-bg" href="/tags/CNN/">CNN</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2021/07/05/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">循环神经网络 RNN</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/07/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20NN/"><span class="hidden-mobile">神经网络 NN</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>