<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="
            https://github.com/thunlp/GNNPapers#knowledge-graph最近对图神经网络进行一个入门，主要是看了百度飞桨训练营的视频，做一个小小的笔记~
          
按照飞桨训练营中对图学习的划分, 图学习算法可以分为三大类:

图游走类算法(图嵌入算法): DeepWalk, Node2Vec 等.
图神经网络算法: GCN, G"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>图神经网络入门 - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="图神经网络入门"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-12-27 13:35" pubdate>2021年12月27日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 37 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">图神经网络入门</h1><p class="note note-info">本文最后更新于：2022年1月5日</p><div class="markdown-body"><div class="note note-primary"><p><a target="_blank" rel="noopener" href="https://github.com/thunlp/GNNPapers#knowledge-graph">https://github.com/thunlp/GNNPapers#knowledge-graph</a></p><p>最近对图神经网络进行一个入门，主要是看了百度飞桨训练营的视频，做一个小小的笔记~</p></div><p>按照飞桨训练营中对图学习的划分, 图学习算法可以分为三大类:</p><ol><li><strong>图游走类算法</strong>(图嵌入算法): DeepWalk, Node2Vec 等.</li><li><strong>图神经网络算法</strong>: GCN, GAT, GraphSAGE 等.</li><li><strong>知识图谱嵌入算法</strong>: TransE, TransR, RotatE 等.</li></ol><h2 id="图游走类模型"><a href="#图游走类模型" class="headerlink" title="图游走类模型"></a>图游走类模型</h2><p>获得 Node embeddings 后进行下游任务。那如何获得 Node embeddings？</p><p>图中的节点可以看作 NLP 中的词，节点序列可以联想成 NLP 中的句子。</p><h3 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h3><p>图游走类模型最开始参考的就是 NLP 领域中的 Word2vec 算法。所以介绍一下 Word2vec ：</p><p>在 Word2Vec 中, <strong>中心词语义可以由周围上下文的词语义</strong>来”决定”。Word2Vec 包含：</p><ul><li><strong>两个算法模型</strong>：<strong>continuous bag-of-words（CBOW）</strong>和 <strong>skip-gram</strong>。CBOW 是根据中心词周围的上下文单词来预测该词的词向量。skip-gram 则相反，是根据中心词预测周围上下文的词的概率分布。</li><li><strong>两个训练方法</strong>：<strong>负采样（negative sampling）</strong>和<strong>层序 softmax（hierarchical softmax）</strong>。Negative sampling 通过抽取负样本来定义目标，hierarchical softmax 通过使用一个有效的树结构来计算所有词的概率来定义目标。</li></ul><blockquote><p>详情可以参考 <a href="https://stuxiaozhang.github.io/2021/07/29/CS224n%2001%20Introduction%20and%20Word%20Vectors/">这篇博客</a>。</p></blockquote><p>图游走类算法更多用到的是 Skip Gram 模型. Skip Gram 是一种根据中心词预测周围上下文的词的方法：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105151021578.png" srcset="/img/loading.gif" lazyload alt=""></p><p>在 Word2Vec 中, <strong>中心词语义可以由周围上下文的词语义</strong>来”决定”。同样，在图中的节点也可能受到邻居节点的影响。所以想到将 Word2Vec 算法迁移到图嵌入领域。</p><p>Word2Vec 整体框架如下：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105151057686.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h3 id="DeepWalk"><a href="#DeepWalk" class="headerlink" title="DeepWalk"></a>DeepWalk</h3><p>将 NLP 领域的思想运用到图嵌入领域。图的节点对应 NLP 的单词，图的节点序列对应 NLP 句子。通过在图上游走获得图的节点序列。</p><p>DeepWalk 就是简单的在图中做<strong>随机游走</strong>(Random Walk)，即在当前节点的邻近节点(包括<strong>自身</strong>)随机游走，当游走到<strong>最大长度</strong>时停止，所以它本质上就是在无向图上<strong>可以重复遍历的DFS</strong>。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105151118597.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>对于一般的 随机游走公式：</p><script type="math/tex;mode=display">{P}\left(c_{i}=x \mid c_{i-1}=v\right)=\left\{\begin{array}{cc}
\frac{\pi_{vx}}{Z}, & \text { if }(v, x) \in E \\
0, & \text { otherwise }
\end{array}\right.</script><p>其中，$v$ 是当前节点，$x$ 是选择的下一个节点，$Z$ 是归一化因子，$\pi<em>{vx}$ 是原始的概率分布，$\frac{\pi</em>{vx}}{Z}$ 是归一化后的转移概率分布。</p><p>对于 DeepWalk 来说，只要与节点 v 相邻，节点概率是相等的，所以有:</p><script type="math/tex;mode=display">P\left(c_{i}=x \mid c_{i-1}=v\right)=\left\{\begin{array}{cc}
\frac{1}{|N(v)|}, & \text { if }(v, x) \in E \\
0, & \text { otherwise }
\end{array}\right.</script><p>DeepWalk 中，$\pi_{vx}=1$，$Z=|N(v)|$ 是节点的邻居个数。</p><p>DeepWalk 的框架与 Word2Vec 的区别就是多了一个随机游走的过程，随机游走后拿到了这个图的遍历序列，就能将它作为一个序列输入到 Word2Vec 中，就得到了节点的表示。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105151138312.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>对于图游走类算法，可以更多的关注图游走的方式这块。</p><h3 id="Node2vec"><a href="#Node2vec" class="headerlink" title="Node2vec"></a>Node2vec</h3><p>DeepWalk 存在一个问题：随机游走的方式比较简单直接，就是可以回头的 DFS 游走的一个过程。然而图是一个复杂结构，需要考虑很多因素。在 DeepWalk 中, 只考虑了使用 DFS 游走的方式。而在数据结构中可知，图的游走方式是有<strong>DFS</strong>和<strong>BFS</strong>两种的:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104164002009.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>在 Node2Vec 中，考虑了上述问题，希望能够让游走的方式更加丰富一点。只需要将图游走的一般公式做如下替换:</p><script type="math/tex;mode=display">\pi_{vx} =\alpha_{pq}(t, x) \cdot w_{vx}</script><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104164947865.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p><p>$v$ 为当前节点, $t$ 为上一个节点, $w<em>{vx}$ 为 $v$ 和 $x$ 之间的权值, 其中 $\alpha</em>{pq}(t, x)$ 为:</p><script type="math/tex;mode=display">\alpha_{p q}(t, x)=\left\{\begin{array}{ll}
\frac{1}{p}, & \text { if } d_{t x}=0 \\
1, & \text { if } d_{t x}=1 \\
\frac{1}{q}, & \text { if } d_{t x}=2
\end{array}\right.</script><p>$d_{tx}$ 代表节点 $t$ 到 $x$ 的距离, 即当前节点 $v$ 的一阶邻居。而 $p,q$ 则是两个参数，它们能控制如何游走:</p><ul><li>$p$ 能控制有多大的概率”回头”, 即从当前节点 $v$ 重新回到前一节点 $t$, 如下图 $v→t$).</li><li>$q$ 控制游走策略倾向于 DFS 或是 BFS:<ul><li>$q&gt;1$ 时倾向于 BFS, 如下图 $v→x_1$.</li><li>$q&lt;1$ 时倾向于 DFS, 如下图 $v→x_2$.</li></ul></li><li>$p=q=1$ 时, $\pi<em>{vx}=w</em>{vx}$.</li></ul><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104173315702.png" srcset="/img/loading.gif" lazyload alt=""></p><p>Node2Vec 的框架如下：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105152305229.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>Node2Vec 这样游走有如下好处:</p><ol><li>结合了图的<strong>权重</strong>对游走的影响.</li><li>能够让模型<strong>自己学习</strong>如何游走合适(不是仅仅执行DFS, 也在某些时候BFS).</li></ol><h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><h3 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h3><p>在CV中的卷积被定义为: <strong>将某个像素点周围的像素以不同权重叠加起来</strong>. 那么扩展到图结构中, 对应的像素应该变为<strong>节点</strong>, <strong>即将某个节点周围的邻居以不同权重叠加起来</strong></p><p>二者区别在于：对于图像来说，周围像素点的个数是固定的。而对于图来说，节点周围的邻居节点数量是不固定的，这也是它复杂的原因。</p><p>于是就出现了两种方式来提取图的特征。一是空间域卷积（spatial domain)，二是频域卷积（spectral domain）。第一种方式由于每个顶点提取出来的 neighbors 不同，处理上比较麻烦，同时它的效果没有频域卷积效果好，没有做深究。因此，现在比较流行、工程上应用较多的为频域卷积。</p><p>以下图中的右上角的 graph 为例：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104173713462.png" srcset="/img/loading.gif" lazyload alt=""></p><p>其中：</p><ul><li><p>$\hat A$ 为图的自邻接矩阵(有节点自身的闭环, 即 $\tilde{A} = A + I$</p></li><li><p>$D$ 为度矩阵。（Note：矩阵的度的计算 包括入度和出度。）</p></li><li><p>$H^{(l)}$ 为第 $l$ 层的 GCN 的节点表示</p></li><li>$W^{(l)}$ 是权重矩阵（DNN）</li></ul><p>则 graph 所对应的邻接矩阵 $\tilde{A}$, 度矩阵 $\tilde{D}$ 分别为:</p><script type="math/tex;mode=display">\tilde{A}=\begin{bmatrix}\color{red}{1}&\color{red}{1}&\color{red}{1}&0&0&0&0\\\color{red}{1}&\color{red}{1}&\color{red}{1}&0&0&0&0\\\color{red}{1}&\color{red}{1}&\color{red}{1}&\color{red}{1}&0&0&0\\0&0&\color{red}{1}&\color{red}{1}&\color{red}{1}&\color{red}{1}&\color{red}{1}\\0&0&0&\color{red}{1}&\color{red}{1}&\color{red}{1}&\color{red}{1}\\0&0&0&\color{red}{1}&\color{red}{1}&\color{red}{1}&0\\0&0&0&\color{red}{1}&\color{red}{1}&0&\color{red}{1}\end{bmatrix} \quad
\tilde{D}=\begin{bmatrix}\color{red}{3}&0&0&0&0&0&0\\0&\color{red}{3}&0&0&0&0&0\\0&0&\color{red}{4}&0&0&0&0\\0&0&0&\color{red}{5}&0&0&0\\0&0&0&0&\color{red}{4}&0&0\\0&0&0&0&0&\color{red}{3}&0\\0&0&0&0&0&0&\color{red}{3}\end{bmatrix}\</script><p>公式中所需要用到的 $\tilde{D}^{-\frac{1}{2}}$ 为如下矩阵:</p><script type="math/tex;mode=display">\tilde{D}^{-\frac{1}{2}}=\begin{bmatrix}\color{red}{\frac{1}{\sqrt{3}}}&0&0&0&0&0&0\\0&\color{red}{\frac{1}{\sqrt{3}}}&0&0&0&0&0\\0&0&\color{red}{\frac{1}{\sqrt{4}}}&0&0&0&0\\0&0&0&\color{red}{\frac{1}{\sqrt{5}}}&0&0&0\\0&0&0&0&\color{red}{\frac{1}{\sqrt{4}}}&0&0\\0&0&0&0&0&\color{red}{\frac{1}{\sqrt{3}}}&0\\0&0&0&0&0&0&\color{red}{\frac{1}{\sqrt{3}}}\end{bmatrix}</script><p>为了方便理解更新方式，对<strong>图卷积计算公式</strong>先做如下方式的<strong>简化</strong>:</p><script type="math/tex;mode=display">\begin{aligned}
H^{(l+1)}&=\sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})\\\ &\Downarrow \\\ H^{(l+1)}&=\sigma(\tilde{A}H^{(l)}W^{(l)})
\end{aligned}</script><p>即，<strong>先不考虑 度 对更新的影响</strong>。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104173728466.png" srcset="/img/loading.gif" lazyload alt=""></p><p>所以，$\tilde{A}H^{(l)}$ 的含义是：$l+1$ 层的第 0 节点表示是 $l$ 层第 0(自环), 1, 2 节点表示的和。</p><p>GCN 计算方式本质上跟 CNN 卷积过程一样，是一个加权求和的过程，就是将邻居节点通过度矩阵及其邻接矩阵，计算出各边的权重，然后加权求和。</p><p>在计算下一层节点表示的过程中, 隐含着一种机制(或是框架), <strong>消息传递</strong>:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104173754122.png" srcset="/img/loading.gif" lazyload alt=""></p><p>0号点<strong>接收</strong>了来自0、1、2号节点的消息；然后进行<strong>聚合</strong>，对自身进行<strong>更新</strong>。</p><p>总结来说，消息传递方式实现图卷积网络的过程就是：</p><ol><li><strong>发送</strong>。边上的源节点，往目标节点发送消息(特征).</li><li><strong>接收</strong>。目标节点对收到的特征进行<strong>聚合</strong>，并更新自身。</li></ol><p>既然已经能够完成特征更新的整个流程, 为什么要引入 $\tilde{D}^{-\frac{1}{2}}$ 呢? 因为如果只使用邻接矩阵做加权, 周围人对你的评价可能并不是真实的:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104173915329.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>例如新垣结衣的周围的人非常多(<strong>度非常大</strong>)，她的特征可能会因为对多人的评价而变得非常大，从而对你的评价可能就不那么准确，在训练时也容易导致梯度消失或梯度爆炸。相反，可能你的好友更加的了解你(<strong>度比较小</strong>), 对你的评价也更准确。对所有节点一视同仁会导致度大的节点特征越来越大，度小的节点越来越小。</p><p>因此, 我们可以使用<strong>度</strong>来衡量邻居信息的<strong>重要性</strong>, 这里的 $\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ 在做的事情实际上是用度矩阵对 $\tilde{A}$ 做了<strong>Renormalization</strong>:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104173835589.png" srcset="/img/loading.gif" lazyload alt=""></p><p>度 d 越大, 信息就越少, $\frac{1}{\sqrt{d}}$ 就越小.</p><blockquote><p>这里采用<strong>Renormalization</strong>是有说法的, 想深入了解可以看 <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/426784258/answer/1536731121">GCN中的拉普拉斯矩阵如何归一化？</a>.</p><p>之所以没有采用”对称归一化”这个说法, 是因为矩阵并没有真正的得到归一化, 原论文中的表述也是”Renormalization”…</p></blockquote><p>下面来总结一下 GCN 的流程:</p><ol><li><p>使用 $\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ 进行节点之间的<strong>特征传递</strong>:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105153028136.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p></li><li><p>对每一个节点做一次线性变换并且激活:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105153039440.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p></li><li><p><strong>重复</strong>上面两步多次, 实现多层GCN, 并能获得每个节点的表示：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105153056016.png" srcset="/img/loading.gif" lazyload alt=""></p></li><li><p>根据取得的节点表示 $H^{(l)}$ 将其用于<strong>下游任务</strong>:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105153122751.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p></li></ol><p>GCN首次提出了卷积的方式融合图结构特征，提供一个全新的视角。</p><p>主要缺点：</p><ol><li>融合时边权值是固定的，不够灵活。</li><li>可扩展性差，因为它是全图卷积融合，全图做梯度更新，当图比较大时，这样的方式就太慢了，不合适。</li><li>层数加深时，结果会极容易平滑，每个点的特征结果都十分相似。</li></ol><blockquote><p>详细的数学推导可以看 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/107162772">图卷积网络（GCN）入门详解</a></p></blockquote><h3 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h3><p>在GCN中的边权重是通过<strong>度</strong>来控制的, 这种度量仅与度有关, 而且不可学习权重的分配方式.</p><p>在深度学习背景下, 我们更希望能够模型能够<strong>自己学习</strong>如何分配权重. 在深度学习中, 关于学习权重分配的分配方式, 人们很自然而然的就想到了<strong>Attention</strong>, 它也确实非常适合去做这件事情. <strong>图注意力网络</strong>(<strong>G</strong>raph <strong>At</strong>tention Network, <strong>GAT</strong>)应运而生.</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104210607354.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>GAT 通过对调整当前节点 $i$ 与其他节点 $j$ 之间的关系的权重来调整, 在这里只考虑节点 $i$ 的<strong>一阶邻居</strong> $j\in N_i$.</p><script type="math/tex;mode=display">e_{i j}=a\left(\mathbf{W} \vec{h}_{i}, \mathbf{W} \vec{h}_{j}\right)</script><p>GAT 中的 <strong>注意力系数 Attention coefficient</strong> 计算方式如下:</p><script type="math/tex;mode=display">\displaylines{
\alpha_{i j}=\operatorname{softmax}_{j}\left(e_{i j}\right)=\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(e_{i k}\right)}
\\\ \Downarrow \\
\alpha_{i j}=\frac{\exp \left(\operatorname{LeakyReLU}\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} || \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\text { LeakyReLU }\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} || \mathbf{W} \vec{h}_{k}\right]\right)\right)}
}</script><p>其中 $\overrightarrow{\mathbf{a}}$ 是一个权重向量, 也可以被视作是一个<strong>单层神经网络</strong>, $\mathbf{W}$ 为权重矩阵, 能够学习到输入特征 $\overrightarrow{h}$ 中更高级的特征. GAT 计算各节点的高阶特征, 后计算各节点对当前节点的重要程度, 并经过 LeakyReLU 激活, 最后用 Softmax 做归一化, 求得 注意力系数:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104211854226.png" srcset="/img/loading.gif" lazyload style="zoom:33%"></p><p>对特征的聚合方式如下:</p><script type="math/tex;mode=display">\vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)</script><p>$\sigma$ 是非线性的激活函数.</p><p>与 Transformer 一样, GAT 也支持<strong>多头特征聚合</strong>:</p><script type="math/tex;mode=display">\vec{h}_{i}^{\prime}=\operatorname{\lVert}\limits_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script><p>其中 $||$ 代表 Concatenation. 即将多个头的特征 Concat 起来. 当然也可以采用求平均的方式来适应不同的场景:</p><script type="math/tex;mode=display">\vec{h}_{i}^{\prime}=\sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script><p>GAT 总体来说如下所示:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220104213525395.png" srcset="/img/loading.gif" lazyload style="zoom:40%"></p><p>图中三种颜色的线代表有三个头, 学习到了不同的权重分配方式, 最后再通过某种聚合方式聚合获得 $\overrightarrow{h_1^\prime}$.</p><p>因此, GAT 不但将权重调整为与两个节点都相关的函数, 而且系数权重还是可学习的, 它同样遵守<u>消息传递框架</u></p><h3 id="Message-Passing"><a href="#Message-Passing" class="headerlink" title="Message Passing"></a>Message Passing</h3><p>消息传递是对图神经网络更新权重方式的一种<strong>范式</strong>或是一种<strong>框架</strong>。GCN、GAT 都是基于邻居聚合的模型 称为 Spatial (空间) GNN, 大部分的 Spatial GNN 都可以用 Message Passing实现</p><p>基于消息传递的 Graph Neural Network的通用公式如下:</p><script type="math/tex;mode=display">h_{l}^{(t)}(v)=\color{green}{f}\left(h_{l}^{(t-1)}, \color{red}{\mathcal{F}}\left\{\color{blue}{h_{l}^{(t-1)}(u) \mid u \in N(v)}\right\}\right)</script><p>其中 $h_{l}^{(t-1)}(u)$ 代表邻居的消息发送, $\mathcal{F}$ 代表聚合函数, 可以是 <strong>Max</strong>, <strong>Mean</strong>, <strong>Sum</strong> 等, $\mathcal{F}$ 对应神经网络, 可以是 MLP 或者其他结构. 在 GCN 中, $\mathcal{F}$ 是基于<strong>度</strong>的加权求和, 在GAT 中是基于 <strong>Attention</strong> 的加权求和</p><h2 id="Graph-Sampling"><a href="#Graph-Sampling" class="headerlink" title="Graph Sampling"></a>Graph Sampling</h2><p>前面 GCN 举例的图中，使用的图 $G$ 节点个数非常少，然而在实际问题中，一张图可能节点非常多，因此就没有办法一次性把整张图送入计算资源，所以应该使用一种有效的<strong>子图采样</strong>算法，从全图 $G$ 中采样出一个子图 $g$，这样就可以进行训练了</p><p>但子图采样并不是随机采样, 我们最起码要保证采样完后的图是<strong>连通</strong>的。例如下图中，左边采样的子图就是连通的，右边的子图不是连通的</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105103240882.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><h3 id="GraphSAGE-SAmple-amp-aggreGatE"><a href="#GraphSAGE-SAmple-amp-aggreGatE" class="headerlink" title="GraphSAGE (SAmple &amp; aggreGatE)"></a>GraphSAGE (SAmple &amp; aggreGatE)</h3><p>GraphSAGE(<strong>SA</strong>mple &amp; aggre<strong>G</strong>at<strong>E</strong>) 主要分两步：<strong>采样、聚合</strong>、(节点预测)</p><p>假设有下面这么一张图, 我们需要求出0号节点的表示, 所以需要从0号节点开始采样:</p><ol><li><p><strong>采样</strong>的阶段首先选取一个点，然后随机选取这个点的一阶邻居，再以这些邻居为起点随机选择它们的一阶邻居。</p><p>因此首先随机选择 0 号节点的一阶邻居 2、4、5，然后<strong>随机</strong>选择 2 号节点的一阶邻居 8、9；4 号节点的一阶邻居 11、12；5 号节点的一阶邻居 13、15</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105103738578.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p></li><li><p><strong>聚合</strong>具体来说就是直接将子图从全图中抽离出来，从最边缘的节点开始，一层一层向里<strong>更新</strong>节点</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105103840425.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p></li><li><p>最后就可以通过采样获得的子图来做节点预测了.</p></li></ol><p>邻居采样有两个优点:</p><ol><li><p>极大减少了训练计算量.</p></li><li><p>在<strong>推断</strong>时允许新的节点的加入, 增强了<strong>泛化</strong>能力.</p><p>因为原本要更新一个节点需要它周围的所有邻居，而通过邻居采样之后，每个节点就不是由所有的邻居来更新它，而是部分邻居节点，所以具有比较强的泛化能力, 也就是所谓的 Inductive 能力.</p></li></ol><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105104530922.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><div class="note note-info"><p>关于 GraphSAGE 在 <strong>Inductive</strong> 上的能力讨论可以看<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/409415383/answer/1361596817">这里</a>, 我个人是比较赞同答主的说法(但是有点没看懂T^T)。算法能否 Inductive 和 Transductive 仅取决于节点输入是否是 One Hot , 以及在更新节点表示时是否只依赖于局部子图.</p><blockquote><p>“Inductive learning” 意为归纳学习，“Transductive learning” 意为直推学习。</p></blockquote></div><h3 id="PinSAGE"><a href="#PinSAGE" class="headerlink" title="PinSAGE"></a>PinSAGE</h3><p><strong>采样时只能选取真实的邻居节点吗？</strong>如果构建的是一个与虚拟邻居相连的子图有什么优点？PinSAGE 算法将会给我们解答</p><ul><li>PinSAGE 算法通过多次随机游走，按游走经过的<strong>频率</strong>选取邻居.</li></ul><p>例如下面以 0 号节点作为起始，随机进行了 4 次游走</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105112734715.png" srcset="/img/loading.gif" lazyload style="zoom:70%"></p><p>其中 5、10、11 三个节点出现的频率最高，因此我们将这三个节点与 0 号节点相连，作为 0 号节点的虚拟邻居</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105112819870.png" srcset="/img/loading.gif" lazyload style="zoom:70%"></p><p>回到上述问题，采样时选取虚拟邻居有什么好处？</p><p><strong>可以快速获取高阶邻居的信息。</strong>实际上如果是按照 GraphSAGE 算法的方式生成子图，在聚合的过程中，非一阶邻居的信息可以通过消息传递逐渐传到中心，但是随着距离的增大，离中心越远的节点，其信息在传递过程中就越困难，甚至可能无法传递到；如果按照 PinSAGE 算法的方式生成子图，有一定的概率可以将非一阶邻居与中心直接相连，这样就可以快速聚合到多阶邻居的信息</p><h2 id="Neighborhood-Aggregation"><a href="#Neighborhood-Aggregation" class="headerlink" title="Neighborhood Aggregation"></a>Neighborhood Aggregation</h2><p>邻居聚合是在图采样之后做的操作, 不同的聚合方式可以达到不同效果. 经典的聚合函数有:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105114426271.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>栗：Max：特征维度对应的地方进行比较，比如第 0 位置上的max为 1，第 1 位置上的max也为 1</p><p>评估聚合表达能力的指标是<strong>单射(一对一映射)</strong>, 单射能保证对聚合以后的结果<strong>可区分</strong>:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105114516651.png" srcset="/img/loading.gif" lazyload alt=""></p><p>两个子图分别进行 Mean、Max得出的结果相同，说明是不可区分的。对于不同的子图, Sum 保留了单射能力:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105114645993.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>因此, 就有基于单射的 GIN(<strong>G</strong>raph <strong>I</strong>somorphism <strong>N</strong>et)模型:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105114753035.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>它的聚合方式就是具有单射能力的<strong>SUM</strong>, 但是为了区分中心节点与邻居, 特意加上了 $\mathcal{E}$:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220105114742148.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>当然, GCN, GAT这类的聚合函数都是相较于经典聚合函数更为复杂的.</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/GNN/">GNN</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/GNN/">GNN</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2021/12/29/R-GCN%EF%BC%9AModeling%20Relational%20Data%20with%20Graph%20Convolutional%20Networks/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">【R-GCN】Modeling Relational Data with Graph Convolutional Networks</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/11/18/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"><span class="hidden-mobile">奇奇怪怪的问题记录</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>