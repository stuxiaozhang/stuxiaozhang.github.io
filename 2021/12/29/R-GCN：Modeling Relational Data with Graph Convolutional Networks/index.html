<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="【R-GCN】Modeling Relational Data with Graph Convolutional NetworksBasic Idea目前大规模知识图谱仍然不完整，并且知识图谱中还没有针对图结构建模的方法。许多缺失的信息，而节点缺失的信息经常可以由邻居节点编码而来。
在 KG 中, 经常用 Entity Classification 和 Link Prediction 作为任务来衡"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>【R-GCN】Modeling Relational Data with Graph Convolutional Networks - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="【R-GCN】Modeling Relational Data with Graph Convolutional Networks"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-12-29 12:04" pubdate>2021年12月29日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.9k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 22 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">【R-GCN】Modeling Relational Data with Graph Convolutional Networks</h1><p class="note note-info">本文最后更新于：2022年1月6日</p><div class="markdown-body"><h1 id="【R-GCN】Modeling-Relational-Data-with-Graph-Convolutional-Networks"><a href="#【R-GCN】Modeling-Relational-Data-with-Graph-Convolutional-Networks" class="headerlink" title="【R-GCN】Modeling Relational Data with Graph Convolutional Networks"></a>【R-GCN】Modeling Relational Data with Graph Convolutional Networks</h1><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>目前大规模知识图谱仍然不完整，并且知识图谱中还没有针对<strong>图结构</strong>建模的方法。许多缺失的信息，而节点缺失的信息经常可以由邻居节点<strong>编码</strong>而来。</p><p>在 KG 中, 经常用 Entity Classification 和 Link Prediction 作为任务来衡量模型对KG补全的能力:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220102214203959.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>图中红色字体为缺失信息, 对应着实体类型和关系。</p><p>在大规模知识图谱中，<strong>多关系数据</strong>特性十分显著，作者希望针对多关系数据，提出一种基于图的方法进行知识图谱补全。</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220101182159046.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><ul><li><p>同构图：点类型 + 边类型=2(也就是不区分点与边类型)</p></li><li><p>异构图：点类型 + 边类型&gt;2</p></li></ul><p>从同构图模型到异构图模型，这其中的差别就是多关系，点多类型的差别。像 GCN，GAT，GraphSAGE 都是以同构图进行研究，沿着这个同构图模型的思想出发，大胆假设一下，将异构图分成多个含单一关系的同构图，那么会发现，其实只需要解决不同关系之间的交互，就可以套用同构图的思想解决异构图的问题。</p><p>于是 R-GCN 就来了（其实 R-GCN 就是这么想的。）</p><h2 id="Relational-Graph-Convolutional-Network"><a href="#Relational-Graph-Convolutional-Network" class="headerlink" title="Relational Graph Convolutional Network"></a>Relational Graph Convolutional Network</h2><p>有向且有标签的多图被表示为 $G=(V,E,R)$，其中节点 $v_i \in V$，边 $(v_i,r,v_j) \in E$, 关系类型 $r \in R$ 。</p><h3 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h3><p>R-GCN 和 GCN 都是利用图卷积模型来模拟信息在网络结构中的传递。R-GCN 是一种 GCN 的扩展形式，GCN 能够聚合周围邻居的信息。</p><p>GCN 遵循<strong>消息传递</strong>机制：</p><script type="math/tex;mode=display">h_{i}^{(l+1)}=\sigma\left(\sum_{m \in \mathcal{M}_{i}} g_{m}\left(h_{i}^{(l)}, h_{j}^{(l)}\right)\right)</script><p>其中 $h<em>{i}^{(l)}$ 是节点 $v_i$ 第 $l$ 层的节点表示(隐藏状态)， $h</em>{j}^{(l)}$ 是节点 $v_i$ 第 $l$ 层的邻居节点，$\mathcal{M_i}$ 为节点 $v_i$ 的<strong>入边</strong>集合。$\sigma$ 为非线性激活函数，例如 $\operatorname{ReLU}$</p><p>$g_m(\cdot, \cdot)$ 为邻居节点的<strong>聚合方式</strong>，一般只用简单的线性变换作为替代，即 $g_m(h_i, h_j) = Wh_j$ 。</p><h3 id="R-GCN"><a href="#R-GCN" class="headerlink" title="R-GCN"></a>R-GCN</h3><p>RGCN 应该说是 GCN 在多关系图场景上的一个简单尝试。<strong>从同构图到异构图，RGCN要解决的核心问题就一个，就是多关系间怎么交互。</strong></p><p>RGCN 的 结构图如下，每一种关系下（可理解为就是同构图），指向内与指向外的都作为它的邻居点，同时加自循环特征，进行特征融合，参与更新中心节点。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20211229233418337.png" srcset="/img/loading.gif" lazyload style="zoom:55%"></p><p>每种关系分别经过变换求和得到绿色块，对所有关系的绿色块求和并激活，得到红色中心节点的新表示。</p><p>可以看到：同一关系，有 in 和 out 的区别，也就是方向的不同决定了关系也是不同的，可以理解为有向图。</p><p>针对不同种类的关系，R-GCN 采用<strong>不同的聚合方式</strong>，在这里是使用了不同的线性变换矩阵 $W_r$，其更新方程为:</p><script type="math/tex;mode=display">h_{i}^{(l+1)}=\sigma\left(\sum_{r \in \mathcal{R} } \sum_{j \in \mathcal{N}_{i}^{r} } \frac{1}{c_{i, r} } W_{r}^{(l)} h_{j}^{(l)}+W_{0}^{(l)} h_{i}^{(l)}\right)</script><p>其中 $h<em>i$ 就是 $l$ 层节点本身，$W_r$ 是 关系 $r$ 下的权重矩阵，$h_j$ 是关系 $r$ 下的邻居节点，也就是说，不同关系下分开来算。 $c</em>{i,r}$ 代表归一化因子, 可以由学习得来, 或规定 $c_{i, r} = |\mathcal{N}_i^r|$。$W_0$ 代表节点自身闭环所对应的变换矩阵。</p><p>针对节点 $v_i$ 及其所有邻居 $N_i$, 分别考虑 $v_i$ 与邻居 $v_j$ 二者之间的关系 $r$，施加以不同的关系变换 $W_r$，再将它们求和并归一化，加上自身的闭环影响，在激活函数的影响下获得下一层的节点表示。</p><p>对比一下 GCN : $H^{(l+1)}=\sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})$ 看得到，W在两边皆为模型待学参数，而 GCN 是采用度矩阵D及邻接矩阵A作为一个加权求和的特征融合，而 R-GCN 的参数都在模型参数 $W_r$ 中，它没有用度矩阵D及邻接矩阵A作为边的权重的，而是在模型中参数自学.</p><h3 id="Regularization-规则化"><a href="#Regularization-规则化" class="headerlink" title="Regularization 规则化"></a>Regularization 规则化</h3><p>由于 R-GCN 模型应用于多关系数据，因此一个核心的问题就是当图中关系与参数数目增长时，会产生对罕见关系过拟合的问题。文中对此提出了两种独立的方法对 R-GCN 层进行规则化：基函数分解 和 块对角分解。</p><h4 id="Basic-Decomposition"><a href="#Basic-Decomposition" class="headerlink" title="Basic Decomposition"></a>Basic Decomposition</h4><p>基函数分解将所有关系的权重矩阵 $W_{r}^{(l)}$ 视为不同系数和基的<strong>线性组合</strong>:</p><script type="math/tex;mode=display">W_{r}^{(l)}=\sum_{b=1}^{B} a_{r b}^{(l)} V_{b}^{(l)}</script><p>其中 $B$ 为基的数量，$a_{rb}$ 是不同关系 $r$ 下的系数，$V_b$ 是分解的参数关系矩阵，二者都与关系类型 $r$ 相关，<strong>这里不同关系是共享 $V_b$ 参数的</strong>。</p><p>这种表示方法可以被视为是不同关系下的<strong>权重共享</strong>，对于少关系的情况能够缓解过拟合现象，因为关系之间的基是相互共享的，基总会被其他关系所频繁更新。</p><h4 id="Block-Diagonal-Decomposition"><a href="#Block-Diagonal-Decomposition" class="headerlink" title="Block - Diagonal Decomposition"></a>Block - Diagonal Decomposition</h4><p>块对角分解将变换矩阵 $W_r$ 拆分为 $B$ 个大小<strong>相同</strong>的块:</p><script type="math/tex;mode=display">W_{r}^{(l)}=\bigoplus_{b=1}^{B} Q_{b r}^{(l)}=diag(Q_{1r}^{(l)}......Q_{Br}^{(l)})</script><p>其中 $Q<em>{b r}^{(l)} \in \mathbb{R}^{\left(d^{(l+1)} / B\right) \times\left(d^{(l)} / B\right) }$，$\bigoplus$ 为生成一系列低维矩阵 $Q</em>{Br}$ 的求和。</p><p>对角块分解又可以视为是一种 $W_r$ 的一种<strong>稀疏性约束</strong>，除去块的位置其余位置都是0，与未分解时相比更为稀疏。而且由于分块的影响，在每个块内部，隐特征的联系将比块与块之间更加<strong>紧密</strong>。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103212837251.png" srcset="/img/loading.gif" lazyload style="zoom:90%"></p><p>至此，R-GCN 已经能够作为一个单独的层，按照层级结构堆叠获得 $L$ 层的多层输出。如果没有节点的初始特征，可以采用 <strong>Embedding</strong> 的方式获取。</p><h3 id="Entity-Classification"><a href="#Entity-Classification" class="headerlink" title="Entity Classification"></a>Entity Classification</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103213601424.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><p>对于实体分类任务，R-GCN 进行堆叠作为 Encoder，通过 R-GCN 的卷积，可以得到每个节点的向量表示，然后再最后一层使用 softmax 激活函数，得到每个节点的预测类别。最后通过有标签的节点来学习模型的参数，具体是通过最小化交叉熵损失函数</p><script type="math/tex;mode=display">\mathcal{L}=-\sum_{i \in \mathcal{Y}} \sum_{k=1}^{K} t_{i k} \ln h_{i k}^{(L)}</script><p>其中 $\mathcal{Y}$ 为有标签的节点集合，$K$ 为类别总数</p><h3 id="Link-Prediction"><a href="#Link-Prediction" class="headerlink" title="Link Prediction"></a>Link Prediction</h3><p>对于链接预测问题，通常在三元组 $(s,r,o)$ 上(也就是边 $\mathcal{E}$ ) 预测缺失的尾实体 $o$，但 R-GCN 只能根据某节点不同关系的邻居获得自身的表示，并不能结合关系信息做尾实体的预测.</p><p>因此, 作者将 R-GCN 集成进 <strong>Encoder-Decoder</strong> 的框架，将 R-GCN 视为一个获取所有节点编码的 <strong>Encoder</strong>，再用其他的 KGE 模型对节点(实体)表示<strong>打分</strong>, 以完成链接预测任务:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103213941559.png" srcset="/img/loading.gif" lazyload style="zoom:70%"></p><p>在这里, 作者选用 DistMult 作为Decoder，其得分函数如下:</p><script type="math/tex;mode=display">f(s, r, o)=e_{s}^{T} R_{r} e_{o}</script><p>DistMult 是基于<strong>语义匹配</strong>的模型，对每个不同的关系，DistMult 都有不同的对角矩阵 $R_r$ 来变换头实体 $e_s$，然后与尾实体 $e_o$ 做<strong>相似度匹配</strong>。所有的 Embedding, $e_s, e_o$ 都来源于 R-GCN。</p><p>然后用 <strong>BCE</strong> 作为损失函数优化:</p><script type="math/tex;mode=display">\mathcal{L}=-\frac{1}{(1+\omega)|\hat{\mathcal{E}}|} \sum_{(s, r, o, y) \in \mathcal{T}} y \log l(f(s, r, o))+
(1-y) \log (1-l(f(s, r, o)))</script><p>其中 $ω$ 代表每个正样本采样多少个负样本，$l$ 为 sigmoid 函数。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的超参数设置和Trick请参照原论文.</p><h3 id="Entity-Classification-Experiments"><a href="#Entity-Classification-Experiments" class="headerlink" title="Entity Classification Experiments"></a>Entity Classification Experiments</h3><p>作者分别在四个实体分类数据集AIFB, MUTAG, BGS, AM上进行了实体分类任务, 数据集的统计信息如下:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103214401776.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>实验结果如下:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103214425487.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>在 AIFB 和 AM 上的效果都要高于其他模型, 而 MUTAG 和 BGS 是<strong>特定领域</strong>的数据集, 与其他两个数据集都不太一样, 导致了 R-GCN 的性能差距.</p><div class="note note-info"><p>作者提到, 对所有邻居都采用<strong>相同权重</strong>的归一化方式可能会有损性能, 一种潜在的解决方案是采用<strong>注意力机制</strong>, 通过学习分配给周围邻居不同的权重.</p><p>其实就是同年10月份提出的 GAT, 而 R-GCN 发布于同年3月份.</p></div><h3 id="Link-Prediction-Experiments"><a href="#Link-Prediction-Experiments" class="headerlink" title="Link Prediction Experiments"></a>Link Prediction Experiments</h3><p>作者主要在 FB15k, WN18, FB15k-237上做了链接预测的实验。</p><p>同样是针对关系特化的模型，作者做出了在 FB15k 的验证集中不同度对 MRR 的影响曲线:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103215614859.png" srcset="/img/loading.gif" lazyload style="zoom:90%"></p><p>作者认为 R-GCN 在度比较高, 即上下文信息比较多时处理很占优势, 而 DistMult 在度比较低时占优势.</p><div class="note note-info"><p>可能也只是作者的一个推测，DistMult 在度比较低的时候并没有比 R-GCN 好特别多.</p></div><p>观察到 R-GCN 和 DistMult 上的<strong>互补</strong>优势, 作者尝试将两种模型融合, 仍然采用 DistMult 的打分函数, 但 Embedding 分别来自于已经训练好的不同模型:</p><script type="math/tex;mode=display">f(s, r, t)_{\mathrm{R}-\mathrm{GCN}+}=\alpha f(s, r, t)_{\mathrm{R}-\mathrm{GCN}}+(1-\alpha) f(s, r, t)_{\text {DistMult }}</script><p>$\alpha$ 为选择模型得分的权重。在 FB15k 中设置为 $\alpha=0.4$，即来自 DistMult 的打分要多一些，R-GCN 少一些，因为作者不希望改进后的模型性能显著高于纯 R-GCN。</p><p>在 FB15k, WN18 上结果如下:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103215220624.png" srcset="/img/loading.gif" lazyload alt=""></p><p>在关系比较少的 WN18 上, R - GCN 并不占优势, 但在FB15k上的表现十分不错. DistMult作为关系特化的模型也在 FB15k 上显示出一些优势, 但仍不及能够对对称, 反对称, 逆关系同时建模的 ComplEx.</p><p>在 FB15k-237 上结果如下:</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20220103220328750.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>R-GCN 比其他方法效果要好特别多, 因为把 DistMult 也塞进去了, 所以比 DistMult 也显著的好。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>R-GCN 是一篇比较早的 GNN 论文，已经作为一种 KGE 中常用的图方法 Baseline 出现，也正是 R-GCN 使得大家对图方法在 KG 上的应用提起了注意.</p><p>R-GCN 的两个创新点：</p><ol><li>提出了一个异构图中多关系融合的一个方式（就是不同关系分别做融合，然后叠加处理，得到 node 表示）</li><li>针对图神经网络的<strong>过拟合</strong>问题，提出了因子分解以及多关系参数共享的方式，降低多关系引起的参数剧增。</li><li>也提出了图神经网络在处理 Entity Classification 和 Link Prediction 问题上的框架，其实主要还是把 R-GCN 的输出作为一种<strong>Node Embedding</strong>的方法来使用。</li></ol><p>对比一下 GCN，GCN 是采用度矩阵 D 及邻接矩阵 A 作为一个加权求和的特征融合，R-GCN 并没有用度矩阵D及邻接矩阵A作为边的权重的，而是把这部分都放在模型中参数自学。</p><p>作者在文中还提出了两种可以优化的地方:</p><ol><li>Decoder 还可以替换为任意的 KGE 模型, 例如能对更多关系建模的 ComplEx.</li><li>对邻居节点的权重分配可以通过 <strong>Attention</strong> 学习得来.</li></ol></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/Papers/">Papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/R-GCN/">R-GCN</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2022/01/05/Logic%20Attention%20Based%20Neighborhood%20Aggregation%20for%20Inductive%20Knowledge%20Graph%20Embedding/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">【LAN】Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/12/27/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8/"><span class="hidden-mobile">图神经网络入门</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>