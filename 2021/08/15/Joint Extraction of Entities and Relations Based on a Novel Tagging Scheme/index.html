<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme这篇文章是 ACL 2017 Outstanding Paper。作者提出了一个新的标注方案，并使用神经网络进行实体和关系的联合抽取。
Basic Idea实体与关系抽取是构建 KB 的重要步骤。两个主要框架已被广泛用于解决抽取实体及其关系的问题。一个"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-08-15 11:04" pubdate>2021年8月15日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 36 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme</h1><p class="note note-info">本文最后更新于：2021年9月19日</p><div class="markdown-body"><h1 id="Joint-Extraction-of-Entities-and-Relations-Based-on-a-Novel-Tagging-Scheme"><a href="#Joint-Extraction-of-Entities-and-Relations-Based-on-a-Novel-Tagging-Scheme" class="headerlink" title="Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme"></a>Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme</h1><p>这篇文章是 ACL 2017 Outstanding Paper。作者提出了一个新的标注方案，并使用神经网络进行实体和关系的联合抽取。</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>实体与关系抽取是构建 KB 的重要步骤。两个主要框架已被广泛用于解决抽取实体及其关系的问题。一个是<strong>流水线方法</strong>，另一个是<strong>联合学习方法</strong>。</p><ul><li><p>传统方法以<strong>流水线</strong>方法将这个任务视为两个分离的任务<strong>，即命名实体识别（NER）和关系分类（RC）。</strong>先抽取实体，然后识别它们的关系。这种分离的框架使得任务易于处理，并且每个组件都可以更加灵活。但它<strong>忽略了这两个子任务之间的相关性</strong>，每个子任务都是一个独立的模型。实体识别的结果可能会影响关系分类的性能，并导致错误的传播。</p></li><li><p><strong>联合学习框架是使用单一模型将实体和关系一起抽取出来。它可以有效地整合实体和关系的信息</strong>，并在这项任务中取得了较好的效果。然而，大多数现有的联合方法都是基于特征的结构化系统，他们需要复杂的特征工程，并且严重依赖其他 NLP 工具包，这也可能导致错误传播。</p></li></ul><p>基于两个方法的问题，作者提出了一个新颖的标注方案，然后抽取由两个实体和这两个实体之间的一个关系组成的三元组（而不是分别抽取实体和关系），并配以端到端的模型。标注方案包含实体信息和它们的关系。基于这种标注方案，实体和关系的联合抽取可以转化为标记问题。这样，可以用神经网络来建模任务，而不需要复杂的特征工程。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>作者提出了一种<strong>新的标注方案</strong>和一个具<strong>有偏置目标函数</strong>的<strong>端到端模型</strong>来联合抽取实体及其关系。</p><h3 id="Tagging-Scheme"><a href="#Tagging-Scheme" class="headerlink" title="Tagging Scheme"></a>Tagging Scheme</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816093540180.png" srcset="/img/loading.gif" lazyload alt=""></p><p>每个单词都被分配一个标签 tags，用于抽取结果。<strong>标签“O”代表“Other”标签</strong>，这意味着相应的单词与抽取结果无关。除了“O”之外，其他标签由<strong>三部分组成</strong>：<strong>实体中的单词位置</strong>、<strong>关系类型</strong>和<strong>关系角色</strong>。<strong>使用“BIES”（Begin, Inside, End, Single）符号来表示单词在实体中的位置信息</strong>。<strong>关系类型信息是从一组预定义的关系中获得的</strong>，<strong>关系角色信息由数字“1”和“2”表示</strong>。抽取的结果由三元组表示：<code>(Entity1，RelationType，Entity2)</code>。“1”表示该词属于三元组中的第一个实体，而“2”则属于该关系类型后面的第二个实体。</p><p>图2是一个说明标注方法的例子。输入句子包含两个三元组：<code>&#123;United States, Country-President, Trump&#125;</code> 和 <code>&#123;Apple Inc, Company-Founder, Steven Paul Jobs&#125;</code>，其中 <code>“Country-President”</code> 和 <code>“Company-Founder”</code> 是预定义的关系类型。<code>”United”</code>, <code>“States”</code>, <code>“Trump”</code>, <code>“Apple”</code>, <code>“Inc”</code> , <code>“Steven”</code>, <code>“Paul”</code> 和 <code>“Jobs”</code> 等词都与最终抽取的结果有关。因此，他们根据特殊标签进行标注。例如 <code>“United”</code> 这个词是<code>“United States”</code> 实体的第一个词，与 <code>“Country-President”</code> 关系有关，所以它的标签是 <code>“B-CP-1”</code>。对应于 <code>“United States”</code> 的另一个实体 <code>“Trump”</code> 被标记为 <code>“S-CP-2”</code>。此外，与最终结果无关的其他字词标记为 <code>“O”</code>。</p><h3 id="End-to-end-Model"><a href="#End-to-end-Model" class="headerlink" title="End-to-end Model"></a>End-to-end Model</h3><p>本文采用了一个端到端的模型来生成标注序列，如图 3 所示。模型用 Bi-LSTM 来对输入句子进行编码，用具有偏置损失的 LSTM 进行解码，偏置损失可以增强实体标签的相关性。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816095825365.png" srcset="/img/loading.gif" lazyload alt=""></p><h4 id="Bi-LSTM-编码层"><a href="#Bi-LSTM-编码层" class="headerlink" title="Bi-LSTM 编码层"></a>Bi-LSTM 编码层</h4><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816194652396.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p><strong>在序列标注问题中，Bi-LSTM 编码层已被证明有效捕获每个单词的语义信息</strong>。它包含前向 LSTM 层，后向 LSTM 层和连接层。<strong>词嵌入层将 one-hot 表示的单词转换为嵌入向量</strong>。因此，一个单词序列可以表示为 $W = {w<em>1，… w_t，w</em>{t+1} … w<em>n}$，其中 $w_t \in R_d$ 是对应于句中第 $t$ 个单词的 $d$ 维词向量，$n$ 是给定句子的长度。在词嵌入层之后，有两个平行的 LSTM 层：前向 LSTM 层 和 后向 LSTM 层。 LSTM 体系结构由一组递归连接的子网（称为 memory blocks）组成。每个时间步是一个 LSTM memory block。 Bi-LSTM 编码层中的 LSTM 记忆块用于根据上一个隐藏向量 $h</em>{t-1}$、上一个单元向量 $c_{t-1}$ 和当前输入词表示 $w_t$ 计算当前隐藏向量$h_t$。其结构图如图3（b）所示，具体操作定义如下：</p><script type="math/tex;mode=display">\begin{array}{l}
f_{t}=\delta\left(W_{w f} w_{t}+W_{h f} h_{t-1}+W_{c f} c_{t-1}+b_{f}\right) \quad (遗忘门 f_t) \\
i_{t}=\delta\left(W_{w i} w_{t}+W_{h i} h_{t-1}+W_{c i} c_{t-1}+b_{i}\right) \quad (输入门 i_t)  \\  
z_{t}=\tanh \left(W_{w c} w_{t}+W_{h c} h_{t-1}+b_{c}\right) \\
c_{t}=f_{t} c_{t-1}+i_{t} z_{t} \\
o_{t}=\delta\left(W_{w o} w_{t}+W_{h o} h_{t-1}+W_{c o} c_{t}+b_{o}\right) \quad (输出门 o_t)  \\
h_{t}=o_{t} \tanh \left(c_{t}\right) \quad (输出结果：当前隐藏向量h_t,作为Decoder层的其中一种输入)
\end{array}</script><h5 id="Bi-LSTM"><a href="#Bi-LSTM" class="headerlink" title="Bi-LSTM"></a>Bi-LSTM</h5><p>前向的LSTM与后向的LSTM结合成BiLSTM。比如，我们对“我爱中国”这句话进行编码，模型如图所示。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210825205225012.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>前向的 LSTML 依次输入“我”，“爱”，“中国” 得到三个向量 ${h<em>{L0}, h</em>{L1}, h<em>{L2}}$。后向的LSTMR依次输入“中国”，“爱”， “我”得到三个向量 ${h</em>{R0}, h<em>{R1}, h</em>{R2}}$。最后将前向和后向的隐向量进行拼接得到 ${[h<em>{L0}, h</em>{R2}], [h<em>{L1}, h</em>{R1}], [h<em>{L2}, h</em>{R0}] }$, 即 ${ho, h1, h2}$。</p><p>所以这个模型图应该是这样（略草率请忽略:P）：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919160619913.png" srcset="/img/loading.gif" lazyload style="zoom:60%"></p><h4 id="LSTM-解码器层"><a href="#LSTM-解码器层" class="headerlink" title="LSTM 解码器层"></a>LSTM 解码器层</h4><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816194348347.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>作者也<strong>采用LSTM结构来生成标注序列</strong>。当检测到单词 $w<em>t$ 的标注时，解码层的输入为：从 Bi-LSTM 编码层获得的 $h_t$，上一个的预测标签表示 $T</em>{t-1}$，上一个单元单元值：$c<em>{t-1}$，以及解码层中的上一个隐藏向量 $h</em>{t-1}$。图3（c）显示了 LSTMd 记忆块的结构图，具体操作定义如下</p><script type="math/tex;mode=display">\begin{array}{l}
f_{t}^{(2)}=\delta\left(W_{w f}^{(2)} h_{t}+W_{h f}^{(2)} h_{t-1}^{(2)}+W_{t f} T_{t-1}+b_{f}^{(2)}\right) \quad (遗忘门 f_t) \\
i_{t}^{(2)}=\delta\left(W_{w i}^{(2)} h_{t}+W_{h i}^{(2)} h_{t-1}^{(2)}+W_{t i} T_{t-1}+b_{i}^{(2)}\right) \quad (输入门 i_t)  \\  
z_{t}^{(2)}=\tanh \left(W_{w c}^{(2)} h_{t}+W_{h c}^{(2)} h_{t-1}^{(2)}+W_{t c} T_{t-1}+b_{c}^{(2)}\right) \\
c_{t}^{(2)}=f_{t}^{(2)} c_{t-1}^{(2)}+i_{t}^{(2)} z_{t}^{(2)} \\
o_{t}^{(2)}=\delta\left(W_{w o}^{(2)} h_{t}+W_{h o}^{(2)} h_{t-1}^{(2)}+W_{c o}^{(2)} c_{t}+b_{o}^{(2)}\right)\quad (输出门 o_t)  \\
h_{t}^{(2)}=o_{t}^{(2)} \tanh \left(c_{t}^{(2)}\right) \\
T_{t}=W_{t s} h_{t}^{(2)}+b_{t s}
\end{array}</script><p>最终的 softmax 层根据标签预测向量 $T_t$ 计算归一化实体标签概率：</p><script type="math/tex;mode=display">y_{t}=W_{y} T_{t}+b_{y} \\
p_{t}^{i}=\frac{\exp \left(y_{t}^{i}\right)}{\sum_{j=1}^{N_{t}} \exp \left(y_{t}^{j}\right)}</script><p>$W_y$ 是 softmax 矩阵，$N_t$ 是标签总数。由于 $T$ 与标签嵌入类似，并且 LSTM 能够学习长期相关性，所以解码方式可以对标签交互进行建模。</p><div class="note note-primary"><p>这个标签的概率所在的索引，就是标签的 id，会有一个 id2label 字典存放的是 id:标签名称，根据字典就能得到标签名称，根据标签名称就能解码实体和关系，像前面例子中的那样</p></div><h4 id="偏置目标函数"><a href="#偏置目标函数" class="headerlink" title="偏置目标函数"></a>偏置目标函数</h4><p>目标函数定义为：</p><script type="math/tex;mode=display">\begin{aligned}
L=& \max \sum_{j=1}^{|\mathbb{D}|} \sum_{t=1}^{L_{j}}\left(\log \left(p_{t}^{(j)}=y_{t}^{(j)} \mid x_{j}, \Theta\right) \cdot I(O)\right.
\left.+\alpha \cdot \log \left(p_{t}^{(j)}=y_{t}^{(j)} \mid x_{j}, \Theta\right) \cdot(1-I(O))\right)
\end{aligned}</script><p>$|D|$ 是训练集的大小，$L_j$ 是句子 $x_j$ 的长度，$y_t^{(j)}$ 是单词 $x_j$ 中词 $t$ 的 tag，$p_t^{(j)}$ 是在上面定义的归一化实体标签概率。$I(O)$ 是一个开关函数，以区分标注 <code>‘O’</code> 与可指示结果的相关 tags 间的损失。定义如下：</p><script type="math/tex;mode=display">I(O)=\left\{\begin{array}{l}
1, \text { if } \operatorname{tag}={ }^{\prime} O^{\prime} \\
0, \text { if } \operatorname{tag} \neq{ }^{\prime} O^{\prime}
\end{array}\right.</script><p>$α$ 是偏置权重，$α$ 越大，对模型中相关 tags 的影响越大。给个 alpha 是想让模型更多关注实体类型的 token</p><p>其实合起来看就是：</p><script type="math/tex;mode=display">L = \left\{\begin{array}{l}
\max \sum_{j=1}^{|\mathbb{D}|} \sum_{t=1}^{L_{j}}\left.\log \left(p_{t}^{(j)}=y_{t}^{(j)} \mid x_{j}, \Theta\right)  \right. , \text { if } \operatorname{tag}={ }^{\prime} O^{\prime} \\
\max \sum_{j=1}^{|\mathbb{D}|} \sum_{t=1}^{L_{j}}\left.\alpha \cdot \log \left(p_{t}^{(j)}=y_{t}^{(j)} \mid x_{j}, \Theta\right) \right. , \text { if } \operatorname{tag} \neq{ }^{\prime} O^{\prime}
\end{array}\right.</script><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>数据集使用公共数据集 NYT。大量的训练数据可以通过远程监督的方式获得，无需人工标注。测试集是手工标记以确保其质量。训练数据总共包含353k三元组，测试集包含3,880三元组。此外，关系集的大小是24。</p><div class="note note-primary"><p>为了打破有监督学习中人工数据标注的局限性，Mintz等人提出了远程监督（Distant Supervision）算法，该算法的核心思想是将文本与大规模知识图谱进行实体对齐，利用知识图谱已有的实体间关系对文本进行标注。</p><p>远程监督基于的基本假设是：如果从知识图谱中可获取三元组R（E1，E2）（注：R代表关系，E1、E2代表两个实体），且E1和E2共现与句子S中，则S表达了E1和E2间的关系R，标注为训练正例。</p><p>远程监督算法是目前主流的关系抽取系统广泛采用的方法，也是该领域的研究热点之一。该算法很好地解决了数据标注的规模问题，但它基于的基本假设过强，会引入大量噪音数据。出现 <code>the wrong label problem</code> 的根本原因，是远程监督假设一个实体对只对应一种关系，但实际上实体对间可以同时具有多种关系.</p></div><h3 id="Performance-Comparison"><a href="#Performance-Comparison" class="headerlink" title="Performance Comparison"></a>Performance Comparison</h3><p>采用标准<strong>Precision（Prec）、Recall（Rec）和F1分数</strong>来评估结果。当三元组的关系类型和两个对应的实体的头部偏移都是正确的时，这个三元组被认为是正确的。从测试集中随机抽取10％的数据来创建验证集。对每个实验运行10次，然后报告平均结果和它们的标准偏差，如表1所示。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816103031029.png" srcset="/img/loading.gif" lazyload alt=""></p><p>表一：抽取两个实体及其关系的不同方法的预测结果。第一部分（从第一行到第三行）是流水线方法，第二部分（第四行到第六行）是联合抽取方法。作者的标注方法在第三部分（第7到第9行）中显示。在这一部分在准确率、召回率和F1的结果同时，还计算了它们的标准差。</p><p>从表 1 可以看出，</p><ol><li>联合抽取方法优于流水线方法，作者的标注方法优于流水线方法和大多数联合抽取方法。这也验证了标注方案对共同抽取实体和关系的任务的有效性。</li><li>与传统方法相比，<strong>端到端模型的准确率显著提高</strong>。但是<strong>只有 LSTM-LSTM-Bias 可以更好地平衡准确率和召回率</strong>（通过比较 F1 分数）。原因可能是这些端到端模型都使用 Bi-LSTM 编码输入句子和不同的神经网络来解码结果，而基于神经网络的方法可以很好地拟合数据，因此，他们可以很好地学习训练集的共同特征，并可能导致较低的可扩展性。</li><li>基于作者的标注方案，LSTM-LSTM 模型优于 LSTM-CRF 模型。因为，LSTM 能够学习长期的依赖关系，CRF 擅长捕捉整个标注序列的联合概率。相关的标签可能相距很远。因此，LSTM 解码方式比 CRF 好一些。 LSTM-LSTM-Bias 增加了一个偏置权重，以增强实体标注的效果，减弱无效标注的影响。因此，在这个标注方案中，作者的方法可以比普通的 LSTM 解码方法更好。</li></ol><div class="note note-primary"><p><strong>有关准确率（Accuracy）、Precision（Prec）、Recall（Rec）和F1分数：</strong></p><ul><li>TP（True Positives）意思就是<strong>被分为了正样本，而且分对了</strong>。</li><li>TN（True Negatives）意思就是<strong>被分为了负样本，而且分对了</strong>。</li><li>FP（False Positives）意思就是<strong>被分为了正样本，但是分错了（事实上这个样本是负样本）</strong>。</li><li>FN（False Negatives）意思就是<strong>被分为了负样本，但是分错了（事实上这个样本是正样本）。</strong></li></ul><p><strong>准确率（Accuracy）：</strong></p><script type="math/tex;mode=display">Accuracy = \frac{TP + TN}{TP + TN+FP + FN}</script><p>准确率就是所有的预测正确（正类负类）的占总的比重。</p><p><strong>precision（精确度）：</strong></p><script type="math/tex;mode=display">Precision= \frac{TP}{TP+FP}</script><p>TP是 分类器认为是正样本而且确实是正样本的例子，FP是 分类器认为是正样本但实际上不是正样本的例子，Precision 翻译过来就是<strong>“分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例”</strong>。</p><p><strong>recall（召回率）：</strong></p><script type="math/tex;mode=display">Recall=\frac{TP}{TP+FN}</script><p>TP是 分类器认为是正样本而且确实是正样本的例子，FN是 分类器认为是负样本但实际上不是负样本的例子，Recall 翻译过来就是“<strong>分类器认为是正类并且确实是正类的部分占所有确实真正是正类的比例</strong>”。</p><p>P 和 R 指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是 <strong>F-Measure</strong> ，通过计算F值来评价一个指标</p><p>常见的 <strong>F1 计算方法</strong>：</p><script type="math/tex;mode=display">F1 = \frac{2 \cdot P \cdot R}{P + R}</script></div><h3 id="Predicted-Results-on-Triplet’s-Elements"><a href="#Predicted-Results-on-Triplet’s-Elements" class="headerlink" title="Predicted Results on Triplet’s Elements"></a>Predicted Results on Triplet’s Elements</h3><p>为了<u>找出影响端到端模型结果的因素</u>，作者分析了预测三元组中每个元素的性能，只有当两个相应实体的关系类型和头部偏移量都是正确的时候，它才能处理三元组。如表 2 所示。E1 和 E2 分别表示预测每个实体的性能。如果第一个实体的头部偏移是正确的，那么 E1 的实例是正确的，E2 同理。不管关系类型，如果两个对应实体的头部偏移都是正确的，则（E1，E2）的实例是正确的。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816103433932.png" srcset="/img/loading.gif" lazyload alt=""></p><ol><li><p>Compare (E1,E2) with single E：与 single E1 和 E2 相比，（E1，E2）具有更高的准确率。<strong>但其召回率低于E1和E2。这意味着一些预测的实体不会形成一对。</strong>他们只获得E1而没有找到相应的E2，或者获得E2并且没有找到相应的E1，导致更多的单个E和更少（E1，E2）对的预测。因此，实体对（E1，E2）比单个E具有更高的准确率和更低的召回率。</p></li><li><p>Compare (E1,E2) with Triplet：与表1中的预测结果相比，表2中（E1，E2）的预测结果有大约3%的改进，这意味着3%的测试数据被预测为错误，因为关系类型被预测为错误。</p></li></ol><h3 id="Analysis-of-Biased-Loss"><a href="#Analysis-of-Biased-Loss" class="headerlink" title="Analysis of Biased Loss"></a>Analysis of Biased Loss</h3><p>与 LSTM-CRF 和 LSTM-LSTM 不同的是，LSTM-LSTM-Bias 的方法偏向于通过关系标签来增强实体之间的联系。如图 4 是预测单个实体的比例可视化。<u>单个实体是指那些找不到相应实体的实体。</u>作者使用偏置目标函数的方法在单个实体上的比例相对较低。这意味着比起 LSTM-CRF 和 LSTM-LSTM 对关系标签关注不多，LSTM-LSTM-Bias 可以<strong>有效地将两个实体关联起来</strong>。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816103719024.png" srcset="/img/loading.gif" lazyload alt="image-20210816103719024" style="zoom:67%"></p><p>此外，作者也将偏差参数 α 从1改变到20，预测结果如图5所示。如果 $α$ 太大，会影响预测的准确率，如果 $\alpha$ 太小，召回率会下降。当 $α= 10$ 时，LSTM-LSTM Bias 可以平衡准确率和召回率，并且可以达到最好的 F1 分数。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816103831764.png" srcset="/img/loading.gif" lazyload alt="image-20210816103831764" style="zoom:67%"></p><h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><p>作者选取了几个有代表性的例子来说明这些方法的优缺点，如表3所示。每个例子包含三行，第一行是黄金标准，第二行和第三行分别是模型 LSTM-LSTM 和 LSTM-LSTM-Bias 的抽取结果。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210816103917080.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>S1 是一个两个相关实体之间的距离彼此很远的栗子，这使得更难以发现他们的关系。</p><p>S2 是一个负面的例子，表明这些方法可能错误地预测了某个实体。</p><p>S3 是模型可以预测实体头部偏移量的情况，但是关系角色是错误的。这说明 LSTM-LSTM-Bias 能够更好地预测实体对，但是在区分两个实体之间的关系方面还有待改进。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本文的主要贡献是：</p><ol><li><strong>提出了一种新的标注方案，联合抽取实体和关系，可以很容易地将抽取问题转化为标注任务。</strong></li><li><strong>基于新的标注方案，研究了不同类型的端到端模型来解决问题。基于标记的方法比大多数现有的流水线和联合学习方法要好。</strong></li><li>此外，还开发了<strong>具有偏置损失函数的端到端模型，以适应新的标注，它可以增强相关实体之间的关联</strong>。</li></ol><p>在未来的工作中，作者<u>将用多个分类器来替换输出层中的softmax函数</u>，这样一个词可以有多个标签。这样，一个单词可以出现在多个三元组结果中，可以解决重叠关系的问题。尽管的模型可以增强实体标注的效果，但是两个相应的实体之间的关联仍然需要在接下来的工作中进行细化。</p><div class="note note-primary"><p>作者貌似把重叠三元组都去掉了。因为无法处理重叠的情况，比如：两个三元组标注的标签一样，解码时候就会有歧义。</p></div></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/NLP/">NLP</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/NLP/">NLP</a> <a class="hover-with-bg" href="/tags/Relation-Extraction/">Relation Extraction</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2021/08/18/TransH%EF%BC%9AKnowledge%20Graph%20Embedding%20by%20Translating%20on%20Hyperplanes/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">TransH：Knowledge Graph Embedding by Translating on Hyperplanes</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/08/13/TransE%EF%BC%9ATranslating%20Embeddings%20for%20Modeling%20Multi-relational%20Data/"><span class="hidden-mobile">TransE：Translating Embeddings for Modeling Multi-relational Data</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>