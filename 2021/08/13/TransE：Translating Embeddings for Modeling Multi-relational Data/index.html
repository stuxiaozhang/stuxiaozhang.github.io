<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="TransE：Translating Embeddings for Modeling Multi-relational Data
本文提出了一种将实体与关系嵌入到低维向量空间中的简单模型 TransE。以前有很多种训练三元组的方法，但是参数过多，以至于模型过于复杂难以理解。本文作者提出了 TransE 模型，工作效果和以前一样，但模型简单易扩展，达到了不错的效果。
Basic Idea
以前"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>TransE：Translating Embeddings for Modeling Multi-relational Data - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="TransE：Translating Embeddings for Modeling Multi-relational Data"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-08-13 16:51" pubdate>2021年8月13日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 3.2k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 25 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">TransE：Translating Embeddings for Modeling Multi-relational Data</h1><p class="note note-info">本文最后更新于：2022年1月22日</p><div class="markdown-body"><h1 id="transetranslating-embeddings-for-modeling-multi-relational-data">TransE：Translating Embeddings for Modeling Multi-relational Data</h1><p><strong>本文提出了一种将实体与关系嵌入到低维向量空间中的简单模型 TransE。</strong>以前有很多种训练三元组的方法，但是参数过多，以至于模型过于复杂难以理解。本文作者提出了 TransE 模型，工作效果和以前一样，但模型简单易扩展，达到了不错的效果。</p><h2 id="basic-idea">Basic Idea</h2><p>以前的 Knowledeg Embedding 模型，参数多，模型复杂，计算成本高。作者认为简单的模型也可以有一样的表现力。</p><p>作者提出了 TransE 模型。一个基于平移的模型，用于学习实体的低维嵌入。在 TransE 中，<strong>关系表示为嵌入空间中的平移</strong>：如果 <span class="math inline">\((h, \ell, t)\)</span> 成立，则尾部实体 <span class="math inline">\(t\)</span> 的嵌入应接近头部实体 <span class="math inline">\(h\)</span> 的嵌入加上依赖于关系的向量 <span class="math inline">\(\ell\)</span>。</p><p>作者提出这个基于平移的模型的动机有两个：</p><ul><li><p>主要的动机，作者认为很多 KBs 的表示方法都含有<strong>层次关系</strong>，类似一个树结构。 树的自然表示可以看作每一个节点的 Embedding 可以用这个节点下面的子树和叶节点表示。那么节点和节点的关系，同样可以表示为实体共同的父节点。</p></li><li><p>次要动机来自于 word embedding 的思想。作者通过学习词嵌入发现，一些实体之间的一对一关系，例如“国家”和“城市”之间的“首都”关系，用模型可以表示为嵌入空间中向量的平移。</p></li></ul><p>这两个动机使作者提出了 TransE 模型。</p><h2 id="translation-based-model">Translation-based model</h2><blockquote><p>给定由两个实体 <span class="math inline">\(h,t \in E\)</span> 和一个关系 <span class="math inline">\(\ell\)</span> 组成的三元组 <span class="math inline">\((h, \ell, t)\)</span>。</p></blockquote><p>TransE 模型认为一个正确的三元组的 embedding 向量 <span class="math inline">\((h, \ell, t)\)</span> 会满足公式：<span class="math inline">\(h+\ell \approx t\)</span></p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210813163920543.png" srcset="/img/loading.gif" lazyload></p><p>头实体 embedding 加上关系 embedding 会约等于尾实体 embedding。如果是一个错误的三元组，那么它们的 embedding 之间就不满足这种关系。即，如果三元组是正确的，则尾实体 embedding 应该与头实体 embedding 和关系 embedding 的加和更为接近；反之，如果三元组是错误的，则尾实体 embedding 应该与头实体 embedding 和关系 embedding 的加和更为远离。可以选择L1或者L2范数来衡量三个向量的差距。因此我们定义如下的势能函数，这里采用<u>L2范数</u>：</p><blockquote><p>势能函数原文里称“衡量三元组能量(energy)的距离函数”</p><p>以后的系列论文都会称为 “得分函数”。</p></blockquote><p><span class="math display">\[ d(h+\ell,t)=f(h,\ell,t)=||h+\ell-t||_2 \]</span></p><p>对于一个正确的三元组，我们希望距离(势能)越近越好，而对于一个错误的三元组，我们希望距离(势能)越远越好。基于此，TransE 模型的目标函数设计为： <span class="math display">\[ \mathcal{L}=\sum_{(h, \ell, t) \in S} \sum_{\left(h^{\prime}, \ell, t^{\prime}\right) \in S_{(h, \ell, t)}^{\prime}}\left[\gamma+f(h,\ell,t)-f(h&#39;,\ell&#39;,t&#39;)\right]_{+} \]</span> 其中：</p><ul><li><p>目标函数的目标是让正例的距离最小，也就是 <span class="math inline">\(min(d(h+\ell, t))\)</span>，让负例的相反数最小也就是 <span class="math inline">\((min(−d(h′+ \ell′,t ′)))\)</span>，对于每一个正样本和负样本求和，再增加一个常数的间距，就是整体距离的最小值。也就是我们的目标函数。</p></li><li><p><span class="math inline">\([f(x)]_+\)</span> 表示为 <span class="math inline">\(max(0,f(x))\)</span>，即 f(x) 大于0为 <span class="math inline">\(f(x)+=f(x)\)</span>，小于0则为 <span class="math inline">\(f(x)+=0\)</span>。这叫做合页损失函数(hinge loss function)。</p><blockquote><p>这个地方我把 <span class="math inline">\([x]_+\)</span> 理解为 <span class="math inline">\([f(x)]_+\)</span> ，这样我就理解了为什么是两个求和符号。</p></blockquote></li><li><p>为了方便训练，避免过拟合，通常还会在上述目标函数后面增加约束条件 <span class="math inline">\(||h||\le1,||r||\le1,||t||\le1\)</span>。</p></li></ul><p>这种训练方法叫做 <strong>margin-based ranking criterion</strong>。它来自于 SVM。支持向量机也是如此，要将正和负尽可能分开，找出最大距离的支持向量。同理，TransE 也是如此，尽可能将对的和错的分开。<span class="math inline">\(\gamma\)</span> 表示的是三元组正样本和负样本的间隔 margin，margin 越大，则两个 triple 之前被修正的间隔就越大，则对于词向量的修正就越严格。<span class="math inline">\(\gamma\)</span> 为超参数。</p><h3 id="负样本错误三元组的产生">负样本（错误三元组）的产生</h3><p><span class="math display">\[ S_{(h, \ell, t)}^{\prime}=\left\{\left(h^{\prime}, \ell, t\right) \mid h^{\prime} \in E\right\} \cup\left\{\left(h, \ell, t^{\prime}\right) \mid t^{\prime} \in E\right\} . \]</span></p><p>上式构造错误的三元组，头部或尾部被随机实体代替（不能同时替换，但肯定有一个是属于训练项中的实体）。</p><p>为了避免出现生成的负例其实存在于知识库中的情况，我们可以对生成的负例进行过滤，如果它是知识库中的正例，那我们就不把它作为负例，而是重新生成一个负例。</p><h3 id="algorithm">Algorithm</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210819112248295.png" srcset="/img/loading.gif" lazyload></p><p>算法1中描述了详细的过程：</p><ol start="0" type="1"><li><p>输入训练集三元组 <span class="math inline">\(S={(h, \ell, t)}\)</span>，实体集 <span class="math inline">\(E\)</span>，关系集 <span class="math inline">\(L\)</span>，嵌入维度 <span class="math inline">\(k\)</span>，超参数：margin <span class="math inline">\(\gamma\)</span>，学习率 <span class="math inline">\(\lambda\)</span></p></li><li><p>初始化：随机初始化头实体、尾实体和关系向量 <span class="math inline">\(\boldsymbol{\ell} , \boldsymbol{e}\)</span> ，并对通过 <em>Xavier</em> 初始化的向量做归一化处理</p></li><li><p>循环：采用 minibatch，一批一批的训练会加快训练速度</p><ol start="0" type="1"><li>每一次循环迭代后要对 <span class="math inline">\(e\)</span> 的 embedding 标准化</li><li>取一个b大小的 <span class="math inline">\(S_{batch}\)</span> ，<span class="math inline">\(T_{batch}\)</span> 初始化为空列表</li><li>对于每批数据 <span class="math inline">\(S_{batch}\)</span><ol type="1"><li>进行负采样（将训练集中的三元组头实体 or 尾实体随机替换掉）</li><li><span class="math inline">\(T_{batch}\)</span> 初始为一个空列表，然后向其添加由元组对（原三元组，错误三元组）组成的列表 <span class="math inline">\(T_{batch} = [ ( [h,r,t], [h&#39;,r,t&#39;] ), ([ ], [ ]), ......]\)</span></li></ol></li><li>利用 SGD 优化目标函数，进行 embedding 参数的更新</li></ol></li></ol><h2 id="experiments">Experiments</h2><p>TransE 是根据从 Wordnet 和 Freebase 中提取的数据进行评估的，与文献中的几种最新方法相比，这些方法在各种基准上实现了最佳的当前性能，并可扩展到相对较大的数据集。</p><h3 id="evaluation-protocol">Evaluation protocol</h3><p>我们得到每个实体和关系的 embedding 之后，如何评估这些学得的 embedding 的质量呢？这里用了一个评估方法/协议—Link prediction。这个方法不仅可以用于评估 TransE ，很多模型也用了这个评估方法。</p><p>假设整个知识库中一共有 n 个实体，那么基本的评估过程如下：</p><ul><li>将一个正确的三元组 a 中的<u>头实体或者尾实体</u>，依次替换为整个知识库中的所有其它实体，也就是会产生 n 个三元组。</li><li>分别对上述 n 个三元组计算其能量值，在 TransE 中，就是计算 <span class="math inline">\(h+\ell-t\)</span> 的值。这样可以得到 n 个能量值，分别对应上述 n 个三元组。</li><li>对上述 n 个能量值进行升序排序。记录三元组 a 的能量值排序后的序号。</li><li>对所有的正确的三元组重复上述过程。</li></ul><p>上述就是评估的过程，共有两个指标：<strong>Mean Rank 和 Hits@10</strong>。每个正确三元组的能量值排序后的序号求平均，得到的值称为 Mean Rank，Mean Rank 越小越好。计算正确三元组的能量排序后的序号小于10的比例，得到的值称为 Hits@10，Hits@10 越大越好。</p><p>但是上述过程存在一个不合理的地方：<u>在将一个正确的三元组a的头或者尾实体替换成其它实体之后得到的这个三元组也有可能是正确的</u>，在计算每个三元组的能量并排序之后，这类正确的三元组的能量有可能排在三元组a的前面。但是上面的基本评估过程并没有考虑这点。因此<strong>把正确的三元组从训练集、验证集、测试集中都删除掉</strong>，从而保证生成的三元组一定是错误的三元组。</p><p>把上述基本评价过程得到的结果称为 <strong>Raw Mean Rank 和 Raw Hits@10</strong>，把过滤掉正确后得到的结果称为 <strong>Filtered Mean Rank 和 Filtered Hits@10</strong>。</p><h3 id="link-prediction">Link prediction</h3><p>实验中使用的 baseline 有：RESCAL、SE、SME（linear）、SME（bilinear）和LFM。RESCAL 通过交替最小二乘法进行训练，而其他方法则通过随机梯度下降法进行训练。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210814141511752.png" srcset="/img/loading.gif" lazyload></p><ul><li><p>从链路预测结果中可以看到，TransE 在所有指标上都优于所有对手，而且有很大的差距。</p></li><li><p>有些指标在 Raw 和 Filtered 上表现有些差距，说明过滤掉正确三元组是有必要的。</p></li></ul><p>作者又将链路预测结果进行了关系的分类：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210814153225701.png" srcset="/img/loading.gif" lazyload></p><p>表4 通过关系的类型对结果进行了分类，发现： TransE <strong>在处理复杂关系上效果欠佳</strong>（复杂关系通常是指一对多、多对一，多对多三种关系模型）。</p><blockquote><p>给定两个事实（诺兰，导演，信条），（诺兰，导演，盗梦空间），那么网络的目的便是优化嵌入表达使得：诺兰+导演≈信条，诺兰+导演≈盗梦空间，这样一来会使得信条≈盗梦空间，但这两部电影是不同的实体，应该用不同的向量表示。</p></blockquote><h4 id="example-predictions">Example predictions</h4><p>作者展示了几个链路预测结果的例子。给定头实体和关系，预测尾实体。粗体是真实的尾实体，斜体表示训练集中存在的其他真实尾部。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210814175543833.png" srcset="/img/loading.gif" lazyload></p><p>即使好的答案并不总是排名靠前，这些预测也说明了TransE能够表示一些常识。</p><h4 id="learning-to-predict-new-relationships-with-few-examples">Learning to predict new relationships with few examples</h4><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210814142644045.png" srcset="/img/loading.gif" lazyload></p><p>作者通过检查这些模型学习新关系的速度，来测试这些模型否能够很好地概括新事实。作者使用 <em>FB15k</em> 数据集，将数据集分为 <em>FB15k-40rel</em> 和 <em>Fb15k-rest</em> ，将 <em>FB15k-40rel</em> 分为 训练集(每种关系1000个样本)和测试集，将 <em>Fb15k-rest</em> 分为训练集和验证集。</p><ol type="1"><li>先在 <em>Fb15k-rest</em> 上进行通过训练集和验证集进行模型的训练和选择。</li><li>然后通过 <em>Fb15k-40rel</em> 进行训练让模型，只学习新的40种关系的相关参数。</li><li>最后，在 <em>FB15k-40rel</em> 的测试集进行链路预测评估，评估仅包含在 第1步 中没有发现的关系。</li></ol><p>结果如上图所示，从图中的 Filtered Mean Rank（越小越好） 和 Filtered Hits@10（越大越好）指标可以看到，在没有提供未知关系的样本的情况下，非结构化的性能最好，因为它不使用这些信息进行预测。但是，在提供标记关系的样本时，这种性能并没有提高。而 TransE 是学习最快的模型，只需要新关系的10个例子hits@10 就已经是18%，展现了优秀的性能。</p><h2 id="code">Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TransE</span>(<span class="hljs-params">PairwiseModel</span>):</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, **kwargs</span>):</span><br>        <span class="hljs-built_in">super</span>(TransE, self).__init__(self.__class__.__name__.lower())<br>        param_list = [<span class="hljs-string">&quot;tot_entity&quot;</span>, <span class="hljs-string">&quot;tot_relation&quot;</span>, <span class="hljs-string">&quot;hidden_size&quot;</span>, <span class="hljs-string">&quot;l1_flag&quot;</span>]<br>        param_dict = self.load_params(param_list, kwargs)<br>        self.__dict__.update(param_dict)<br><br>        self.ent_embeddings = NamedEmbedding(<span class="hljs-string">&quot;ent_embedding&quot;</span>, self.tot_entity, self.hidden_size)<br>        self.rel_embeddings = NamedEmbedding(<span class="hljs-string">&quot;rel_embedding&quot;</span>, self.tot_relation, self.hidden_size)<br>        nn.init.xavier_uniform_(self.ent_embeddings.weight)<br>        nn.init.xavier_uniform_(self.rel_embeddings.weight)<br><br>        self.parameter_list = [<br>            self.ent_embeddings,<br>            self.rel_embeddings,<br>        ]<br><br>        self.loss = Criterion.pairwise_hinge<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, h, r, t</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;Function to get the embedding value.</span><br><span class="hljs-string"></span><br><span class="hljs-string">           Args:</span><br><span class="hljs-string">               h (Tensor): Head entities ids.</span><br><span class="hljs-string">               r (Tensor): Relation ids.</span><br><span class="hljs-string">               t (Tensor): Tail entity ids.</span><br><span class="hljs-string"></span><br><span class="hljs-string">           Returns:</span><br><span class="hljs-string">               Tensors: the scores of evaluationReturns head, relation and tail embedding Tensors.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        h_e, r_e, t_e = self.embed(h, r, t)<br><br>        norm_h_e = F.normalize(h_e, p=<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br>        norm_r_e = F.normalize(r_e, p=<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br>        norm_t_e = F.normalize(t_e, p=<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">if</span> self.l1_flag:<br>            <span class="hljs-keyword">return</span> torch.norm(norm_h_e + norm_r_e - norm_t_e, p=<span class="hljs-number">1</span>, dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">return</span> torch.norm(norm_h_e + norm_r_e - norm_t_e, p=<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">embed</span>(<span class="hljs-params">self, h, r, t</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;Function to get the embedding value.</span><br><span class="hljs-string"></span><br><span class="hljs-string">           Args:</span><br><span class="hljs-string">               h (Tensor): Head entities ids.</span><br><span class="hljs-string">               r (Tensor): Relation ids.</span><br><span class="hljs-string">               t (Tensor): Tail entity ids.</span><br><span class="hljs-string"></span><br><span class="hljs-string">           Returns:</span><br><span class="hljs-string">               Tensors: Returns a tuple of head, relation and tail embedding Tensors.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        h_e = self.ent_embeddings(h)<br>        r_e = self.rel_embeddings(r)<br>        t_e = self.ent_embeddings(t)<br><br>        <span class="hljs-keyword">return</span> h_e, r_e, t_e<br><br></code></pre></td></tr></table></figure><h2 id="summary">Summary</h2><p>TransE 简单有效，已经成为知识表示学习的代表模型，并衍生出不同的变体：TransH ，TransR ，TransD ，CTransR ，TransA 等等。</p><p>与以往模型相比，TransE 模型参数较少， 计算复杂度低， 却能直接建立实体和关系之间的复杂语义联系。Bordes 等人在 WordNet 和 Freebase 等数据集上进行链接预测等评测任务， 实验表明 TransE 的性能较以往模型有显著提升。虽然 TransE 算法对知识图谱的表示学习提供了很好的研究思路，但是缺点也很多，比如它只能很好的解决知识图谱中1对1的关系表示，而对于1对多，多对1和多对多的关系类型就无法很好的进行表示。（还有其他的缺点我就不是很了解了...）</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/Papers/">Papers</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/KG/">KG</a> <a class="hover-with-bg" href="/tags/TransE/">TransE</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2021/08/15/Joint%20Extraction%20of%20Entities%20and%20Relations%20Based%20on%20a%20Novel%20Tagging%20Scheme/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/08/07/Transformer%EF%BC%9AAttention%20Is%20All%20You%20Need/"><span class="hidden-mobile">Transformer：Attention Is All You Need</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>