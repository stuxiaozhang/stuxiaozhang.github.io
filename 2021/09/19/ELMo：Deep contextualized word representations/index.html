<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="ELMo：Deep contextualized word representations
ELMo 模型出自《Deep contextualized word representations》，是 NAACL 2018 best paper。
ELMo 是一种基于语境的深度词表示模型（Word Representation Model），它可以捕获单词的复杂特征（词性句法），也可以解决同一个"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>ELMo：Deep contextualized word representations - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="ELMo：Deep contextualized word representations"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-09-19 09:24" pubdate>2021年9月19日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 3.3k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 25 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">ELMo：Deep contextualized word representations</h1><p class="note note-info">本文最后更新于：2021年9月23日</p><div class="markdown-body"><h1 id="elmodeep-contextualized-word-representations">ELMo：Deep contextualized word representations</h1><p>ELMo 模型出自《Deep contextualized word representations》，是 NAACL 2018 best paper。</p><p>ELMo 是一种基于语境的深度词表示模型（Word Representation Model），它可以捕获单词的复杂特征（词性句法），也可以解决同一个单词在不同语境下的不同表示（语义）。</p><p>ELMo 采用了典型的两阶段过程，<strong>第一个阶段是利用语言模型进行预训练；第二个阶段是在做下游任务时，从预训练网络中提取对应单词的网络各层的Word Embedding作为新特征补充到下游任务中。</strong></p><h2 id="background">Background</h2><p>以 Word2Vec 和 GloVe 为代表的词表示模型通过训练为每个单词训练出固定大小的词向量，这在以往的 NLP 任务中都取得了不错的效果，但是他们都存在两个问题：</p><ol type="1"><li>没法处理复杂的单词用法，即语法问题；</li><li>没办法结合语境给出正确词向量，即一词多义；</li></ol><p>为了解决这2个问题，作者提出了一个新的深层语境词表示模型——ELMo。</p><p>区别于传统模型生成的固定单词映射表的形式（为每个单词生成一个固定的词向量），ELMo 使用了预训练的语言模型（Language Model），模型会扫面句子结构，并更新内部状态，从而为句子中的每个单词都生成一个<strong>基于当前的句子</strong>的词向量（Embedding）。这也是就是 ELMo 取名的由来：Embeddings from Language Models。</p><p>此外，ELMo <strong>采用字符级的多层 BI-LM 模型</strong>作为语言模型，高层的网络能够捕获基于语境的词特征（例如主题情感），而底层的 LSTM 可以学到语法层次的信息（例如词性句法），前者可以处理一词多义，后者可以被用作词性标注，作者通过线性组合多层 LSTM 的内部状态来丰富单词的表示。</p><h2 id="elmo">ELMo</h2><p>这是 ELMo 整体架构。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919184321765.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><h3 id="char-encode-layer">Char Encode Layer</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919184310425.png" srcset="/img/loading.gif" lazyload></p><ol type="1"><li>Char Embedding：这就是正常的 embedding 层，针对每个char进行编码</li><li>Multi-Scale 卷积层：这里用的是不同 scale 的卷积层，注意是在宽度上扩展，而不是深度上，即输入都是一样的，卷积之间的不同在于其<code>kernel_size</code>和<code>channel_size</code>的大小不同，用于捕捉不同 n-grams 之间的信息，这点其实是仿照 <em>TextCNN</em> 的模型结构。</li><li>Concat 层：上一步得出的是m个不同维度的矩阵，为了方便后期处理，这里将其在最后一维上进行拼接，而后将其 reshape 回单词级别的维度</li><li>Highway 层：Highway（参见：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.00387">Highway Network</a> ）是仿照图像中 <strong>residual</strong> 的做法，在 NLP 领域中常有应用，这一层实现的公式其实就是一种<strong>全连接+残差</strong>的实现方式，只不过这里还需要一个 element-wise 的 gate 矩阵对 x 和 f(A(x)) 进行变换。</li><li>Linear 映射层：经过前面的计算，得到的向量维度 <span class="math inline">\(d1+d2+...+dm\)</span> 往往比较长，这里额外加了一层的Linear进行映射，将维度映射到D，作为词的embedding送入后续的层中，这里输出的维度为 <span class="math inline">\(B * W * D\)</span>。</li></ol><h3 id="bi-lm">Bi-LM</h3><p>ELMo 是一种称为 Bi-LM 的特殊类型的语言模型，它是两个方向上的 LM 的组合，如下图所示：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919135130780.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p>ELMo 利用<strong>正向</strong>和<strong>反向</strong>扫描句子计算单词的词向量，并通过级联的方式产生一个中间向量。通过这种方式得到的词向量它可以了解到当前句子的结构(语义)和该单词的使用方式。</p><p>设一个序列有 N 个 token <span class="math inline">\((t_1, t_2,...,t_N)\)</span>（这里说 token 是为了兼容字符和单词，EMLo 使用的是字符级别的 Embedding）</p><p>对于一个前向语言模型来说，是基于先前的序列来预测当前 token： <span class="math display">\[ p\left(t_{1}, t_{2}, \ldots, t_{N}\right)=\prod_{k=1}^{N} p\left(t_{k} \mid t_{1}, t_{2}, \ldots, t_{k-1}\right) \]</span> 而对于一个后向语言模型来说，是基于后面的序列来预测当前 token： <span class="math display">\[ p\left(t_{1}, t_{2}, \ldots, t_{N}\right)=\prod_{k=1}^{N} p\left(t_{k} \mid t_{k+1}, t_{k+2}, \ldots, t_{N}\right) \]</span> 可以用 <span class="math inline">\(\overrightarrow{h_{k, j}}\)</span> 和 <span class="math inline">\(\overleftarrow{h_{k, j}}\)</span> 分别表示前向和后向语言模型。</p><p>损失函数：ELMo 用的是多层双向的 LSTM，所以我们联合前向模型和后向模型给出对数似然估计： <span class="math display">\[ \begin{array}{l} \sum_{k=1}^{N}\left(\log p\left(t_{k} \mid t_{1}, \ldots, t_{k-1} ; \Theta_{x}, \vec{\Theta}_{L S T M}, \Theta_{s}\right)\right. \\ \left.\quad+\log p\left(t_{k} \mid t_{k+1}, \ldots, t_{N} ; \Theta_{x}, \overleftarrow{\Theta}_{L S T M}, \Theta_{s}\right)\right) \end{array} \]</span> 其中，<span class="math inline">\(\Theta_{x}\)</span> 表示 token 的向量，<span class="math inline">\(\Theta_{s}\)</span> 表示 Softmax 层分类的参数， <span class="math inline">\(\overleftarrow{\Theta}_{L S T M}\)</span> 和 <span class="math inline">\(\overrightarrow{\Theta}_{L S T M}\)</span> 表示前向和后向的 LSTM 的参数。</p><h3 id="生成-elmo-词向量">生成 ELMo 词向量</h3><p>上文提到：ELMo 通过<strong>级联</strong>的方式给出<strong>中间向量</strong></p><p>对每一个 token <span class="math inline">\(t_k\)</span> 来说，一个 L 层的 ELMo 的 2L + 1 个表征： <span class="math display">\[ \begin{aligned} R_{k} &amp;=\left\{\mathbf{x}_{k}^{L M}, \overrightarrow{\mathbf{h}}_{k, j}^{L M}, \overleftarrow{\mathbf{h}}_{k, j}^{L M} \mid j=1, \ldots, L\right\} \\ &amp;=\left\{\mathbf{h}_{k, j}^{L M} \mid j=0, \ldots, L\right\} \end{aligned} \]</span> 其中，<span class="math inline">\(\mathbf{h}_{k, 0}^{L M}\)</span> 表示输入层，<span class="math inline">\(\mathbf{h}_{k, j}^{L M}=[\overrightarrow{\mathbf{h}}_{k, j}^{L M}, \overleftarrow{\mathbf{h}}_{k, j}^{L M}]\)</span> 表示每一层的正向和反向输出拼接后的结果。（之所以是 2L + 1 是因为把输入层加了进来）</p><p>对于下游任务来说，ELMo 会将所有的表征加权合并为一个<strong>中间向量</strong>： <span class="math display">\[ \mathbf{E L M o}_{k}=E\left(R_{k} ; \boldsymbol{\Theta}_{e}\right) \]</span> 最简单的情况下，ELMo 只选择顶层，<span class="math inline">\(E\left(R_{k}\right)=\mathbf{h}_{k, L}^{L M}\)</span> ，所有 biLM 层的任务特定权重： <span class="math display">\[ \mathbf{E L M o}_{k}^{\text {task }}=E\left(R_{k} ; \Theta^{\text {task }}\right)=\gamma^{\text {task }} \sum_{j=0}^{L} s_{j}^{t a s k} \mathbf{h}_{k, j}^{L M} \]</span> 其中，<span class="math inline">\(s\)</span> 是 Softmax 的结果，用作权重；<span class="math inline">\(\gamma\)</span> 是常量参数，允许模型缩放整个 ELMo 向量，这两部分都是作为参数来学习的，针对不同任务会有不同的值。</p><p>同时论文里面还提到，每一层输出的分布之间可能会有较大差别，所以有时也会在线性融合之前，为每层的输出做一个 Layer Normalization，这与 Transformer 里面一致。</p><p>经过 Scalar Mixer之后的向量维度为 <span class="math inline">\(B * W * 2\)</span>，即为生成的 ELMo 词向量，可以用于后续的任务。</p><p>整个为下游任务获取embedding的过程即为：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919170249970.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><div class="note note-info"><p>注意是，ELMo 使用的 <strong>Bi-LM 与 Bi-LSTM 不同</strong>，虽然长得相似，但是 Bi-LM 是两个 LM 模型的串联，一个向前，一个向后。而 Bi-LSTM 不仅仅是两个 LSTM 串联，<strong>Bi-LSTM 模型中来自两个方向的内部状态在被送到下层时进行级联（注意下图的 out 部分，在 out 中进行级联），而在 Bi-LM 中，两个方向的内部状态仅从两个独立训练的 LM 中进行级联。</strong></p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919162000789.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p></div><h3 id="supervised-nlp-task结合下游nlp任务">Supervised NLP task（结合下游NLP任务）</h3><p>一般 ELMo 模型会在一个超大的语料库上进行预训练，因为是训练语言模型，不需要任何的标签，纯文本就可以，因而这里可以用超大的语料库，这一点的优势是十分明显的。训练完 ELMo 模型之后，就可以输入一个新句子，得到其中每个单词在当前这个句子上下文下的 ELMo 词向量了。</p><p>论文中提到，在训练的时候，发现使用合适的 dropout 和 L2 在 ELMo 模型上时会提升效果。</p><p>此时这个词向量就可以接入到下游的NLP任务中，比如问答、情感分析等。从接入的位置来看，可以与下游NLP任务本身输入的embedding拼接在一起，也可以与其输出拼接在一起。而从模型是否固定来看，又可以将ELMo词向量预先全部提取出来，即固定ELMo模型不让其训练，也可以在训练下游NLP任务时顺带fine-tune这个ELMo模型。总之，使用起来非常的方便，可以插入到任何想插入的地方进行增补。</p><h3 id="elmo-的优点是什么">ELMo 的优点是什么？</h3><p>ELMo利用了深度上下文单词表征，该模型的优点：</p><ul><li>引入双向语言模型，其实是 2 个单向语言模型（前向和后向）的集成；</li><li>通过保存预训练好的 2 层 biLSTM，通过特征集成或 finetune 应用于下游任务；</li></ul><p>总结来说，通过上述结构，ELMo 能够达到区分多义词的效果，每个单词(token)不再是只有一个上下文无关的 embedding 表示。</p><h3 id="elmo-为什么有效">ELMo 为什么有效？</h3><ul><li>首先，ELMo 的假设前提是<strong>一个词的词向量不应该是固定的</strong>，所以在多义词区分方面 ELMo 的效果必然比 word2vec 要好。</li><li>另外，ELMo 通过语言模型生成的词向量是通过特定上下文的“传递”而来，再根据下游任务，对原本上下文无关的词向量以及上下文相关的词向量表示引入一个权重，这样既在原来的词向量中引入了上下文的信息，又能根据下游任务适时调整各部分的权重(权重是在网络中学习得来的)，因此这也是 ELMo 有效的一个原因。</li></ul><h3 id="elmo为什么能够达到区分多义词的效果">ELMo为什么能够达到区分多义词的效果？</h3><p>在ELMo第一阶段训练完成之后，将句子输入模型中在线提取各层embedding的时候，每个单词(token)对应两边LSTM网络的对应节点，那两个节点得到的embedding是动态改变的，会受到上下文单词的影响，周围单词的上下文不同应该会强化某种语义，弱化其它语义，这样就达到区分多义词的效果了。需要注意的是，第一个单词和最后一个单词也是有上下文的，譬如说第一个单词的上文是一个特殊的 token <code>&lt;BOS&gt;</code>，下文是除第一个单词外的所有单词，最后一个单词的下文是一个特殊的token <code>&lt;EOS&gt;</code>，上文是除最后一个单词外的所有单词。</p><p>论文中也举例说明了这个问题，图示如下：</p><figure><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210920084513229.png" srcset="/img/loading.gif" lazyload alt="image-20210920084513229"><figcaption>image-20210920084513229</figcaption></figure><p>上图对于Glove训练出的word embedding来说，多义词比如play，根据它的embedding找出的最接近的其它单词大多数集中在体育领域，这很明显是因为训练数据中包含play的句子中体育领域的数量明显占优导致；而使用ELMo，根据上下文动态调整后的embedding不仅能够找出对应的“演出”的相同语义的句子，而且还可以保证找出的句子中的play对应的词性也是相同的，这是超出期待之处(当然也可能是因为论文中给出的例子都是比较好的例子，不过ELMo这样的做法是值得学习的)。</p><h3 id="elmo-把三种不同的向量叠加的意义是什么这样做能达到什么样的效果">ELMo 把三种不同的向量叠加的意义是什么？这样做能达到什么样的效果？</h3><p>因为通过ELMo模型，句子中每个单词都能得到对应的三个Embedding：最底层是单词的Word Embedding，往上走是第一层双向LSTM中对应单词位置的Embedding，这层编码单词的<strong>句法信息</strong>更多一些；再往上走是第二层LSTM中对应单词位置的Embedding，这层编码单词的<strong>语义信息</strong>更多一些。</p><p>需要注意的是，这里得到的结论是通过实验验证的，是在这样的模型设计中，能够得到上述结论，可能不同模型结构，得到的结论又是不一样的。</p><p>ELMo把三种不同的向量叠加的意义主要体现在以下两个点：</p><ul><li>一是之前很多方法都只用了最顶层LSTM的hidden state，但是通过实验验证，在很多任务中，将每一层hidden state融合在一起会取得更好的效果；</li><li>二是在上述实验中得到结论，每一层LSTM得到单词的embedding所蕴含的信息是不一样的，因此将所有信息融合起来，会让单词embedding的表达更丰富。</li></ul><p>这样做能够起到区分多义词的效果，如上个问题，而且在论文展示的6个任务中都取得了 SOTA 的效果。</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210919192856819.png" srcset="/img/loading.gif" lazyload></p><p>疑问</p><ol type="1"><li><p>为什么要用 LSTM 而不用类似 Transformer 的结构？毕竟 Transformer 在发表于 2017 年，早于 ELMo；</p></li><li><p>其次，ELMo 采用的并不是真正的双向 LSTM，而是两个独立的 LSTM 分别训练，并且只是在 Loss Function 中通过简单相加进行约束，只能一定程度上学习到单词两边句子的特征。</p></li></ol></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/NLP/">NLP</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/NLP/">NLP</a> <a class="hover-with-bg" href="/tags/ELMo/">ELMo</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2021/09/23/BERT%EF%BC%9APre-training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">【BERT】Pre-training of Deep Bidirectional Transformers for Language Understanding</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/09/17/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%20GAN/"><span class="hidden-mobile">生成对抗网络 GAN</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>