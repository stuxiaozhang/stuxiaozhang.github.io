<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><link rel="icon" href="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="TranSparse：Knowledge graph completion with adaptive sparse transfer matrix
TranSparse 是自动化所赵军、刘康老师团队发表在 AAAI 2016 上的工作， 和 TransD 的作者是一个人。主要思想是：引入稀疏因子解决知识库的异质性和不平衡性问题。
Motivation
通过先前的模型，我们基本掌握了知识表示"><meta name="author" content="小张同学"><meta name="keywords" content=""><title>TranSparse：Knowledge graph completion with adaptive sparse transfer matrix - 小张同学的博客</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"stuxiaozhang.github.io",root:"/",version:"1.8.11",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:4},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",app_key:"CgnvRL262D07ied40NiXm2VL",server_url:null}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body><header style="height:50vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>xiaozhang's space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/schedule/"><i class="iconfont icon-cliplist"></i> 动态</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(https://gitee.com/stuxiaozhang/blogimage/raw/master/img/mytheme/post.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="TranSparse：Knowledge graph completion with adaptive sparse transfer matrix"></span><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> 小张同学 </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2021-09-12 14:29" pubdate>2021年9月12日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.8k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 21 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-1"></div><div class="col-lg-9 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">TranSparse：Knowledge graph completion with adaptive sparse transfer matrix</h1><p class="note note-info">本文最后更新于：2021年9月12日</p><div class="markdown-body"><h1 id="transparseknowledge-graph-completion-with-adaptive-sparse-transfer-matrix">TranSparse：Knowledge graph completion with adaptive sparse transfer matrix</h1><p>TranSparse 是自动化所赵军、刘康老师团队发表在 AAAI 2016 上的工作， 和 TransD 的作者是一个人。主要思想是：引入稀疏因子解决知识库的异质性和不平衡性问题。</p><h2 id="motivation">Motivation</h2><p>通过先前的模型，我们基本掌握了知识表示的学习方法：首先通过投影策略将实体和关系映射到对应的语义空间，其次均使用得分函数 <span class="math inline">\(f(h,t)=||h+r-t||\)</span> 表示实体对的评分。另外使用负采样生成错误样本进行训练，使得正确的样本得分函数值降低，错误样本的得分函数值升高。</p><p>然而这些模型均忽略了图谱的两个重要特性：<strong>异质性（heterogeneity）</strong>和 <strong>不平衡性（imbalance）</strong>。图谱中的异质性是指不同关系对应的实体对数量不一致，例如对于关系 <span class="math inline">\(r\)</span> 链接的所有实体对数量可能非常多，而对于 <span class="math inline">\(r ′\)</span> 链接的所有实体对数量可能只有1个。不平衡性是指头尾实体的数量不一致，例如形如对于 <code>(地名，local，洲名)</code> 的三元组，地名可能成千上万个，而洲名只有七个。由于数量的不对等，可知数量较多的对应关系的实体对或头尾实体，它们所包含的信息应该越多，而前面的几种模型忽略了这一点，使得针对每个实体对都用同样的方法训练，势必会导致<strong>数量多的部分出现欠拟合</strong>，<strong>数量少的部分出现过拟合</strong>。因此本文 TranSparse 处理这种问题的策略是引用<strong>稀疏矩阵</strong>。首先对于异质性，提出 TranSparse（Share），稀疏因子取决于关系链接对应的实体对数量，且两个实体对应的关系投影矩阵是相同的。对于不平衡性，提出 TranSparse（Separate），每个关系对应的实体对中，头尾实体使用不同的关系投影矩阵。</p><h2 id="transparse">TranSparse</h2><h3 id="稀疏矩阵">稀疏矩阵</h3><p>稀疏矩阵是指一个矩阵中含有大量的0元素，而 <strong>0元素所占总元素个数的比值为稀疏因子</strong> <span class="math inline">\(\theta\)</span>。稀疏因子 <span class="math inline">\(\theta\)</span> 越大表示这个矩阵越稀疏。用 <span class="math inline">\(M(\theta)\)</span> 表示稀疏因子为 <span class="math inline">\(\theta\)</span> 的矩阵。对于稀疏矩阵有两种结构，如图所示：</p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210912164706797.png" srcset="/img/loading.gif" lazyload style="zoom:50%"></p><p>黑色表示非0元素，白色表示0元素。图（a）表示结构化的稀疏矩阵，可知所有非0元素沿着主对角线排列，因此可知对于 <span class="math inline">\(m\times m\)</span> 的对角矩阵的稀疏因子为 $ (m m - m) / (m m)$。图（b）中表示非结构稀疏矩阵，0元素是随机排布。</p><h3 id="为什么选择稀疏矩阵而不是低秩矩阵">为什么选择稀疏矩阵，而不是低秩矩阵？</h3><p><strong>自由度</strong>是衡量一个矩阵中相互独立的元素个数，而稀疏矩阵和低秩矩阵均可以在一定程度上降低自由度（稀疏矩阵包含大量的0，而低秩矩阵对应的梯形矩阵包含大量的0，0的个数越多，则非0的相互独立的元素个数变少）。对于低秩矩阵，由于许多变量之间存在线性约束条件（可回顾线性方程组和线性相关的概念），因此秩越低，自由度就越低。对于稀疏矩阵，由于含有非0元素数量少，所以在训练过程中让0元素保持不变，因此可变的元素就很少，亦即自由的变量很少。之所以引入自由度的概念，是因为对于一个矩阵，如果自由度越低，即包含有效的信息量就越少，对解决异质性和非平衡性很有效。</p><p>对于低秩矩阵，矩阵的秩的大小不大于该矩阵最小的维度数，而自由度也仅局限于一小范围内。具体地说，如果矩阵 $ M_{mn}$ ，秩 <span class="math inline">\(rank(M)\leq min(m,n)\)</span>，自由度也在 <span class="math inline">\(0-min(m,n)\)</span> 之间，因为矩阵的秩主要用于衡量行向量或列向量的线性最大无关组的数量，因此其可以控制大量的元素，不易于控制。如果使用稀疏矩阵，我们知道非0元素的个数即为自由元素的个数，因此其可以控制唯一的元素，使得自由度范围更大，亦即能够大范围的表示不同复杂度的图。稀疏矩阵中仅有非0元素参与运算，这比低秩矩阵更有效，因此选择稀疏矩阵来控制投影的复杂度。</p><div class="note note-primary"><p>矩阵的秩：手工求矩阵的秩时，为了求矩阵 A 的秩，我们是通过矩阵初等变换把 A 化为阶梯型矩阵，若该阶梯型矩阵有 r 个非零行，那 A 的秩 rank(A) 就等于 r。<strong>从物理意义上讲，矩阵的秩度量的就是矩阵的行列之间的相关性。</strong>如果矩阵的各行或列是线性无关的，矩阵就是满秩的，也就是秩等于行数。</p><p>比如： <span class="math display">\[ \left\{\begin{array}{l} 3 x+5 y+z=15 \\ x-y+z=8 \\ 2 x-2 y+2 z=16 \end{array}\right. \]</span> 因为线性方程组可以用矩阵描述，所以秩就表示了有多少个有用的方程了。上面的方程组有3个方程，实际上只有2个是有用的，一个是多余的，所以对应的矩阵的秩就是2了。</p><p>既然秩可以度量相关性，而矩阵的相关性实际上就表示了矩阵的结构信息。如果矩阵之间各行的相关性很强，那么就表示这个矩阵实际可以投影到更低维的线性子空间，也就是用几个向量就可以完全表达了，它就是低秩的。所以总结的一点就是：如果矩阵表达的是结构性信息，例如图像、用户-商品推荐表等等，那么这个矩阵各行之间存在这一定的相关性，那这个矩阵一般就是低秩的。</p><p><strong>如果X是一个m行n列的数值矩阵，rank(X) 是X的秩，假如 rank (X) 远小于m和n，则称X是低秩矩阵。</strong>低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。</p></div><h3 id="transparseshare">TranSparse（Share）</h3><p>先前的模型中，不论关系对应的实体或实体对数量多少，训练的参数是相同的，因此可能导致数量少的实体或实体对训练过拟合，数量多的实体或实体对训练欠拟合，因此<strong>需要考虑参数与实体对数量的关系。</strong>（针对异质性）</p><p>在 TranSparse（Share）中，设 <span class="math inline">\(N_r\)</span> 表示关系 <span class="math inline">\(r\)</span> 链接的实体对数量，<span class="math inline">\(N_{r^*}\)</span> 表示其中最大值，<span class="math inline">\(r^*\)</span> 表示对应的关系。设 <span class="math inline">\(\theta_{\min }\left(0 \leq \theta_{\min } \leq 1\right)^{3}\)</span> 表示矩阵 <span class="math inline">\(M_{r^*}\)</span> 的稀疏因子，则 <span class="math display">\[ \theta_{r}=1-\left(1-\theta_{\min }\right) N_{r} / N_{r^{*}} \]</span> 公式中，取最大实体对数量为基数，其他实体对数量与之比值作为相对复杂度。该公式可计算对应关系投影矩阵的稀疏因子。</p><p>其次可将头尾实体通过同一个投影矩阵分别映射到关系空间中： <span class="math display">\[ \mathbf{h}_{p}=\mathbf{M}_{r}\left(\theta_{r}\right) \mathbf{h}, \quad \mathbf{t}_{p}=\mathbf{M}_{r}\left(\theta_{r}\right) \mathbf{t} \]</span></p><h3 id="transparseseparate">TranSparse（Separate）</h3><p>TranSparse（Separate）与 Share 不同，头尾实体使用不同的投影矩阵，分别映射到不同的关系空间中。（针对不平衡性）<span class="math inline">\(\mathbf{M}_{r}^{h}\left(\theta_{r}^{h}\right)\)</span> 表示“头实体-关系”映射矩阵 ，<span class="math inline">\(\mathbf{M}_{r}^{t}\left(\theta_{r}^{t}\right)\)</span> 表示“尾实体-关系”映射矩阵。对于关系 <span class="math inline">\(r\)</span> ，最大数量头尾实体 <span class="math inline">\(h^*\)</span> 和 <span class="math inline">\(t^*\)</span> 分别对应的数量 <span class="math inline">\(N_{r^{*}}^{h^{*}}\)</span>，<span class="math inline">\(N_{r^{*}}^{t^{*}}\)</span>。因此“头实体-关系”映射矩阵的稀疏因子为 <span class="math display">\[ \theta_{r}^{h}=1-\left(1-\theta_{\min }\right) N_{r}^{h} / N_{r^{*}}^{h^{*}} \\ \theta_{r}^{t}=1-\left(1-\theta_{\min }\right) N_{r}^{t} / N_{r^{*}}^{t^{*}} \]</span> 因此头尾实体分别映射到关系空间中： <span class="math display">\[ \mathbf{h}_{p}=\mathbf{M}_{r}^{h}\left(\theta_{r}^{h}\right) \mathbf{h}, \quad \mathbf{t}_{p}=\mathbf{M}_{r}^{t}\left(\theta_{r}^{t}\right) \mathbf{t} \]</span></p><p>TranSparse（Share） 和 TranSparse（Separate）两者的得分函数为： <span class="math display">\[ f_{r}(\mathbf{h}, \mathbf{t})=\left\|\mathbf{h}_{p}+\mathbf{r}-\mathbf{t}_{p}\right\|_{\ell_{1 / 2}}^{2} \]</span></p><h3 id="损失函数">损失函数</h3><p>由于图谱中都为真实的三元组，因此需要进行负采样。这一部分与 TransH 相同。损失函数为： <span class="math display">\[ L=\sum_{(h, r, t) \in \Delta} \sum_{\left(h^{\prime}, r, t^{\prime}\right) \in \Delta^{\prime}}\left[\gamma+f_{r}(\mathbf{h}, \mathbf{t})-f_{r}\left(\mathbf{h}^{\prime}, \mathbf{t}^{\prime}\right)\right]_{+} \]</span></p><h3 id="algorithm">Algorithm</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210912185154063.png" srcset="/img/loading.gif" lazyload></p><h2 id="experiments">Experiments</h2><h3 id="triplet-classification">Triplet Classification</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210912191950720.png" srcset="/img/loading.gif" lazyload style="zoom:67%"></p><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210912194325002.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><ol type="1"><li>在表3中，TranSparse（share）比Trans（E，H，R）获得更好的性能，并且接近 TransD，这表明异质性在我们的任务中很重要。在图3中可以看到 TranSparse 可以更好地处理数据的异质性。TranSparse 改进了 TransR 在简单和复杂关系上的性能，TranSparse 比 TransR 具有更少的简单关系参数和更多的复杂关系参数。</li><li>TranSparse（Separate）比 TranSparse（share）获得更好的性能，这说明不平衡也是一个关键问题，作者的方法可以减少其负面影响；</li><li>非结构化模式通常比结构化模式稍好一些。可能是非结构化模式更接近最佳稀疏模式。</li></ol><h3 id="link-prediction">Link Prediction</h3><p><img src="https://gitee.com/stuxiaozhang/blogimage/raw/master/img/机器学习/image-20210912195347399.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><ol type="1"><li><p>TranSparse（share）优于Trans（E，H，R），接近TransD，这表明作者的方法很好地处理了数据的异质性。</p></li><li><p>在大多数情况下，TranSparse（Separate）比 TranSparse（share）获得更好的性能。在表5中，对于典型的不平衡关系（1-to-N、N-to-1和N-to-N），TranSparse（Separate）在大多数预测精度上都优于 TranSparse（share）。</p><p>因此，我们可以得出这样的结论：<strong>TranSparse（Separate）可以同时克服数据的异构性和不平衡性；非结构化模式的性能也优于结构化模式。</strong></p></li></ol><h2 id="summary">Summary</h2><p>提出一种 TranSparse 模型用于补全知识图谱，考虑异质性和不平衡性，引入了稀疏变换矩阵。并提出了两种稀疏模式，并分析优劣。实验证明了方法是有效的，且含有少量的参数；在三元组分类和链接预测任务上达到了最优效果。</p><div class="note note-info"><p>有人认为，实验中对比的 baseline 并不多，TranSparse 自己的模型就占了四行，很多论文是这样，自己提出的模型有很多个小 trick，可以视为几个子模型，与 baseline 一齐比较，即使其中任意一个达到 state-of-the-art 的效果，都是成功，看起来会比较好看，在 baseline 比较少的情况下不会使实验部分看起来很单薄。</p></div></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/NLP/">NLP</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/NLP/">NLP</a> <a class="hover-with-bg" href="/tags/TranSparse/">TranSparse</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处来源：<a href="https://stuxiaozhang.github.io/">小张的宇宙空间站</a></p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2021/09/12/TransM%EF%BC%9ATransition-based%20Knowledge%20Graph%20Embedding%20with%20Relational%20Mapping/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">TransM：Transition-based Knowledge Graph Embedding with Relational Mapping</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2021/09/12/TransA%EF%BC%9AAn%20Adaptive%20Approach%20for%20Knowledge%20Graph%20Embedding/"><span class="hidden-mobile">TransA：An Adaptive Approach for Knowledge Graph Embedding</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js",function(){var e=Object.assign({appId:"81O1jSOqY3veRxOg71BDYfri-gzGzoHsz",appKey:"CgnvRL262D07ied40NiXm2VL",placeholder:"快来评论鸭~",path:"window.location.pathname",avatar:"retro",meta:["nick","mail","link"],pageSize:10,lang:"zh-CN",highlight:!0,recordIP:!0,serverURLs:"",emojiCDN:"https://cdn.bootcdn.net/ajax/libs/emojione/4.5.0/lib/js/emojione.min.js",emojiMaps:null,enableQQ:!0,requiredFields:["nick"]},{el:"#valine",path:window.location.pathname});new Valine(e)})})</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://stuxiaozhang.github.io" target="_blank" rel="nofollow noopener"><span>小张同学的宇宙空间站</span></a> 已经运转了<span id="timeDate">载入天数...</span><script src="/js/duration.js"></script></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js"></script><script>!function(t){(0,Fluid.plugins.typing)(t.getElementById("subtitle").title)}((window,document))</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},options:{renderActions:{findScript:[10,a=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const n=new a.options.MathItem(e.textContent,a.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),n.start={node:t,delim:"",n:0},n.end={node:t,delim:"",n:0},a.math.push(n)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}}</script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js"></script><script src="/js/boot.js"></script></body></html>